[{"title":"Driver,BSP和HAL","url":"/2025/07/15/Driver-BSP%E5%92%8CHAL/","content":"基本关系如下图所示\n\n1.驱动（Driver）\n驱动程序是直接与硬件设备交互的软件组件。它们为操作系统或应用程序提供控制硬件的接口。可以理解为驱动直接与硬件交互。最为底层。\n2.板级支持包（BSP, Board Support Package）\n是一套针对特定硬件系统的低级软件代码， 其主要作用是抽象硬件细节， 以便操作系统能够顺利运行在特定的硬件平台上。BSP 是高度硬件相关的，为一块板写的 BSP 通常不能直接用在另一块不同的板上，即使它们使用了相同的 MCU/MPU（因为外围电路、引脚连接、时钟源等都可能不同）。\n3.硬件抽象层（HAL, Hardware Abstraction Layer）\nHAL是介于底层硬件和上层软件之间的一层抽象层，用于隐藏硬件的具体实现细节，提供统一的接口。包含一组通用的API接口，可以理解为定义好的一组标准的函数（如 HAL_UART_Transmit(), HAL_GPIO_WritePin(), HAL_ADC_Start()）来执行常见的硬件操作。\n目的是提供统一的、标准化的接口来访问某一类硬件功能（如 UART、I2C、GPIO、ADC、定时器等），屏蔽不同厂商、不同系列、甚至不同架构（如 ARM Cortex-M vs RISC-V）芯片的具体寄存器操作差异。        相对于BSP抽象层次更高，可移植性更高。\n以stm32HAL库开发为例，流程如下：\n应用程序\n│\n↓ 调用统一API\nHAL 层（如 HAL_UART_Transmit()）\n│\n↓ 调用板级驱动或直接操作寄存器\nBSP 层（如 BSP_UART_Write() 或 直接写 UART-&gt;DR 寄存器）\n│\n↓ 操作物理寄存器\n硬件寄存器（如 USART1-&gt;DR = data）\n","categories":["嵌入式"]},{"title":"FastKV","url":"/2025/10/03/FastKV/","content":"FastKV 论文阅读笔记\n1. 论文在解决什么问题？\n大语言模型（LLM）处理长文本（比如128K tokens）时，有一个很大的瓶颈：KV Cache。\n\nKV Cache是什么？ 为了在生成每个新token时不用重新计算所有历史token的信息，Transformer的Attention层会把之前所有token的Key和Value缓存下来。(可以读我之前写的注意力机制)\n问题在哪？ 文本越长，KV Cache，导致：\n\n内存不够用：例如，处理128K tokens的文本，KV Cache可能比模型本身还占内存。\n速度变慢：尤其是在“预填充”阶段（Prefill Stage，即处理用户输入的整个提示词），需要为所有输入token计算并存储KV Cache，计算量和延迟很高。TTFT（首token时间）是影响用户体验的关键指标。\n\n\n\n现有的KV Cache压缩方法，比如SnapKV，主要在生成阶段节省内存，但对预填充阶段的加速没什么帮助。而另一个方法GemFilter虽然能加速预填充，但因为它直接删掉了输入提示词中的部分token，导致模型丢失了全局上下文信息，精度下降。\n所以，这篇论文的目标就是：找到一个既能大幅加速预填充阶段（降低TTFT）、又能保持模型精度的KV Cache压缩方法。\n\n补充：什么是TTFT？\n\nTTFT 的全称是 Time To First Token，指的是从你按下送，把完整的Prompt交给大模型开始，到大模型生成的第一个token为止所花费的时间。\n2. 核心方法：FastKV 与 Token-Selective Propagation (TSP)\nFastKV 的核心方法是 Token-Selective Propagation (TSP) 机制。\n核心思想\n\n早期层（TSP层之前）：让模型像正常一样，完整地处理所有输入token。这样，每个token都经过了多层Attention的“信息融合”，已经包含了丰富的上下文信息。\n在某个中间层（TSP层）：从所有token中，筛选出一小部分“最重要”的token。\n后期层（TSP层之后）：只对这一小部分筛选出来的token进行后续计算。因为token数量大大减少，后续层的计算量也大幅降低，从而实现了加速。\n\n\n$S_i^{l,g}=\\frac{1}{H_G}\\sum_{h=h_g}^{h_g+H_G}S_i^{j,h}$\n( S_i^{l,g} )  第 l 层、第 g 个注意力Attention Head Group中，第 i 个 token 的组重要性得分。这是该公式的计算结果，代表一个Attention Head Group对某个 token 的注意力得分。\n( H_G ) 每个注意力Attention Head Group中包含的 Attention Head 数量。这是一个预设的超参数，用于控制组的规模。\n( h_g )  第 g 个组的起始 Attention Head 索引。例如，如果每组有8个头，那么第一组 ( h_g = 0 )，第二组 ( h_g = 8 )，以此类推。\n( h_g + H_G )  第 g 个组的结束 Attention Head 索引。即对一个完整组内所有头进行遍历。\n( S_i^{j,h} )  第 j 层、第 h 个 Attention Head 中，第 i 个 token 的重要性得分。\n\n这里插入一个和SnapKV的对比\nSnapKV 为每个头单独计算和选择， 每个头选自己的token，不同头保留的token集合可能完全不同\n\n$S_i^{l,h}=\\frac{1}{2w_p+1}\\sum_{m=-w_p}^{w_p}\\sum_{n=0}^{N_\\mathrm{obs}}Att_l[h,N_I-n,i+m]$\nFastKV 按组统一计算和选择， 整个组共享同一套token，组内所有头保留相同的token集合\nSnapKV为每个头独立选择token，而FastKV按头组统一选择token，并且通过TSP机制实现了预填充阶段的加速\nTSP 如何选择重要token？\n利用Attention机制本身来评估token的重要性。\n\n计算注意力分数：在选定的TSP层，对于该层的每一个Attention Head，我们都能得到一个注意力分数矩阵 Att_l。\n计算token重要性得分：为了得到一个统一的、代表整个层观点的分数，论文将所有Attention Head的分数进行平均：\n[ S_{i}^{TSPlayer} = \\frac{1}{H} \\sum_{h=0}^{H-1} S_{i}^{TSPlayer, h} ]\n\n( S_{i}^{TSPlayer} )：第 i 个token在TSP层的重要性得分。\n( H )：该层的Attention Head总数。\n( S_{i}^{TSPlayer, h} )：第 i 个token在第 h 个Head中的重要性得分（这个得分可以理解为对注意力分数进行滑窗平均得到的）。\n\n\n选择Top-K：根据 ( S_{i}^{TSPlayer} ) 得分，选择得分最高的K个token。这个K就是 TSP长度（TSP Length）。论文发现TSP长度设为2048是个比较好的平衡点。\n\n\n注意一个时间节点：\n\n&quot;These tokens are used to index hidden states after the MLP block, effectively reducing the layer input size for subsequent computation.&quot;\n也就是说TSP操作发生的时间点是“after the MLP block”，在 TSP 层，模型首先像正常一样，对所有输入 token 执行了 自注意力计算 和 MLP 计算。在经过了 MLP 块之后得到了该层最终的、经过充分信息处理的隐藏状态。此时，FastKV 才使用之前选出的重要 token 的索引，从这个完整的隐藏状态矩阵中，索引出那些重要 token 对应的隐藏状态。这些被挑出来的隐藏状态，会被传递给下一层。由于 token 数量大大减少，下一层的计算量也随之大幅降低。\n两个关键参数的解耦\nTSP长度 和 KV Cache预算（KV Budget） 是两个独立的参数。这样的涉及便于实际应用中平衡速度和精度。\n\nTSP长度：决定有多少个token会参与TSP层之后的计算，影响预填充阶段的计算速度（TTFT）。\nKV Budget：决定最终有多少个token的KV值会被存入Cache，影响生成阶段的内存占用和吞吐量（Throughput）。\n\n例如，可以设置 TSP长度=2048，KV Budget=512。这意味着：\n\n预填充时，后期层只处理2048个token，计算量小，TTFT低。\n生成时，KV Cache里只存了512个token的Key和Value，内存占用小，吞吐量高。\n\n5. 一些疑问和思考\n5.1 （续上面对SnapKV和FastKV的对比）如果有超长代码生成等任务（或者其他细粒度依赖的任务），FastKV采用的是按组进行token选择，而不是为每个注意力头单独选择token，假设在代码生成任务中，有一个注意力头专门负责结构体的定义，另一个头负责api的调用。这两个头关注的内容不同，因此它们认为重要的token也可能不同。如果这两个头被分在同一个组，那么组的重要性得分是这两个头得分的平均。这可能导致一些对其中一个头非常重要但对另一个头不重要的token被平均掉，从而不被选择。而在SnapKV中，每个头都可以保留自己最重要的token，因此不会出现这个问题。\n","categories":["论文阅读笔记"],"tags":["LLM","长上下文处理","KV Cache"]},{"title":"Cache及DMA缓存一致性处理","url":"/2025/07/21/Cache%E5%8F%8ADMA%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%A4%84%E7%90%86/","content":""},{"title":"LoRA","url":"/2025/06/26/LoRA/","content":"一.LoRA原理\n参考：https://zhuanlan.zhihu.com/p/702629428\n原论文：https://arxiv.org/pdf/2106.09685\nLoRA(Low-Rank Adaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。\nLoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。\n1.1实现流程\n\n\n在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；\n用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B；\n训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数。\n\n具体来讲，预训练权重矩阵 $\\mathbf{W}_0\\in\\mathbb{R}^{d\\times d}$ ，\n将增量参数矩阵 $\\Delta\\mathbf{W}$ ，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式\n$$\\mathbf{W}{0}+\\Delta\\mathbf{W}=\\mathbf{W}{0}+\\mathbf{BA}$$\n其中 $\\mathbf{B}\\in\\mathbb{R}^{d\\times r}$ ，$\\mathbf{A}\\in\\mathbb{R}^{r\\times d}$ ，秩$\\mathrm{r}$远小于$\\mathrm{d}$\n给定输入$.\\mathbf{x}\\in\\mathbb{R}^d$ ,添加LoRA后的输出$.\\mathbf{h}\\in\\mathbb{R}^d$\n$$\\mathbf{h}=(\\mathbf{W}{0}+\\Delta\\mathbf{W})\\mathbf{x}=\\mathbf{W}{0}\\mathbf{x}+\\mathbf{BA}\\mathbf{x}$$\n$$\\Delta\\mathbf{h}=\\mathbf{BAx}$$\n1.2LoRA参数合并系数\n实际实现时以以下形式合并，其中$\\alpha$为超参数\n$$\\mathbf{h}=(\\mathbf{W}_{0}+\\frac{\\alpha}{r}\\Delta\\mathbf{W})\\mathbf{x}$$\n系数$\\frac{\\alpha}{r}$越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合\n系数$\\frac{\\alpha}{r}$越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）\n一般来说，在给定任务上LoRA微调，让$\\alpha$为$\\mathbf{r}$的2倍数。\n1.3 LoRA的秩$\\mathbf{r}$如何选择\n目标：找到一个秩$\\mathbf{r}$，使$\\mathrm{BA}$无限接近$\\Delta\\mathbf{W}$的表达能力。\n秩$\\mathbf{r}$越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。\n","categories":["-科研实习 -RadioDiff微调"],"tags":["大模型微调"]},{"title":"Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption","url":"/2025/06/26/Phasic%20Content%20Fusing%20Diffusion%20Model%20with%20Directional%20Distribution%20Consistency%20for%20Few-Shot%20Model%20Adaption/","content":"Few-Shot\nPhasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption\nAbstract\n\n当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节\n引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）\n跨领域情景的结构一致性\n\nChallenges\n\noverfit\n细节学习阶段（t较小的时候）风格迁移失败\n现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转\n\nMethod\nTraining with Phasic Content Fusion\n在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合$E(x^{A})$和噪声$z\\sim\\mathcal{N}(0,I)$，\n$\\hat{E}(x^A)=m(t)E(x^A)+(1-m(t))z$\n然后使用多个卷积块将 $\\hat{E}(x^A)$ 与 $E(x_{t}^{A})$ 融合，得到融合后的特征 $E(x^A,x_t^A)$ ，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的 $x_{t-1}^A$\n方向分布一致性损失函数 directional distribution consistency loss (DDC)\n最终的损失函数由以下三个损失函数构成：\n\n\nDirectional distribution consistency loss\n$\\mathcal{L}_{DDC}=|E(x^A)+w,E(x_0^{A\\to B})|^2$\n其中w为方向向量，给定源分布 $A={x_{1}^{A},\\cdots x_{m}^{A}}$ 和目标分布 $B={x_{1}^{B},\\cdots x_{m}^{B}}$ ,特征空间中从源域中心到目标域中心的跨域方向向量w,\n$w=\\frac{1}{m}\\sum_{i=1}^mE(x_i^B)-\\frac{1}{n}\\sum_{i=1}^nE(x_i^A)$\n\n\nStyle loss\n$\\mathcal{L}{style}=\\frac{1}{m}\\sum{i=1}^{m}\\sum_{l}w_{l}|G^{l}(x_{0}^{A\\to B})-G^{l}(x_{i}^{B})|^{2}$\n用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵\n\n\nDiffusion Loss\n\n\n$\\mathcal{L}{dif}=||\\epsilon\\theta(x_t^B,t)-\\epsilon||^2$\n\n\n最终的损失函数为：\n$\\mathcal{L}=m(t)(1-w(t))(\\lambda_{DDC}\\mathcal{L}{DDC}(x^{A},x{0}^{A\\to B})+\\lambda_{style}\\mathcal{L}{style}(x{0}^{A\\to B},x^{B}))+w(t)\\mathcal{L}_{dif}(x^{B})$\n迭代跨域结构引导 Iterative Cross-domain Structure Guidance(ICSG)\n需要进一步理解\n实验及评估过程\n相关概念\n图像翻译 Image-to-Image Translation\n将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。\nGram矩阵\n原理\nn维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Gram matrix)，很明显，这是一个对称矩阵。\n输入图像的feature map为[ ch, h, w]。我们经过flatten（即是将h* w 进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w, ch]的矩阵。再对两个作内积得到Gram矩阵。\n应用\nGram matrix的应用-风格迁移：\n\n\n准备基准图像和风格图像\n\n\n使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图feature map）\n\n\n分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像\n\n\n一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。\n消融实验 Ablation Study\n类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。\n","categories":["论文阅读笔记"],"tags":["Few-Shot"]},{"title":"Specialist Diffusion","url":"/2025/06/26/Specialist-Diffusion/","content":"Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models to Learn Any Unseen Style\nhttps://arxiv.org/pdf/2211.12572\n主要内容\n这篇论文提出Specialist Diffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，content loss to facilitate content-style disentanglement，sparsely updating diffusion time steps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。\nData Augmentations for Text2Image Diffusion（数据增强）\nImage Augmentation\nText Prompt Augmentation\nCaption Retrieval Augmentation 标题搜索增强\nSynonym Augmentation 同义词增强\nDoubled Augmentation 双重增强\nContent Loss\nSparse Updating\n相关概念\n增强泄露问题 augmentation leakage\n生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。\n举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能 “bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended” ，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏” 到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentation leakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的 “虚假模式”，而非真实场景的合理特征，影响生成效果。\n正则化 Regularization\n正则化是用来防止模型过拟合而采取的手段，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大\n参考：https://blog.csdn.net/weixin_41960890/article/details/104891561\n","categories":["论文阅读笔记"],"tags":["Few-Shot"]},{"title":"STM32移植FreeRTOS-基于HAL库","url":"/2025/08/14/STM32%E7%A7%BB%E6%A4%8DFreeRTOS-%E5%9F%BA%E4%BA%8EHAL%E5%BA%93/","content":"前段时间电赛训练时常苦于复杂工程的时间调度问题，由于裸机系统主程序是在一整个while(1)循环中实现的，所以面对需要实现多个功能的情况总会显得力不从心，我只好自己写状态机通过状态判断来优化调度，但这种做法实现起来比较复杂，突然想到或许可以移植FreeRTOS来解决这个问题，遂开始学习。\ncubemx基本配置\nTimebase Source\n由于FreeTROS使用systick作为心跳，故搭载FreeRTOS时需要为HAL库另外选择一个定时器充当系统时基，推荐选择一个无任何输入输出即功能较少的定时器。\nMiddleware and Software Packs\n选择FreeRTOS的CMSIS_v2接口\n详细配置参考：https://blog.csdn.net/qq_45396672/article/details/120877303\n创建任务与队列\n\n创建任务\n任务（线程）是操作系统运行的基本单元,点击add并配置相关的任务名称，任务实体（函数名），优先级等\n创建队列\n队列（消息队列）负责任务之间传输数据，发送数据的任务发送到队列，接收数据的任务挂起到队列的挂起列表。点击add并设置队列名称大小等。\n下面介绍发送队列和接收队列API的调用方法：\n发送函数\n函数原型：\nosStatus_t osMessageQueuePut (osMessageQueueId_t mq_id, const void *msg_ptr, uint8_t msg_prio, uint32_t timeout);  ```   入参分别为队列句柄的指针，发送内容的指针，发送队列优先级（好像暂时无法使用，默认为1就行），等待超时时间使用示例：```cppvoid StartuartTask(void *argument)&#123;  /* USER CODE BEGIN StartuartTask */\tosStatus_t result;\tuint8_t dat[]=&quot;111\\r\\n&quot;;  /* Infinite loop */  for(;;)  &#123;\t\t\t\tresult= osMessageQueuePut(myQueue01Handle,dat,1,0);\t\tif(result == osOK)\t\t&#123;\t\t\t//发送成功\t\t&#125;else\t\t&#123;\t\t\t//发送失败\t\t&#125;       osDelay(1);  &#125;  /* USER CODE END StartuartTask */&#125;\n接收函数\n函数原型：\nosStatus_t osMessageQueueGet (osMessageQueueId_t mq_id, void *msg_ptr, uint8_t *msg_prio, uint32_t timeout);\n使用示例：\nvoid StartledTask(void *argument)&#123;    /* USER CODE BEGIN StartledTask */    osStatus_t result;    uint8_t dat[10]= &#123;&#125;;    uint8_t *pro;    /* Infinite loop */    for(;;)    &#123;        result= osMessageQueueGet(myQueue01Handle,dat,pro,10);        if(result == osOK)        &#123;            //接受成功        &#125; else        &#123;            //接受失败        &#125;        osDelay(1);    &#125;    /* USER CODE END StartledTask */&#125;\n创建软件定时器与信号量\n\n创建软件定时器\n添加软件定时器之后会生成一个回调函数\nvoid CallBack01()&#123;&#125;\n以下分别为定时器启动和停止的函数原型，调用方法与队列的句柄一致\nosStatus_t osTimerStart (osTimerId_t timer_id, uint32_t ticks);     osStatus_t osTimerStop (osTimerId_t timer_id);\nticks是定时器周期\n创建信号量\n信号量本质上是一个特殊的 RTOS 内核对象，用于任务之间或任务与中断之间的 同步 或 资源管理。\n可以理解为定时器，但是装载的不是数字而是信号数目，当信号数目大于0时任务可以进行但要获取一个信号数目（即信号-1），信号数目=0时任务阻塞，等到有信号再唤醒。\n二值信号量 (Binary Semaphore)\n只能取值 0 或 1，相当于开关；最常用来让一个任务等待某个事件发生，示例如下\nvoid StartDefaultTask(void *argument)&#123;  /* USER CODE BEGIN StartDefaultTask */\t\t  /* Infinite loop */  for(;;)  &#123;    //等待信号量（注意要有一个事件释放信号，即当这个事件执行一次后，便开始执行以下任务）\t\tif( osSemaphoreAcquire(myBinarySem01Handle,10)==osOK)&#123;            //开始执行任务                    &#125;\t\t    osDelay(1);  &#125;  /* USER CODE END StartDefaultTask */&#125;\n计数信号量 (Counting Semaphore)\n计数范围大于 1，可用于控制对某类资源的访问次数\n简单理解，可以这样用：有个事件A释放信号，设置Count（信号量最大数目）为n,当A执行满n次后开始执行任务B\n创建互斥量\n\n上面是普通互斥量，下面是递归互斥量\n互斥量可以这样理解：二值信号量 + 优先级\n使用方法与信号量相同\n普通互斥量\n只有一个任务能持有（值为 0 时其他任务阻塞），不能由另一个任务释放（必须持有者释放），同一任务如果再次请求同一 Mutex → 死锁（因为它已经占用，自己还在等自己释放），即只能请求一次。\n递归互斥量\n允许同一个任务多次获取同一把锁，每次获取都要匹配一次释放。必须释放和获取次数匹配，计数归零时才真正释放锁。\n创建事件标志组\n","categories":["-嵌入式 -单片机 -stm32"],"tags":["stm32","RTOS"]},{"title":"stm32-ADC","url":"/2025/07/21/stm32-ADC/","content":"采样率和转换时间\n对于stm32使用的逐次逼近型ADC，总转换时间计算公式为：T=采样时间+逐次逼近时间\n对于我最近使用的stm32h7,逐次逼近时间为7.5个ADC周期，即：T=采样时间+7.5个ADC时钟周期\n而采样时间可通过 ADCx_SMPR1 和 ADCx_SMPR2 寄存器中的 SMP[2:0] 位编程，可选采样时间值如下：\n\n\n设置ADC采样率时，无论是软件触发还是定时器触发，都要保证ADC采样两次触发之间的时间间隔要大于（等于）完成一次转换的时间。\n定时器触发\nstm32h7定时器：\nAPB1 定时器有 TIM2, TIM3 ,TIM4, TIM5, TIM6, TIM7, TIM12, TIM13, TIM14，LPTIM1\nAPB2 定时器有 TIM1, TIM8 , TIM15, TIM16，TIM17\nAPB4 定时器有 LPTIM2，LPTIM3，LPTIM4，LPTIM5\n","categories":["-嵌入式 -单片机 -stm32"],"tags":["stm32"]},{"title":"week1","url":"/2025/05/20/week1/","content":"一致性模型（Consistency Models，CM）\nhttps://zhuanlan.zhihu.com/p/623402026\n一致性模型（Consistency Models，CM）主要解决扩散生成模型迭代采样过程缓慢的问题，支持一步采样快速生成和多步采样高精度生成，CM 的本质就是将任何时间步的点映射到轨迹的起点。CM 的一个关键的性质是 self-consistency 性：相同轨迹上的点映射到相同的初始点。\nSDE与ODE\n前向过程满足的SDE：\n$\\mathrm{d}\\mathbf{x}=\\mathbf{f}(\\mathbf{x},t)\\mathrm{d}t+g(t)\\mathrm{d}\\mathbf{w}(t) $\nf:漂移因子 g:扩散因子 w:维纳过程(标准布朗运动)  score:$\\nabla_x\\log p(x)$ 即概率密度对数的梯度\n朗之万动力学\n边缘概率密度\nscore matching\n逆向过程的SDE为：\n$\\mathrm{d}\\mathbf{x}=[\\mathbf{f}(\\mathbf{x},t)-g^2(t)\\nabla_\\mathbf{x}\\log p_t(\\mathbf{x})]\\mathrm{d}t+g(t)\\mathrm{d}\\bar \\ {\\mathbf{w}}(t)$\nODE：SDE去掉维纳过程，变成一个常微分方程\n$\\mathrm{d}\\mathbf{x}_t=\n\\begin{bmatrix}\nf(\\mathbf{x}_t,t)-\\frac{1}{2}g^2(t)\\nabla\\log p_t(\\mathbf{x}_t)\n\\end{bmatrix}\\mathrm{d}t$\n如何用神经网络训练一致性模型\n一致性函数\n$f(\\mathbf{x}t,t)=\n\\begin{cases}\n\\mathbf{x}\\varepsilon, &amp; t=\\varepsilon \\\nf(\\mathbf{x}_{t^{\\prime}},t^{\\prime}), &amp; t\\in(\\varepsilon,T],\\forall t^{\\prime}\\in[\\varepsilon,T] &amp;\n\\end{cases}$\n一致性模型：即用神经网络模拟一致性函数的特性\n给定任意神经网络F,\n$f_\\theta(\\mathbf{x}t,t)=C{\\mathrm{skip}}(t)\\mathbf{x}t+C{\\mathrm{out}}(t)F_\\theta(\\mathbf{x}_t,t)$   随t变化时C的变化\nEDM–$C_{in}$\n损失函数——相邻两个时间输出值差距最小化$\\mathcal{L}^N(\\theta)=\\mathbb{E}[|f_\\theta(\\mathbf{x}{t{n+1}},t_{n+1})-f_\\theta(\\hat{\\mathbf{x}}{t_n},t_n)|2^2]$  再经过EMA,最终$\\mathcal{L}^N(\\theta,\\theta^-)=\\mathbb{E}[|f\\theta(\\mathbf{x}{t_{n+1}},t_{n+1})-f_{\\theta^-}(\\hat{\\mathbf{x}}_{t_n},t_n)|_2^2]$\n一致性蒸馏（简称CD，Consistency Distillation）——从已经学好的score function蒸馏\n\n已经有了score function $\\mathbf{s}_{\\phi}(\\mathbf{x}(t),t)$\n一致性训练(简称CT，Consistency Training)——从数据中直接学\n\n用$\\nabla\\log p_t(\\mathbf{x}_t)=-\\mathbb{E}\\left[\\frac{\\mathbf{x}_t-\\mathbf{x}}{t^2}|\\mathbf{x}_t\\right]$来代替一致性蒸馏中的已有的sore fuction\n如何通过一致性模型采样获得图像\n一步采样\n给定一个$x_t$，带入一致性模型\n多步采样\n可提升图像质量\nSR3\nSR3 is an approach to image super resolution via iterative refinement\n通过迭代优化实现生成图像超分辨率\nkey words\n\niterative refinement\nboth faces and natural images\nbicubic interpolation\nflexibility inchoosing number of diffusion steps, and the noise schedule during inference\nFID\nrather than estimating the posterior mean, SR3 generates samples from the target posterior.\nconstant number of refinement steps (often no more than 100).\nonot requireanyauxiliaryobjective function inorder toensureconsistencywith the low resolutioninputs\nour diffusion models do not provide a knob to control sample quality vs. sample diversity（如何平衡样本质量与样本多样性吗？）, and finding ways to do so isinteresting\navenue for future research.\n\n涉及知识点\n\nscore matching\nLangevin dynamics\nPSNR and SSIM\nresidual blocks\n级联结构\nNormalizing flows\nanti-aliasing\nImageNet\nDropout\n\n总结\n\n将LR作为条件输入\n不在取离散的t，而是将同样范围内连续t的采样值（即noise）输入\n或许可以减小推理步数，加快速度？\n级联 分阶段生成：\n第一阶段：使用无条件生成模型（如DDPM）生成低分辨率图像（如64×64）。\n第二阶段：将低分辨率图像输入第一个SR3模型，进行4倍上采样（64→256）。\n第三阶段：将256×256图像输入第二个SR3模型，再次4倍上采样至1024×1024。\n\n问题\n\n下采样操作，将 HR 图像的尺⼨减半，⽣成对应的 LR 图像\n下采样方式如何选择（是否采用SR3论文中提到的双三次插值？），以及为什么规定LR为HR尺寸减半后的结果\nSR3采用的是迭代优化实现图像超分辨率重建的方法，是否面临计算和时间成本高的问题，如何解决是否可以参考连续一致性模型的做法\n连续一致性模型有单步采样和多部采样两种方式，多部采样可以理解为牺牲速度换取高质量？是否可以再次基础上实现超分辨率重建？\n尝试https://github.com/openai/consistency_models\n和https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement 时遇到困难\n对数学公式的推导要掌握到什么程度？\n\n","categories":["科研实习周记"],"tags":["diffusion model","科研实习周记"]},{"title":"week2","url":"/2025/06/25/week2/","content":"diffusion model (李宏毅)笔记\n概念部分\n一般图像生成模型基本框架\ntext encoder → generation model → decoder\nFID(Frechet Inception Distance)\nFID是一种用于评估生成图像质量的度量标准\n\n\n特征提取  使用预训练的 Inception V3 模型（在 ImageNet 数据集上训练的图像分类网络）作为特征提取器。输入图像（通常调整为 299×299 的分辨率）会通过 Inception V3 前向传播，提取池化层（即 pool3 层）的输出特征。这个特征是一个 2048 维的向量。\n\n\n特征分布假设  FID 假设提取的特征向量服从多变量正态分布。对于真实图像集合X和生成图像集合G，分别计算特征的均值向量和协方差矩阵：\n真实图像特征均值 $\\mu_{r}$   协方差 $\\Sigma_{r}$\n生成图像特征均值 $\\mu_{g}$   协方差 $\\Sigma_{g}$\n\n\nFréchet 距离计算\nFréchet 距离用来衡量两个正态分布之间的差异$$\\mathrm{FID}=|\\mu_r-\\mu_g|_2^2+\\mathrm{Tr}(\\Sigma_r+\\Sigma_g-2(\\Sigma_r\\Sigma_g)^{1/2})$$\n第一项衡量两个分布均值的欧几里得距离，表示分布中心的偏移，第二项衡量协方差矩阵的差异，反映分布形状和分散度的不同\n\n\n原理部分\nhttps://www.bilibili.com/video/BV14c411J7f2?spm_id_from=333.788.player.switch&amp;vd_source=257a40315247000b85510107fa6b747d&amp;p=4\n\n\n最大似然估计 https://zhuanlan.zhihu.com/p/55791843\n\n\n\n扩散模型与能量模型，Score-Matching和SDE，ODE的关系 https://zhuanlan.zhihu.com/p/576779879\n\n\n疑问\n\n李宏毅认为噪声实际上不是一步一步加进$x_{0}$的,而是一步实现的\n\n但通过对一致性模型的学习，我了解到diffusion model的前向过程和逆向过程实际上都能表示为SDE过程，需要进行多次迭代，而consistency model就是为了解决这个问题，将SDE的随机项消除，转变为ODE过程，从而实现减少迭代次数，这是否与上图观点相悖？\n\n","categories":["科研实习周记"],"tags":["diffusion model","科研实习周记"]},{"title":"week3","url":"/2025/06/30/week3/","content":"Few-Shot\nPhasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption\nhttps://arxiv.org/pdf/2309.03729\nAbstract\n\n当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节\n引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）\n跨领域情景的结构一致性\n\nChallenges\n\noverfit\n细节学习阶段（t较小的时候）风格迁移失败\n现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转\n\nMethod\nTraining with Phasic Content Fusion\n在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合$E(x^{A})$和噪声$z\\sim\\mathcal{N}(0,I)$，\n$\\hat{E}(x^A)=m(t)E(x^A)+(1-m(t))z$\n然后使用多个卷积块将 $\\hat{E}(x^A)$ 与 $E(x_{t}^{A})$ 融合，得到融合后的特征 $E(x^A,x_t^A)$ ，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的 $x_{t-1}^A$\n方向分布一致性损失函数 directional distribution consistency loss (DDC)\n最终的损失函数由以下三个损失函数构成：\n\n\nDirectional distribution consistency loss\n$\\mathcal{L}_{DDC}=|E(x^A)+w,E(x_0^{A\\to B})|^2$\n其中w为方向向量，给定源分布 $A={x_{1}^{A},\\cdots x_{m}^{A}}$ 和目标分布 $B={x_{1}^{B},\\cdots x_{m}^{B}}$ ,特征空间中从源域中心到目标域中心的跨域方向向量w,\n$w=\\frac{1}{m}\\sum_{i=1}^mE(x_i^B)-\\frac{1}{n}\\sum_{i=1}^nE(x_i^A)$\n\n\nStyle loss\n$\\mathcal{L}{style}=\\frac{1}{m}\\sum{i=1}^{m}\\sum_{l}w_{l}|G^{l}(x_{0}^{A\\to B})-G^{l}(x_{i}^{B})|^{2}$\n用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵\n\n\nDiffusion Loss\n\n\n$\\mathcal{L}{dif}=||\\epsilon\\theta(x_t^B,t)-\\epsilon||^2$\n\n\n最终的损失函数为：\n$\\mathcal{L}=m(t)(1-w(t))(\\lambda_{DDC}\\mathcal{L}{DDC}(x^{A},x{0}^{A\\to B})+\\lambda_{style}\\mathcal{L}{style}(x{0}^{A\\to B},x^{B}))+w(t)\\mathcal{L}_{dif}(x^{B})$\n迭代跨域结构引导 Iterative Cross-domain Structure Guidance(ICSG)\n需要进一步理解\n实验及评估过程\n相关概念\n图像翻译 Image-to-Image Translation\n将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。\nGram矩阵\n原理\nn维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Gram matrix)，很明显，这是一个对称矩阵。\n输入图像的feature map为[ ch, h, w]。我们经过flatten（即是将h* w 进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w, ch]的矩阵。再对两个作内积得到Gram矩阵。\n应用\nGram matrix的应用-风格迁移：\n\n\n准备基准图像和风格图像\n\n\n使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图feature map）\n\n\n分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像\n\n\n一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。\n消融实验 Ablation Study\n类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。\nSpecialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models to Learn Any Unseen Style\nhttps://arxiv.org/pdf/2211.12572\n主要内容\n这篇论文提出Specialist Diffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，content loss to facilitate content-style disentanglement，sparsely updating diffusion time steps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。\nData Augmentations for Text2Image Diffusion（数据增强）\nImage Augmentation\nText Prompt Augmentation\nCaption Retrieval Augmentation 标题搜索增强\nSynonym Augmentation 同义词增强\nDoubled Augmentation 双重增强\nContent Loss\nSparse Updating\n相关概念\n增强泄露问题 augmentation leakage\n生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。\n举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能 “bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended” ，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏” 到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentation leakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的 “虚假模式”，而非真实场景的合理特征，影响生成效果。\n正则化 Regularization\n正则化是用来防止模型过拟合而采取的手段，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大\n参考：https://blog.csdn.net/weixin_41960890/article/details/104891561\n一.LoRA原理\n参考：https://zhuanlan.zhihu.com/p/702629428\n原论文：https://arxiv.org/pdf/2106.09685\nLoRA(Low-Rank Adaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。\nLoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。\n1.1实现流程\n\n\n在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；\n用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B；\n训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数。\n\n具体来讲，预训练权重矩阵 $\\mathbf{W}_0\\in\\mathbb{R}^{d\\times d}$ ，\n将增量参数矩阵 $\\Delta\\mathbf{W}$ ，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式\n$\\mathbf{W}{0}+\\Delta\\mathbf{W}=\\mathbf{W}{0}+\\mathbf{BA}$\n其中 $\\mathbf{B}\\in\\mathbb{R}^{d\\times r}$ ，$\\mathbf{A}\\in\\mathbb{R}^{r\\times d}$ ，秩$\\mathrm{r}$远小于$\\mathrm{d}$\n给定输入$.\\mathbf{x}\\in\\mathbb{R}^d$ ,添加LoRA后的输出$.\\mathbf{h}\\in\\mathbb{R}^d$\n$\\mathbf{h}=(\\mathbf{W}{0}+\\Delta\\mathbf{W})\\mathbf{x}=\\mathbf{W}{0}\\mathbf{x}+\\mathbf{BA}\\mathbf{x}$\n$\\Delta\\mathbf{h}=\\mathbf{BAx}$\n1.2LoRA参数合并系数\n实际实现时以以下形式合并，其中$\\alpha$为超参数\n$\\mathbf{h}=(\\mathbf{W}_{0}+\\frac{\\alpha}{r}\\Delta\\mathbf{W})\\mathbf{x}$\n系数$\\frac{\\alpha}{r}$越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合\n系数$\\frac{\\alpha}{r}$越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）\n一般来说，在给定任务上LoRA微调，让$\\alpha$为$\\mathbf{r}$的2倍数。\n1.3 LoRA的秩$\\mathbf{r}$如何选择\n目标：找到一个秩$\\mathbf{r}$，使$\\mathrm{BA}$无限接近$\\Delta\\mathbf{W}$的表达能力。\n秩$\\mathbf{r}$越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。\n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"week5","url":"/2025/07/13/week5/","content":"一、论文阅读笔记 Few-shot Image Generation with Diffusion Models\n论文：https://arxiv.org/pdf/2211.03264\n主要内容：\n提出Few-shot Diffusion Models (FDM)，在仅使用 10 张训练图像时，就能生成具有合理多样性和质量的图像。\n主要挑战\n过拟合和模式崩溃（模型只能生成训练集中见过的少数几种样本）\n核心方法\n结构感知数据增强 (Structure-Aware Data Augmentation)\n使用预训练的CLIP模型提取图像的语义特征，然后基于这些特征计算图像之间的相似性，\nCLIP相似度计算：$s_{ij}=\\frac{\\phi(I_i)\\cdot\\phi(I_j)}{|\\phi(I_i)||\\phi(I_j)|}$\n其中 ϕ(⋅) 是CLIP图像编码器，$s_{ij}\\in[-1,1]$表示图像 $I_{i}$  和 $I_{j}$  的语义相似度\n相似度高的图像对：应用更强的几何变换（如大幅旋转、裁剪），能提供更多样的“视角”而不会完全破坏结构。\n相似度低的图像对：应用较弱的变换，避免破坏其各自独特的结构信息。\n自适应变换强度:\n$\\lambda_{ij}=\\lambda_{\\min}+(\\lambda_{\\max}-\\lambda_{\\min})\\cdots_{ij}$\n$\\lambda_{\\mathrm{min}}$和$\\lambda_{\\mathrm{max}}$是最小/最大变换强度，相似度越高，变换强度越大\n层级优化机制 (Hierarchical Optimization)\nFDM 将扩散模型（如DDPM）的UNet结构划分为两个层级：\n\n\n基础层：负责捕捉图像的全局结构和基本语义（一般是UNet的深层/瓶颈层）\n\n\n细节层：负责生成图像的局部细节（一般是UNet的浅层）\n\n\n采用交替优化策略：\n阶段一 (Freeze Detail Layers)：冻结西接层参数，只优化基础层\n阶段二 (Freeze Base Layers)：冻结基础层参数，只优化细节层\n自适应卷积模块 (Adaptive Convolution Module)\n引入自适应卷积模块，根据输入特征图动态生成卷积核的偏移量 (offset) 和调制标量 (modulation scalar)\n偏移量： 卷积核的采样位置根据输入内容进行微调\n$\\Delta p_k=f_{\\mathrm{offset}}(\\mathbf{F};\\phi)$\n$f_{\\mathrm{offset}}$是轻量子网络，$\\mathrm{F}$是输入特征图\n调制标量： 动态调整卷积核的权重，增强模型对输入变化的适应能力\n$m_k=\\sigma(g_{\\mathrm{mod}}(\\mathbf{F};\\psi))$\n$\\mathrm{o}$ 是sigmoid激活函数，限制输出在(0,1)范围\n自适应卷积公式：\n$\\mathbf{y}(p)=\\sum_{k=1}^K\\mathbf{w}_k\\cdot\\mathbf{F}(p+p_k+\\Delta p_k)\\cdot m_k$\n模式崩溃\n对于某一个训练数据集，其中样本的概率分布为一个简单的一维高斯混合分布，包含两个峰，如下图\n\n模式崩溃问题是针对于生成样本的多样性，即生成的样本大量重复类似，如下图\n\n虽然生成样本的质量比较高，但是生成器完全没有捕捉到右边的峰的模式。\n解决思路：\n参考：https://cloud.tencent.com/developer/article/1522756\n二、代码改进\n改进代码，\n（1）由原来只替换注意力层改进为替换UNet的所有线性层和1x1卷积层\n（2）改进数据集的选择，原来是随机挑选了10个样本训练lora参数，应改进为挑选部分dpm和少量的irt4_car样本去训练\n7.9遇到的问题：替换Swin Transformer中的层，需要访问weight属性\n尝试解决\n（1）：跳过Swin Transformer中的层\n（2）：当win Transformer访问qkv.weight时，返回原始层的权重\n7.12 解决了LoRA注入失败的问题\n下一步：测试训练效果\n改进用于微调的样本的选择\n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"week4","url":"/2025/06/30/week4/","content":"一、LoRA微调\ntest1:\n将训练第二阶段注意力机制中的线性层’w_q’,‘w_k’,'w_v’替换为LoRA层\nlora_r: 8                    # LoRA秩大小lora_alpha: 16               # LoRA缩放因子\n预训练模型只加载第二阶段扩散网络权重\n结果： _IncompatibleKeys 错误（缺少 encoder/decoder 层）\n可能原因：只加载了第二阶段模型，缺少 Autoencoder 部分，无法将输入图像编码为潜在空间表示，无法将生成的潜在编码解码为图像\ntest2:\n由第一次尝试得，当只微调扩散网络本身时，仍需要\n\n\n先加载第一阶段Autoencoder\n\n\n再加载第二阶段扩散网络权重\n\n\n则test2总体流程为：\n\n加载完整的加载完整的扩散模型（含 Autoencoder + 扩散网络）\n注入 LoRA 参数到扩散网络的特定层\n冻结其他参数，随机选择20张图片训练 LoRA 层\n\n测试结果：\n\n\n\n评估指标\n微调前\n微调后\n变化趋势\n变化率\n\n\n\n\nNMSE\n0.006882\n0.005570\n↓\n-19.06%\n\n\nRMSE\n0.029842\n0.026012\n↓\n-12.83%\n\n\nSSIM\n0.945097\n0.955175\n↑\n+1.07%\n\n\nPSNR (dB)\n30.574329\n31.882632\n↑\n+4.28%\n\n\n\n注意力机制\n原论文：https://arxiv.org/pdf/1706.03762\n什么是注意力机制\n注意力机制就是让模型重点关注重要信息，忽略次要信息。注意力机制分为空间注意力和时间注意力，前者用于图像处理，后者用于自然语言处理.\n原理\nQuery：当前需要查询的目标，即当前输入的特征表示。\nKey：可以将每个单词的重要特征表示看作成 Key。\nValue：每个单词本身的特征向量看作为 Value，一般和 Key成对出现，也就是我们常说的&quot;键-值&quot;对。\n\n核心公式（原论文中）：\n$$\nAttention(Q,K,V)=Softmax(\\frac{QK^\\top}{\\sqrt{d_k}})V\n$$\n步骤：\n\n\n先根据 Query，Key计算两者的相关性，然后再通过 softmax 函数得到 注意力分数，使用 softmax 函数是为了使得所有的注意力分数在 [0,1] 之间，并且和为1。\n相关性公式一般表示如下：\n$$\nscore(q,k_i)=softmax(\\alpha(q,k_i))=\\frac{exp(\\alpha(q,k_i))}{\\sum_1^jexp(\\alpha(q,k_j))}\n$$\n其中$\\alpha(q,k_{i})$有很多变体：\ne.g. 在加性注意力中\n$$\n\\alpha(q,k_i)=w_v^Ttanh(W_qq+W_kk)\n$$\nW_q：Query对应的可训练矩阵\nW_k: Key对应的可训练矩阵\nw_v^T: Value对应的可训练矩阵\n(tanh为双曲正切函数，作为一种常见的激活函数)\ne.g.在缩放点积注意力中\n$$\n\\alpha(q,k_i)=\\frac{QK^T}{\\sqrt{d}}\n$$\n其中d为Keys的维度大小，除以sqrt{d}是为了使方差变小，训练梯度更新时更稳定\n\n\n将注意力分数加权求和，得到带注意力分数的Value\n\n\n自注意力机制（Self-Attention Mechanism）\n\n2.1 Embedding 操作, 将向量x转化为a,a作为注意力机制的input data\n2.2 q, k 操作\n$$q^i=W^qa^i$$\n$$k^i=W^ka^i$$\n$$v^i=W^va^i$$\n多头注意力机制（Multi-head Self-Attention Machanism）\n参考：https://zhuanlan.zhihu.com/p/631398525\n通道注意力机制\n空间注意力机制\n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"week6","url":"/2025/07/21/week6/","content":"微调效果测试\n用lora层替换unet中所有可替换的线性层和1×1卷积层，测试效果较差，有明显失真，指标相比上一次微调均有下降\n论文代码学习\n学习论文 Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption 的开源代码，\n微调部分实现方法如下：\n1. 内容融合模块微调 (train-recon.py)\n#创建一个Adam优化器，只优化扩散模型中条件模块(c_content_condition)的参数optimizer = Adam(diffusion.model.c_content_condition.parameters(), lr=1e-4)#遍历数据集中的所有批次for batch in dataloader:       real_image = batch.cuda()          condition = real_image  # 使用自身作为条件          t, (x, loss_diffusion) = diffusion.few_shot_forward(        real_image,           x_self_cond=condition,          max_step=1000      )      # 计算扩散损失的平均值（预测噪声与真实噪声的差异）      loss_diffusion.mean().backward()  # 反向传播计算梯度      optimizer.step()     if global_step % 200 == 0:        # 使用DDIM采样器生成重建图像        output_image = diffusion.ddim_sample(            real_image.shape,              condition=condition,              sample_step=50,                 max_step=800          #从噪声步800开始逆向扩散（跳过前200步）        )              \n通过 c_content_condition 模块分离内容/风格学习:\nmodel_target.prepare(style_condition=True, two_stage_step=300)\n2. 少样本域适应微调 (train-whole.py)\na.分阶段训练策略：大t步学内容/风格，小t步学细节, 具体是大t：学习全局内容/风格 (step=300-1000)  小t：学习局部细节 (t~rand(0,300))\nb.方向分布一致性：feature_dir = (target_feature - source_feature) 引导特征迁移\nL_DDC = ||φ(G(x)) - (φ(x) + Δ)||^2\n其中 Δ = E[φ(y)] - E[φ(x)] 是域间特征方向\nc.动态加权\nα = 20^{t/T} \\quad (T=1000)\n#创建一个优化器，只优化需要梯度的参数# 使用filter+lambda过滤出requires_grad=True的参数，冻结有些参数optimizer = Adam(    filter(lambda p: p.requires_grad, diffusion_target.parameters()),     lr=1e-4  #使用相对较小的学习率防止过拟合)# 遍历源域和目标域的数据加载器# 使用zip确保每次迭代获取一对源域和目标域批次数据for (target_batch, source_batch) in zip(target_dataloader, source_dataloader):    # 阶段1：内容保持（大t）      if global_step % 2 == 0:  # 每两步执行一次                    # step=300 表示在扩散过程的前300步进行内容融合        t, (x, _) = diffusion.few_shot_forward(            source_image,     # 源域输入图像            step=300,                   x_self_cond=condition  #内容条件输入        )              # 方向分布一致性损失              # 使用CLIP模型提取源域图像特征        feature_source = clip_model.encode_img(source_image)              feature_target = clip_model.encode_img(generated_image)                    #feature_dir = E[φ(y)] - E[φ(x)] 预计算的域间特征方向        loss_feature = mse_loss(            feature_target,             feature_source + feature_dir  # 特征方向约束        ) * opts.beta_f  #可调节的损失权重              # 风格损失              # 使用预定义的风格损失函数(训练的VGG)              loss_style = style_loss(generated_image, style_imgs) * opts.beta_style        # 阶段2：细节学习（小t）       else:  #与阶段1交替执行              t = torch.randint(0, 300, (batch_size,))                #使用目标域图像进行前向传播             _, (_, loss_diffusion) = diffusion.few_shot_forward(            target_image,              t=t                  )         #时间步相关加权          alpha = 20 ** (t / 1000)  #权重函数      #加权总损失       total_loss = (alpha * (loss_feature + loss_style)).mean()        total_loss.backward()     \n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"week7","url":"/2025/07/27/week7/","content":"跑代码\nhttps://github.com/sjtuplayer/few-shot-diffusion\n生成效果如下图：\n\n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"串口重定向","url":"/2025/07/08/%E4%B8%B2%E5%8F%A3%E9%87%8D%E5%AE%9A%E5%90%91/","content":"stm32串口重定向HAL库\n#include &lt;stdio.h&gt;// 包含标准输入输出头文件 int fputc(int ch,FILE *f)&#123;//采用轮询方式发送1字节数据，超时时间设置为无限等待HAL_UART_Transmit(&amp;huart1,(uint8_t *)&amp;ch,1,HAL_MAX_DELAY);return ch;&#125;int fgetc(FILE *f)&#123;uint8_t ch;// 采用轮询方式接收 1字节数据，超时时间设置为无限等待HAL_UART_Receive( &amp;huart1,(uint8_t*)&amp;ch,1, HAL_MAX_DELAY );return ch;&#125;\n","categories":["-嵌入式 -单片机 -stm32"],"tags":["stm32"]},{"title":"使用循环缓冲区进行串口数据解析","url":"/2025/06/29/%E4%BD%BF%E7%94%A8%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E8%A1%8C%E4%B8%B2%E5%8F%A3%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/","content":"stm32cubemx配置\n开启串口收发异步模式，开启串口空闲中断\n代码实现\n#include &quot;command.h&quot;// 指令的最小长度#define COMMAND_MIN_LENGTH 4// 循环缓冲区大小#define BUFFER_SIZE 128// 循环缓冲区uint8_t buffer[BUFFER_SIZE];// 循环缓冲区读索引uint8_t readIndex = 0;// 循环缓冲区写索引uint8_t writeIndex = 0;/*** @brief 增加读索引* @param length 要增加的长度*/void Command_AddReadIndex(uint8_t length) &#123;    readIndex += length;    readIndex %= BUFFER_SIZE;&#125;/*** @brief 读取第i位数据 超过缓存区长度自动循环* @param i 要读取的数据索引*/uint8_t Command_Read(uint8_t i) &#123;    uint8_t index = i % BUFFER_SIZE;    return buffer[index];&#125;/*** @brief 计算未处理的数据长度* @return 未处理的数据长度* @retval 0 缓冲区为空* @retval 1~BUFFER_SIZE-1 未处理的数据长度* @retval BUFFER_SIZE 缓冲区已满*///uint8_t Command_GetLength() &#123;//  // 读索引等于写索引时，缓冲区为空//  if (readIndex == writeIndex) &#123;//    return 0;//  &#125;//  // 如果缓冲区已满,返回BUFFER_SIZE//  if (writeIndex + 1 == readIndex || (writeIndex == BUFFER_SIZE - 1 &amp;&amp; readIndex == 0)) &#123;//    return BUFFER_SIZE;//  &#125;//  // 如果缓冲区未满,返回未处理的数据长度//  if (readIndex &lt;= writeIndex) &#123;//    return writeIndex - readIndex;//  &#125; else &#123;//    return BUFFER_SIZE - readIndex + writeIndex;//  &#125;//&#125;uint8_t Command_GetLength() &#123;    return (writeIndex + BUFFER_SIZE - readIndex) % BUFFER_SIZE;&#125;/*** @brief 计算缓冲区剩余空间* @return 剩余空间* @retval 0 缓冲区已满* @retval 1~BUFFER_SIZE-1 剩余空间* @retval BUFFER_SIZE 缓冲区为空*/uint8_t Command_GetRemain() &#123;    return BUFFER_SIZE - Command_GetLength();&#125;/*** @brief 向缓冲区写入数据* @param data 要写入的数据指针* @param length 要写入的数据长度* @return 写入的数据长度*/uint8_t Command_Write(uint8_t *data, uint8_t length) &#123;    // 如果缓冲区不足 则不写入数据 返回0    if (Command_GetRemain() &lt; length) &#123;        return 0;    &#125;    // 使用memcpy函数将数据写入缓冲区    if (writeIndex + length &lt; BUFFER_SIZE) &#123;        memcpy(buffer + writeIndex, data, length);        writeIndex += length;    &#125; else &#123;        uint8_t firstLength = BUFFER_SIZE - writeIndex;        memcpy(buffer + writeIndex, data, firstLength);        memcpy(buffer, data + firstLength, length - firstLength);        writeIndex = length - firstLength;    &#125;    return length;&#125;/*** @brief 尝试获取一条指令* @param command 指令存放指针* @return 获取的指令长度* @retval 0 没有获取到指令*/uint8_t Command_GetCommand(uint8_t *command) &#123;    // 寻找完整指令    while (1) &#123;        // 如果缓冲区长度小于COMMAND_MIN_LENGTH 则不可能有完整的指令        if (Command_GetLength() &lt; COMMAND_MIN_LENGTH) &#123;        return 0;        &#125;        // 如果不是包头 则跳过 重新开始寻找        if (Command_Read(readIndex) != 0xAA) &#123;        Command_AddReadIndex(1);        continue;        &#125;        // 如果缓冲区长度小于指令长度 则不可能有完整的指令        uint8_t length = Command_Read(readIndex + 1);        if (Command_GetLength() &lt; length) &#123;        return 0;        &#125;        // 如果校验和不正确 则跳过 重新开始寻找        uint8_t sum = 0;        for (uint8_t i = 0; i &lt; length - 1; i++) &#123;        sum += Command_Read(readIndex + i);        &#125;        if (sum != Command_Read(readIndex + length - 1)) &#123;        Command_AddReadIndex(1);        continue;        &#125;        // 如果找到完整指令 则将指令写入command 返回指令长度        for (uint8_t i = 0; i &lt; length; i++) &#123;        command[i] = Command_Read(readIndex + i);        &#125;        Command_AddReadIndex(length);        return length;    &#125;&#125;\n头文件：\n#ifndef INC_COMMAND_H_#define INC_COMMAND_H_#include &quot;main.h&quot;#include &lt;string.h&gt;uint8_t Command_Write(uint8_t *data, uint8_t length);uint8_t Command_GetCommand(uint8_t *command);#endif /* INC_COMMAND_H_ */\nmain.c:\n/* Private define ------------------------------------------------------------*//* USER CODE BEGIN PD */uint8_t readBuffer[10];/* USER CODE END PD */\n/* USER CODE BEGIN 0 */void HAL_UARTEx_RxEventCallback(UART_HandleTypeDef *huart, uint16_t Size)&#123;\tif (huart == &amp;huart2)&#123;\t\tCommand_Write(readBuffer, Size);\t\tHAL_UARTEx_ReceiveToIdle_IT(&amp;huart2, readBuffer, sizeof(readBuffer));\t&#125;&#125;/* USER CODE END 0 */\n/* USER CODE BEGIN 2 */HAL_UARTEx_ReceiveToIdle_IT(&amp;huart2, readBuffer, sizeof(readBuffer));uint8_t command[50];int commandLength = 0;/* USER CODE END 2 *//* Infinite loop *//* USER CODE BEGIN WHILE */while (1)&#123;    commandLength = Command_GetCommand(command);    if (commandLength != 0)&#123;        HAL_UART_Transmit(&amp;huart2, command, commandLength, HAL_MAX_DELAY);        for (int i = 2; i &lt; commandLength - 1; i += 2)&#123;            GPIO_PinState state = GPIO_PIN_SET;            if (command[i + 1] == 0x00)&#123;                state = GPIO_PIN_RESET;            &#125;            if (command[i] == 0x01)&#123;                HAL_GPIO_WritePin(RED_GPIO_Port, RED_Pin, state);            &#125;else if (command[i] == 0x02)&#123;                HAL_GPIO_WritePin(GREEN_GPIO_Port, GREEN_Pin, state);            &#125;else if (command[i] == 0x03)&#123;                HAL_GPIO_WritePin(BLUE_GPIO_Port, BLUE_Pin, state);            &#125;        &#125;    &#125;/* USER CODE END WHILE *//* USER CODE BEGIN 3 */&#125;\n","categories":["-嵌入式 -单片机 -stm32"],"tags":["stm32"]},{"title":"决策树","url":"/2025/07/15/%E5%86%B3%E7%AD%96%E6%A0%91/","content":"1.决策树介绍\n决策树（Decision Tree）是一种以树形数据结构来展示决策规则和分类结果的模型，代表对象属性和对象值之间的一种映射关系。\n以下图为例：\n\n一个决策树包含三种类型的节点：\n1.决策节点：通常用矩形框来表示\n2.机会节点：通常用圆圈来表示\n3.终结节点：通常用三角形来表示\n构建决策树的一般流程如下图：\n\n2.决策树的构建标准\n2.1 信息增益\n2.1.1 信息熵\n$H\\left(S\\right)=-\\sum_{i=1}^{c}p_{i}\\log_{2}\\left(p_{i}\\right)$\n其中，S 表示样本集，C 表示样本集合中类别个数（只含有正负样本，则 C=2），pᵢ表示第 i 个类的概率，（pᵢ可由类别 i 中含有样本的个数除以总样本数得到）\n取值范围：$0\\leq H(X)\\leq\\log_2n$  即所有结果等概率时熵最大\n直观理解：不确定性越大，信息熵越大。\n2.1.2 条件熵\n$H(X|Y)=-\\sum_{x,y}p(x,y)\\log(p(x|y))$\n条件熵$H(X|Y)$表示在移植随机变量Y的条件下，随机变量X的不确定性。\n\n2.1.3 信息增益\n信息增益是知道了某个条件后，事件不确定性降低的幅度。信息增益是非对称的，用以度量两种概率分布P和Q的差异，从P到Q的信息增益通常不等于从Q到P的信息增益。\n公式：$IG(S, A) = H(S) - H(S|A)$\n表示特征 $A$ 带来的不确定性减少量\n2.2 基尼系数\n基尼系数可以在样本集中随机抽出两个样本不同类别的概率。\n数据集的基尼系数：$Gini(D)=\\sum_{k=1}^n\\sum_{k\\prime\\neq k}p_kp_{k\\prime}=1-\\sum_{k=1}^\\mathrm{n}p_k^2$\n$p_{k}$表示第k类样本在数据集中的比例\n值域：$[0,0.5]$，（二分类时最大值为 0.5，K分类时最大为1-1/K）\n特征划分后的加权基尼系数：$Gini(S,A)=\\sum_{v=1}^m\\frac{|S_v|}{|S|}\\cdot Gini(S_v)$\n$\\mathrm{S}$：特征A取第v个值时对应的子集\n$\\frac{|S_{v}|}{|S|}$：子集的样本权重\n$Gini(S_{v})$： 子集的基尼系数\n2.3 增益比\n信息增益比较偏好可取值较多的属性，比如我们的样本有一个属性叫序号，每一个样本都具有一个单独的序号，因此使用序号划分后，每个子结点只有一个样本，熵为0。这样的话信息增益最大，算法就会以此属性作为最优划分属性。这显然与我们的意愿不同。因此引申出了增益比的思想。可以说，增益比就是为了矫正信息增益偏好的问题。为了使算法不偏向可取值较多的属性。\n$Gain_ratio(D,a)=\\frac{Gain(D,a)}{IV(a)}$\n其中$IV(a)=-\\sum_{\\mathrm{i}=1}^V\\frac{|D^i|}{|D|}log_2\\frac{|D^i|}{|D|}$，是a的固有属性\n2.4 均方误差\n$\\mathrm{MSE}=\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}$\n$n$：样本数量\n$y_i$：第 $i$ 个样本的真实值\n$\\hat{y}_i$：第 $i$ 个样本的预测值\n用于回归问题，衡量预测值和真实值的差异。MSE 越小，表示回归树的预测效果越好。\n3.算法分类\n\n4.将使用Python的scikit-learn库实现决策树\npip install scikit-learn\nfrom sklearn.tree import DecisionTreeClassifier #导入分类模型from sklearn.tree import DecisionTreeRegressor  #导入回归模型model_c = DecisionTreeClassifier(max_depth=10,max_features=5) #括号内加入要人工设定的参数model_r = DecisionTreeRegressor(max_depth=10,max_features=5)  #同样的，加入参数设定值，不仅局限于这几个model_c.fit(x_train,y_train)  #训练分类模型model_r.fit(x_train,y_train)  #训练回归模型result_c = model_c.predict(x_test)  #使用模型预测分类结果result_r = model_r.predict(x_test)  #使用模型预测回归结果\n参数解释参考:https://blog.csdn.net/GreenYang5277/article/details/104500739\n5.剪枝处理\n剪枝处理是防止决策树过拟合的有效手段。剪枝分为“预剪枝”和“后剪枝”。\n\n预剪枝：在决策树生成过程中，对每个结点在划分前先进性估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。它的位置在每一次生成分支节点前，先判断有没有必要生成，如没有必要，则停止划分。\n后剪枝：先从训练集生成一棵完整的决策树（相当于结束位置），然后自底向上的对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点，相当于将子树剪去。值得注意的是，后剪枝时要用到一个测试数据集合，如果存在某个叶子剪去后能使得在测试集上的准确度或其他测度不降低（不变得更坏），则剪去该叶子。\n理论上讲，后剪枝生成的决策树要比预剪枝生成的效果好，但是后剪枝在计算复杂度上比预剪枝高。\n\n","categories":["模型与算法"],"tags":["模型与算法","机器学习"]},{"title":"注意力机制","url":"/2025/07/02/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/","content":"注意力机制\n原论文：https://arxiv.org/pdf/1706.03762\n什么是注意力机制\n注意力机制就是让模型重点关注重要信息，忽略次要信息。注意力机制分为空间注意力和时间注意力，前者用于图像处理，后者用于自然语言处理.\n原理\nQuery：当前需要查询的目标，即当前输入的特征表示。\nKey：可以将每个单词的重要特征表示看作成 Key。\nValue：每个单词本身的特征向量看作为 Value，一般和 Key成对出现，也就是我们常说的&quot;键-值&quot;对。\n\n核心公式（原论文中）：\n$Attention(Q,K,V)=Softmax(\\frac{QK^\\top}{\\sqrt{d_k}})V$\n步骤：\n\n\n先根据 Query，Key计算两者的相关性，然后再通过 softmax 函数得到 注意力分数，使用 softmax 函数是为了使得所有的注意力分数在 [0,1] 之间，并且和为1。\n相关性公式一般表示如下：\n$score(q,k_i)=softmax(\\alpha(q,k_i))=\\frac{exp(\\alpha(q,k_i))}{\\sum_1^jexp(\\alpha(q,k_j))}$\n其中$\\alpha(q,k_{i})$有很多变体：\ne.g. 在加性注意力中\n$\\alpha(q,k_i)=w_v^Ttanh(W_qq+W_kk)$\nW_q：Query对应的可训练矩阵\nW_k: Key对应的可训练矩阵\nw_v^T: Value对应的可训练矩阵\n(tanh为双曲正切函数，作为一种常见的激活函数)\ne.g.在缩放点积注意力中\n$\\alpha(q,k_i)=\\frac{QK^T}{\\sqrt{d}}$\n其中d为Keys的维度大小，除以sqrt{d}是为了使方差变小，训练梯度更新时更稳定\n\n\n将注意力分数加权求和，得到带注意力分数的Value\n\n\n自注意力机制（Self-Attention Mechanism）\n\n2.1 Embedding 操作, 将向量x转化为a,a作为注意力机制的input data\n2.2 q, k 操作\n$q^i=W^qa^i$\n$k^i=W^ka^i$\n$v^i=W^va^i$\n一般用 $\\alpha_{1,i}=q^1\\cdot k^i/\\sqrt{d}$  表示 $a^{1}$ 与 $a^{i}$ 之间的关系，\n其中$\\mathrm{d}$表示 $\\mathrm{q}$和$\\mathrm{k}$ 矩阵的维度\n\n2.3 v操作\n$b^1=\\sum_i\\tilde{\\alpha}_{1,i}v^i$\n$b^2=\\sum_i\\tilde{\\alpha}_{2,i}v^i$\n以此类推\n\n多头注意力机制\nq,k操作\n这里以两头为例\n$q^{i,1}=W^{q,1}q^i$\n$q^{i,2}=W^{q,2}q^i$\nk也是同样的操作\nv操作\n与自注意力机制相同\n\n通道注意力机制\n通道注意力机制是通过计算每个通道channel的重要性程度；因此，常常被用在卷积神经网络里面。目前，比较经典的通道注意力机制方法就是SENet模型，SENet通过学习通道间的关系（每个通道的重要性），提升了网络在特征表示中的表达能力，进而提升了模型的性能。\nSENet介绍\n参考：https://zhuanlan.zhihu.com/p/631398525\n空间注意力机制\n通过引入注意力模块，使模型能够自适应地学习不同区域的注意力权重。这样，模型可以更加关注重要的图像区域，而忽略不重要的区域。其中，最为典型的是 CBAM（Convolutional Block Attention Module），CBAM 是一种结合了通道注意力和空间注意力的模型，旨在增强卷积神经网络对图像的关注能力。\n","categories":["-科研实习 -深度学习"],"tags":["深度学习"]},{"title":"调制与解调","url":"/2025/07/13/%E8%B0%83%E5%88%B6%E4%B8%8E%E8%A7%A3%E8%B0%83/","content":"1.基本概念\n调制时将基带信号搬移到高频载波，实现频谱搬移的过程。解调则是调制的逆过程。\n1.1 为什么要进行调制：\na.高频信号更容易收发传输，天线尺寸需要是波长的1/4，使用高频信号可以减小天线尺寸;\nb.无线频谱资源有限，需要在指定的频率上进行发射接收，调制实现频率复用\nc.增加信号在信道中传输时的抗干扰性能，提高频率效率\n1.2 调制中包含哪些信号类型\na.消息信号\nb.载波信号\nc.调制信号\n2.调制的类型\n\n模拟调制：指模拟消息信号直接调制在载波上，让载波的特性跟随其幅度进行变化。包括调幅（AM）、调相（PM）、调频（FM）、模拟脉冲调制（后面会讲）\n数字调制：指调制信号或者消息信号已经不在是模拟形式，而是进行了模数转换，将数字基带信号调制到载波上进行传输，它的优点有高抗噪性、高可用带宽和容许功率。\n数字调控由三种基本的方式：幅移键控(ASK)、频移键控(FSK)和相移键控(PSK)。它们分别对应于用载波（正弦波）的幅度、频率和相位来传递数字基带信号。（后面会仔细讲）\n3.解调的类型\n相干解调与非相干解调。相干解调（也被称为同步检波）适用于所有线性调制信号的解调。\n4.模拟调制与解调\n参考：https://blog.csdn.net/weixin_50493296/article/details/121048869\n4.1 幅度调制（线性调制）的原理\n\n$\\mathrm{S_m(t)=[m(t)\\cos\\omega_ct]*h(t)}$\n$\\mathrm{S}{\\mathrm{m}}(\\omega)=\\frac{1}{2}\\left[\\mathrm{M}(\\omega+\\omega{\\mathrm{c}})+\\mathrm{M}(\\omega-\\omega_{\\mathrm{c}})\\right]\\mathrm{H}(\\omega)$\n4.1.1 常规 调幅（AM）\n4.1.2 双边带调制（DSB-SC）\n4.1.3 单边带调制（SSB）\n4.1.4 残留边带调制（VSB）\n4.1.5 相干解调与包络检波\n4.2 非线性调制（角度调制）原理\n角度调制时FM和PM的总称，载波的幅度恒定，而频率或相位受调制，抗噪声性能优于幅度调制\n4.2.1 宽带 调频\n4.3 模拟脉冲调制\n5.数字调制\n\n5.1 ASK （幅移键控法）\n载波幅度是随着调制信号而变化的，分为2ASK（2进制调制）,MASK（多进制数字调制法）\n5.2 PSK（相移键控法）\n根据数字基带信号的两个电平使载波相位在两个不同的数值之间切换的一种相位调制方法。\n产生PSK信号的两种方法：\n\n\n调相法：将基带数字信号（双极性）与载波信号直接相乘的方法：\n\n\n选择法：用数字基带信号去对相位相差180度的两个载波进行选择。两个载波相位通常相差180度，此时称为反向键控（PSK）。\n\n\n5.3 FSK（频移键控法）\n载波信号的频率根据离散数字变化而变化，FSK 调制波的输出对于二进制高电平输入频率较高，对于二进制低电平输入频率较低。\n5.4 QAM（正交幅度调制法）\n利用正交载波对两路信号分别进行双边带抑制载波调幅形成的。通常有二进制 QAM，四进制QAM（16QAM），八进制QAM（64QAM）等。\n\n","categories":["信号处理"],"tags":["信号处理"]},{"title":"量化交易初尝-基于FMZ平台","url":"/2025/08/18/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E5%88%9D%E5%B0%9D-%E5%9F%BA%E4%BA%8EFMZ%E5%B9%B3%E5%8F%B0/","content":"量化交易是我第一次接触的领域，以下记录我的初尝经历。\n基于FMZ平台部署一个实盘交易\n部署托管者\n直接下载托管程序\n\n下载\n\nwget https://www.fmz.com/dist/robot_linux_amd64.tar.gz      \n\n\n解压\n\ntar -zxvf robot_linux_amd64.tar.gz\n\n添加执行权限\n\nchmod +x robot\n\nscreen 窗口运行\n\nscreen -S fmz_robot./robot -s node.fmz.com/120855418 -p 登录密码\nDocker 部署\n\n拉取镜像\n\ndocker pull fmzcom/docker:latest\n\n运行\n\ndocker run -d --name FMZDocker -e UID=120855418 -e PASSWORD=登录密码 fmzcom/docker:latest       \n至此，托管者部署成功（如下图），只需要建立实盘时选择托管者。\n\n关联交易所账户\n\n创建API\n进入你选择的交易平台（我以OKX为例），创建API，系统会自动生成API key和Secret key，并修改权限（允许读取和交易）\n关联交易所\nFMZ平台配置：\n\n&#123;          &quot;accessKey&quot;: &quot;API Key&quot;,  &quot;secretKey&quot;: &quot;Secret Key&quot;,  &quot;Passphras&quot;: &quot;password&quot;,   &#125;\n创建策略\n新建一个策略并选择你使用的语法，开始编写策略。\n以下是一个基于python编写的获取账户信息的策略，用于调试API是否可用。\ndef main():    account = exchange.GetAccount()  # 获取账户信息    Log(&quot;原始账户信息:&quot;, account)        if account is None:        Log(&quot;账户信息获取失败，API 或交易所对象未配置&quot;)    else:        # OKX 返回整数，需要除以 1e8        balance = account.Balance / 1e8        stocks = account.Stocks / 1e8        Log(&quot;可用余额:&quot;, balance, &quot;持仓:&quot;, stocks)\n以下是一个简单的基于python编写的策略，核心逻辑如下：\n用basePrice记录上一次的参考价格，当价格上涨超过 ratio 时用账户余额的一部分买入；当价格下跌超过 ratio 时用持仓的一部分卖出。\n每 5 分钟撤销一次所有挂单，每 2000 毫秒循环一次并更新日志。\nimport timebasePrice = -1ratio = 0.8acc = _C(exchange.GetAccount)lastCancelAll = 0minStocks = 0.1def CancelAll():    while True :         orders = _C(exchange.GetOrders)        for i in range(len(orders)) :            exchange.CancelOrder(orders[i][&quot;Id&quot;], orders[i])        if len(orders) == 0 :            break        Sleep(1000)def main():    global basePrice, acc, lastCancelAll    exchange.SetPrecision(4, 1)    while True:        ticker = _C(exchange.GetTicker)        if basePrice == -1 :            basePrice = ticker.Last        if ticker.Last - basePrice &gt; 0 and (ticker.Last - basePrice) / basePrice &gt; ratio :            acc = _C(exchange.GetAccount)            if acc.Balance * ratio / ticker.Last &gt; minStocks :                exchange.Buy(ticker.Last, acc.Balance * ratio / ticker.Last)                basePrice = ticker.Last        if ticker.Last - basePrice &lt; 0 and (basePrice - ticker.Last) / basePrice &gt; ratio :             acc = _C(exchange.GetAccount)            if acc.Stocks * ratio &gt; minStocks :                exchange.Sell(ticker.Last, acc.Stocks * ratio)                basePrice = ticker.Last        ts = time.time()        if ts - lastCancelAll &gt; 60 * 5 :            CancelAll()            lastCancelAll = ts         LogStatus(_D(), &quot;\\n&quot;, &quot;行情信息:&quot;, ticker, &quot;\\n&quot;, &quot;账户信息:&quot;, acc)        Sleep(200)  \n实际运用时需要注意：\n\n\n要根据自己的余额和所用平台的单次最小金额更改ratio。我当前余额很少，所以选择用80%的仓位下单，否则会下单失败。\n\n\nexchange.SetPrecision(4, 1) 用来设置价格和数量的小数位精度。我使用的交易对DOGE/USDT → 价格精度 0.0001，数量精度 0.1，所以设置为4和1。更换交易对时注意修改。\n\n\nminStocks = 0.1 表示最小下单数量，也要根据交易所和交易对更改。\n\n\n回测\n建议在跑实盘之前先运行回测验证逻辑。python支持本地回测，参考：https://www.fmz.com/bbs-topic/1687\n创建实盘\n选择运行策略和托管主机，配置合适的交易对和交易所，就可以跑实盘了。\n","categories":["量化交易"],"tags":["量化交易"]}]