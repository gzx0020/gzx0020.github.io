[{"title":"Driver,BSP和HAL","url":"/2025/07/15/Driver-BSP%E5%92%8CHAL/","content":"基本关系如下图所示\n1.驱动（Driver）驱动程序是直接与硬件设备交互的软件组件。它们为操作系统或应用程序提供控制硬件的接口。可以理解为驱动直接与硬件交互。最为底层。\n2.板级支持包（BSP, Board Support Package）是一套针对特定硬件系统的低级软件代码， 其主要作用是抽象硬件细节， 以便操作系统能够顺利运行在特定的硬件平台上。BSP 是高度硬件相关的，为一块板写的 BSP 通常不能直接用在另一块不同的板上，即使它们使用了相同的 MCU&#x2F;MPU（因为外围电路、引脚连接、时钟源等都可能不同）。\n3.硬件抽象层（HAL, Hardware Abstraction Layer）HAL是介于底层硬件和上层软件之间的一层抽象层，用于隐藏硬件的具体实现细节，提供统一的接口。包含一组通用的API接口，可以理解为定义好的一组标准的函数（如 HAL_UART_Transmit(), HAL_GPIO_WritePin(), HAL_ADC_Start()）来执行常见的硬件操作。\n目的是提供统一的、标准化的接口来访问某一类硬件功能（如 UART、I2C、GPIO、ADC、定时器等），屏蔽不同厂商、不同系列、甚至不同架构（如 ARM Cortex-M vs RISC-V）芯片的具体寄存器操作差异。        相对于BSP抽象层次更高，可移植性更高。\n以stm32HAL库开发为例，流程如下：\n应用程序    │    ↓ 调用统一APIHAL 层（如 HAL_UART_Transmit()）    │    ↓ 调用板级驱动或直接操作寄存器BSP 层（如 BSP_UART_Write() 或 直接写 UART-&gt;DR 寄存器）    │    ↓ 操作物理寄存器硬件寄存器（如 USART1-&gt;DR &#x3D; data）\n","categories":["嵌入式"]},{"title":"LoRA","url":"/2025/06/26/LoRA/","content":"一.LoRA原理\r\n参考：https://zhuanlan.zhihu.com/p/702629428 原论文：https://arxiv.org/pdf/2106.09685 LoRA(Low-Rank\r\nAdaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。\r\nLoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。\r\n1.1实现流程\r\n\r\n\r\n在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；\r\n\r\n用随机高斯分布初始化\r\nA，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵\r\nB；\r\n训练完成后，将 B 矩阵与 A\r\n矩阵相乘后合并预训练模型参数作为微调后的模型参数。\r\n\r\n具体来讲，预训练权重矩阵 W0 ∈ ℝd × d\r\n，\r\n将增量参数矩阵 ΔW\r\n，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式\r\nW0 + ΔW = W0 + BA\r\n其中 B ∈ ℝd × r\r\n，A ∈ ℝr × d\r\n，秩r远小于d\r\n给定输入.x ∈ ℝd\r\n,添加LoRA后的输出.h ∈ ℝd\r\nh = (W0 + ΔW)x = W0x + BAx\r\nΔh = BAx\r\n1.2LoRA参数合并系数\r\n实际实现时以以下形式合并，其中α为超参数\r\n$$\\mathbf{h}=(\\mathbf{W}_{0}+\\frac{\\alpha}{r}\\Delta\\mathbf{W})\\mathbf{x}$$\r\n系数$\\frac{\\alpha}{r}$越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合\r\n系数$\\frac{\\alpha}{r}$越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）\r\n一般来说，在给定任务上LoRA微调，让α为r的2倍数。\r\n1.3 LoRA的秩r如何选择\r\n目标：找到一个秩r，使BA无限接近ΔW的表达能力。\r\n秩r越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。\r\n","categories":["-科研实习 -RadioDiff微调"],"tags":["大模型微调"]},{"title":"Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption","url":"/2025/06/26/Phasic%20Content%20Fusing%20Diffusion%20Model%20with%20Directional%20Distribution%20Consistency%20for%20Few-Shot%20Model%20Adaption/","content":"Few-Shot\r\nPhasic\r\nContent Fusing Diffusion Model with Directional Distribution Consistency\r\nfor Few-Shot Model Adaption\r\nAbstract\r\n\r\n当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节\r\n引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）\r\n跨领域情景的结构一致性\r\n\r\nChallenges\r\n\r\noverfit\r\n细节学习阶段（t较小的时候）风格迁移失败\r\n现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转\r\n\r\nMethod\r\nTraining with Phasic\r\nContent Fusion\r\n在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合E(xA)和噪声z ∼ 𝒩(0, I)， Ê(xA) = m(t)E(xA) + (1 − m(t))z\r\n然后使用多个卷积块将 Ê(xA)\r\n与 E(xtA)\r\n融合，得到融合后的特征 E(xA, xtA)\r\n，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的\r\nxt − 1A\r\n#### 方向分布一致性损失函数 directional distribution consistency loss\r\n(DDC) 最终的损失函数由以下三个损失函数构成：\r\n\r\nDirectional distribution consistency loss\r\nℒDDC = ∥E(xA) + w, E(x0A → B)∥2\r\n其中w为方向向量，给定源分布 A = {x1A, ⋯xmA}\r\n和目标分布 B = {x1B, ⋯xmB}\r\n,特征空间中从源域中心到目标域中心的跨域方向向量w,\r\n$w=\\frac{1}{m}\\sum_{i=1}^mE(x_i^B)-\\frac{1}{n}\\sum_{i=1}^nE(x_i^A)$\r\nStyle loss\r\n$\\mathcal{L}_{style}=\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{l}w_{l}\\|G^{l}(x_{0}^{A\\to\r\nB})-G^{l}(x_{i}^{B})\\|^{2}$\r\n用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵\r\nDiffusion Loss\r\nℒdif = ||ϵθ(xtB, t) − ϵ||2\r\n\r\n最终的损失函数为：\r\nℒ = m(t)(1 − w(t))(λDDCℒDDC(xA, x0A → B) + λstyleℒstyle(x0A → B, xB)) + w(t)ℒdif(xB)\r\n迭代跨域结构引导\r\nIterative Cross-domain Structure Guidance(ICSG)\r\n需要进一步理解\r\n实验及评估过程\r\n相关概念\r\n图像翻译 Image-to-Image\r\nTranslation\r\n将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。\r\nGram矩阵\r\n原理\r\nn维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Gram\r\nmatrix)，很明显，这是一个对称矩阵。 输入图像的feature map为[ ch, h,\r\nw]。我们经过flatten（即是将h* w\r\n进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w,\r\nch]的矩阵。再对两个作内积得到Gram矩阵。\r\n应用\r\nGram matrix的应用-风格迁移： 1. 准备基准图像和风格图像\r\n\r\n使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图feature\r\nmap）\r\n分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像\r\n\r\n一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。\r\n消融实验 Ablation Study\r\n类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。\r\n","categories":["论文阅读笔记"],"tags":["Few-Shot"]},{"title":"Specialist Diffusion","url":"/2025/06/26/Specialist-Diffusion/","content":"Specialist\r\nDiffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image\r\nDiffusion Models to Learn Any Unseen Style\r\nhttps://arxiv.org/pdf/2211.12572\r\n主要内容\r\n这篇论文提出Specialist\r\nDiffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，content\r\nloss to facilitate content-style disentanglement，sparsely updating\r\ndiffusion time\r\nsteps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。\r\nData\r\nAugmentations for Text2Image Diffusion（数据增强）\r\nImage Augmentation\r\nText Prompt Augmentation\r\nCaption Retrieval\r\nAugmentation 标题搜索增强\r\nSynonym Augmentation\r\n同义词增强\r\nDoubled Augmentation\r\n双重增强\r\nContent Loss\r\nSparse Updating\r\n相关概念\r\n增强泄露问题 augmentation\r\nleakage\r\n生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。\r\n举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能\r\n“bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended”\r\n，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏”\r\n到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentation\r\nleakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的\r\n“虚假模式”，而非真实场景的合理特征，影响生成效果。\r\n正则化 Regularization\r\n正则化是用来防止模型过拟合而采取的手段，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大\r\n参考：https://blog.csdn.net/weixin_41960890/article/details/104891561\r\n","categories":["论文阅读笔记"],"tags":["Few-Shot"]},{"title":"week1","url":"/2025/05/20/week1/","content":"一致性模型（Consistency\r\nModels，CM）\r\nhttps://zhuanlan.zhihu.com/p/623402026\r\n一致性模型（Consistency\r\nModels，CM）主要解决扩散生成模型迭代采样过程缓慢的问题，支持一步采样快速生成和多步采样高精度生成，CM\r\n的本质就是将任何时间步的点映射到轨迹的起点。CM 的一个关键的性质是\r\nself-consistency 性：相同轨迹上的点映射到相同的初始点。\r\nSDE与ODE\r\n前向过程满足的SDE： $=(,t)t+g(t)(t) $ f:漂移因子 g:扩散因子\r\nw:维纳过程(标准布朗运动) score:∇xlog p(x)\r\n即概率密度对数的梯度\r\n朗之万动力学\r\n边缘概率密度\r\nscore matching\r\n逆向过程的SDE为： $\\mathrm{d}\\mathbf{x}=[\\mathbf{f}(\\mathbf{x},t)-g^2(t)\\nabla_\\mathbf{x}\\log\r\np_t(\\mathbf{x})]\\mathrm{d}t+g(t)\\mathrm{d}\\bar \\\\\r\n{\\mathbf{w}}(t)$\r\nODE：SDE去掉维纳过程，变成一个常微分方程\r\n$\\mathrm{d}\\mathbf{x}_t=\r\n\\begin{bmatrix}\r\nf(\\mathbf{x}_t,t)-\\frac{1}{2}g^2(t)\\nabla\\log p_t(\\mathbf{x}_t)\r\n\\end{bmatrix}\\mathrm{d}t$\r\n如何用神经网络训练一致性模型\r\n一致性函数 $f(\\mathbf{x}_t,t)=\r\n\\begin{cases}\r\n\\mathbf{x}_\\varepsilon, &amp; t=\\varepsilon \\\\\r\nf(\\mathbf{x}_{t^{\\prime}},t^{\\prime}), &amp; t\\in(\\varepsilon,T],\\forall\r\nt^{\\prime}\\in[\\varepsilon,T] &amp;\r\n\\end{cases}$\r\n一致性模型：即用神经网络模拟一致性函数的特性\r\n给定任意神经网络F, fθ(xt, t) = Cskip(t)xt + Cout(t)Fθ(xt, t)\r\n随t变化时C的变化\r\nEDM–Cin\r\n损失函数——相邻两个时间输出值差距最小化$\\mathcal{L}^N(\\theta)=\\mathbb{E}[\\|f_\\theta(\\mathbf{x}_{t_{n+1}},t_{n+1})-f_\\theta(\\hat{\\mathbf{x}}_{t_n},t_n)\\|_2^2]$\r\n再经过EMA,最终$\\mathcal{L}^N(\\theta,\\theta^-)=\\mathbb{E}[\\|f_\\theta(\\mathbf{x}_{t_{n+1}},t_{n+1})-f_{\\theta^-}(\\hat{\\mathbf{x}}_{t_n},t_n)\\|_2^2]$\r\n一致性蒸馏（简称CD，Consistency\r\nDistillation）——从已经学好的score function蒸馏\r\n\r\n已经有了score function sϕ(x(t), t)\r\n### 一致性训练(简称CT，Consistency Training)——从数据中直接学 \r\n用$\\nabla\\log\r\np_t(\\mathbf{x}_t)=-\\mathbb{E}\\left[\\frac{\\mathbf{x}_t-\\mathbf{x}}{t^2}|\\mathbf{x}_t\\right]$来代替一致性蒸馏中的已有的sore\r\nfuction\r\n如何通过一致性模型采样获得图像\r\n一步采样\r\n给定一个xt，带入一致性模型\r\n多步采样\r\n可提升图像质量\r\nSR3\r\nSR3 is an approach to image super resolution via iterative refinement\r\n通过迭代优化实现生成图像超分辨率\r\nkey words\r\n\r\niterative refinement\r\nboth faces and natural images\r\nbicubic interpolation\r\nflexibility inchoosing number of diffusion steps, and the noise\r\nschedule during inference\r\nFID\r\nrather than estimating the posterior mean, SR3 generates samples\r\nfrom the target posterior.\r\nconstant number of refinement steps (often no more than 100).\r\nonot requireanyauxiliaryobjective function inorder\r\ntoensureconsistencywith the low resolutioninputs\r\nour diffusion models do not provide a knob to control sample quality\r\nvs. sample diversity（如何平衡样本质量与样本多样性吗？）, and finding\r\nways to do so isinteresting avenue for future research.\r\n\r\n涉及知识点\r\n\r\nscore matching\r\nLangevin dynamics\r\nPSNR and SSIM\r\nresidual blocks\r\n级联结构\r\nNormalizing flows\r\nanti-aliasing\r\nImageNet\r\nDropout\r\n\r\n总结\r\n\r\n将LR作为条件输入\r\n不在取离散的t，而是将同样范围内连续t的采样值（即noise）输入\r\n或许可以减小推理步数，加快速度？\r\n级联 分阶段生成：\r\n第一阶段：使用无条件生成模型（如DDPM）生成低分辨率图像（如64×64）。\r\n第二阶段：将低分辨率图像输入第一个SR3模型，进行4倍上采样（64→256）。\r\n第三阶段：将256×256图像输入第二个SR3模型，再次4倍上采样至1024×1024。\r\n\r\n问题\r\n\r\n下采样操作，将 HR 图像的尺⼨减半，⽣成对应的 LR 图像\r\n下采样方式如何选择（是否采用SR3论文中提到的双三次插值？），以及为什么规定LR为HR尺寸减半后的结果\r\nSR3采用的是迭代优化实现图像超分辨率重建的方法，是否面临计算和时间成本高的问题，如何解决是否可以参考连续一致性模型的做法\r\n连续一致性模型有单步采样和多部采样两种方式，多部采样可以理解为牺牲速度换取高质量？是否可以再次基础上实现超分辨率重建？\r\n尝试https://github.com/openai/consistency_models 和https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement\r\n时遇到困难\r\n对数学公式的推导要掌握到什么程度？\r\n\r\n","categories":["科研实习周记"],"tags":["diffusion model","科研实习周记"]},{"title":"week2","url":"/2025/06/25/week2/","content":"diffusion model (李宏毅)笔记\r\n概念部分\r\n一般图像生成模型基本框架\r\ntext encoder → generation model → decoder\r\nFID(Frechet Inception\r\nDistance)\r\nFID是一种用于评估生成图像质量的度量标准\r\n\r\n特征提取 使用预训练的 Inception V3 模型（在 ImageNet\r\n数据集上训练的图像分类网络）作为特征提取器。输入图像（通常调整为 299×299\r\n的分辨率）会通过 Inception V3 前向传播，提取池化层（即 pool3\r\n层）的输出特征。这个特征是一个 2048 维的向量。\r\n特征分布假设 FID\r\n假设提取的特征向量服从多变量正态分布。对于真实图像集合X和生成图像集合G，分别计算特征的均值向量和协方差矩阵：\r\n真实图像特征均值 μr 协方差 Σr\r\n生成图像特征均值 μg 协方差 Σg\r\nFréchet 距离计算 Fréchet 距离用来衡量两个正态分布之间的差异FID = ∥μr − μg∥22 + Tr(Σr + Σg − 2(ΣrΣg)1/2)\r\n第一项衡量两个分布均值的欧几里得距离，表示分布中心的偏移，第二项衡量协方差矩阵的差异，反映分布形状和分散度的不同\r\n\r\n原理部分\r\nhttps://www.bilibili.com/video/BV14c411J7f2?spm_id_from=333.788.player.switch&amp;vd_source=257a40315247000b85510107fa6b747d&amp;p=4\r\n\r\n最大似然估计 https://zhuanlan.zhihu.com/p/55791843 \r\n扩散模型与能量模型，Score-Matching和SDE，ODE的关系 https://zhuanlan.zhihu.com/p/576779879\r\n\r\n疑问\r\n\r\n李宏毅认为噪声实际上不是一步一步加进x0的,而是一步实现的 \r\n但通过对一致性模型的学习，我了解到diffusion\r\nmodel的前向过程和逆向过程实际上都能表示为SDE过程，需要进行多次迭代，而consistency\r\nmodel就是为了解决这个问题，将SDE的随机项消除，转变为ODE过程，从而实现减少迭代次数，这是否与上图观点相悖？\r\n\r\n","categories":["科研实习周记"],"tags":["diffusion model","科研实习周记"]},{"title":"week4","url":"/2025/06/30/week4/","content":"一、LoRA微调\r\ntest1:\r\n将训练第二阶段注意力机制中的线性层’w_q’,‘w_k’,’w_v’替换为LoRA层\r\nlora_r: 8                    # LoRA秩大小lora_alpha: 16               # LoRA缩放因子 预训练模型只加载第二阶段扩散网络权重\r\n结果： _IncompatibleKeys 错误（缺少 encoder/decoder 层）\r\n可能原因：只加载了第二阶段模型，缺少 Autoencoder\r\n部分，无法将输入图像编码为潜在空间表示，无法将生成的潜在编码解码为图像\r\ntest2:\r\n由第一次尝试得，当只微调扩散网络本身时，仍需要\r\n\r\n先加载第一阶段Autoencoder\r\n再加载第二阶段扩散网络权重\r\n\r\n则test2总体流程为：\r\n\r\n加载完整的加载完整的扩散模型（含 Autoencoder + 扩散网络）\r\n注入 LoRA 参数到扩散网络的特定层\r\n冻结其他参数，随机选择20张图片训练 LoRA 层\r\n\r\n测试结果：\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n评估指标\r\n微调前\r\n微调后\r\n变化趋势\r\n变化率\r\n\r\n\r\n\r\n\r\nNMSE\r\n0.006882\r\n0.005570\r\n↓\r\n-19.06%\r\n\r\n\r\nRMSE\r\n0.029842\r\n0.026012\r\n↓\r\n-12.83%\r\n\r\n\r\nSSIM\r\n0.945097\r\n0.955175\r\n↑\r\n+1.07%\r\n\r\n\r\nPSNR (dB)\r\n30.574329\r\n31.882632\r\n↑\r\n+4.28%\r\n\r\n\r\n\r\n注意力机制\r\n原论文：https://arxiv.org/pdf/1706.03762\r\n什么是注意力机制\r\n注意力机制就是让模型重点关注重要信息，忽略次要信息。注意力机制分为空间注意力和时间注意力，前者用于图像处理，后者用于自然语言处理.\r\n原理\r\nQuery：当前需要查询的目标，即当前输入的特征表示。\r\nKey：可以将每个单词的重要特征表示看作成 Key。\r\nValue：每个单词本身的特征向量看作为 Value，一般和\r\nKey成对出现，也就是我们常说的”键-值”对。\r\n\r\n核心公式（原论文中）：\r\n$$\r\nAttention(Q,K,V)=Softmax(\\frac{QK^\\top}{\\sqrt{d_k}})V\r\n$$\r\n步骤：\r\n\r\n先根据 Query，Key计算两者的相关性，然后再通过 softmax 函数得到\r\n注意力分数，使用 softmax 函数是为了使得所有的注意力分数在 [0,1]\r\n之间，并且和为1。\r\n相关性公式一般表示如下：\r\n$$\r\nscore(q,k_i)=softmax(\\alpha(q,k_i))=\\frac{exp(\\alpha(q,k_i))}{\\sum_1^jexp(\\alpha(q,k_j))}\r\n$$\r\n其中α(q, ki)有很多变体：\r\ne.g. 在加性注意力中\r\nα(q, ki) = wvTtanh(Wqq + Wkk)\r\nW_q：Query对应的可训练矩阵\r\nW_k: Key对应的可训练矩阵\r\nw_v^T: Value对应的可训练矩阵\r\n(tanh为双曲正切函数，作为一种常见的激活函数)\r\ne.g.在缩放点积注意力中\r\n$$\r\n\\alpha(q,k_i)=\\frac{QK^T}{\\sqrt{d}}\r\n$$\r\n其中d为Keys的维度大小，除以sqrt{d}是为了使方差变小，训练梯度更新时更稳定\r\n将注意力分数加权求和，得到带注意力分数的Value\r\n\r\n自注意力机制（Self-Attention\r\nMechanism）\r\n\r\n2.1 Embedding 操作, 将向量x转化为a,a作为注意力机制的input data\r\n2.2 q, k 操作\r\nqi = Wqai\r\nki = Wkai\r\nvi = Wvai\r\n多头注意力机制（Multi-head\r\nSelf-Attention Machanism）\r\n参考：https://zhuanlan.zhihu.com/p/631398525 ##\r\n通道注意力机制\r\n空间注意力机制\r\n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"week3","url":"/2025/06/30/week3/","content":"Few-Shot\r\nPhasic\r\nContent Fusing Diffusion Model with Directional Distribution Consistency\r\nfor Few-Shot Model Adaption\r\nhttps://arxiv.org/pdf/2309.03729\r\nAbstract\r\n\r\n当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节\r\n引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）\r\n跨领域情景的结构一致性\r\n\r\nChallenges\r\n\r\noverfit\r\n细节学习阶段（t较小的时候）风格迁移失败\r\n现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转\r\n\r\nMethod\r\nTraining with Phasic\r\nContent Fusion\r\n在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合E(xA)和噪声z ∼ 𝒩(0, I)，\r\nÊ(xA) = m(t)E(xA) + (1 − m(t))z\r\n然后使用多个卷积块将 Ê(xA)\r\n与 E(xtA)\r\n融合，得到融合后的特征 E(xA, xtA)\r\n，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的\r\nxt − 1A\r\n方向分布一致性损失函数\r\ndirectional distribution consistency loss (DDC)\r\n最终的损失函数由以下三个损失函数构成：\r\n\r\nDirectional distribution consistency loss\r\nℒDDC = ∥E(xA) + w, E(x0A → B)∥2\r\n其中w为方向向量，给定源分布 A = {x1A, ⋯xmA}\r\n和目标分布 B = {x1B, ⋯xmB}\r\n,特征空间中从源域中心到目标域中心的跨域方向向量w,\r\n$w=\\frac{1}{m}\\sum_{i=1}^mE(x_i^B)-\\frac{1}{n}\\sum_{i=1}^nE(x_i^A)$\r\nStyle loss\r\n$\\mathcal{L}_{style}=\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{l}w_{l}\\|G^{l}(x_{0}^{A\\to\r\nB})-G^{l}(x_{i}^{B})\\|^{2}$\r\n用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵\r\nDiffusion Loss\r\nℒdif = ||ϵθ(xtB, t) − ϵ||2\r\n\r\n最终的损失函数为：\r\nℒ = m(t)(1 − w(t))(λDDCℒDDC(xA, x0A → B) + λstyleℒstyle(x0A → B, xB)) + w(t)ℒdif(xB)\r\n迭代跨域结构引导\r\nIterative Cross-domain Structure Guidance(ICSG)\r\n需要进一步理解\r\n实验及评估过程\r\n相关概念\r\n图像翻译 Image-to-Image\r\nTranslation\r\n将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。\r\nGram矩阵\r\n原理\r\nn维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Gram\r\nmatrix)，很明显，这是一个对称矩阵。 输入图像的feature map为[ ch, h,\r\nw]。我们经过flatten（即是将h* w\r\n进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w,\r\nch]的矩阵。再对两个作内积得到Gram矩阵。 ##### 应用\r\nGram matrix的应用-风格迁移：\r\n\r\n准备基准图像和风格图像\r\n使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图feature\r\nmap）\r\n分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像\r\n\r\n一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。\r\n消融实验 Ablation Study\r\n类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。\r\nSpecialist\r\nDiffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image\r\nDiffusion Models to Learn Any Unseen Style\r\nhttps://arxiv.org/pdf/2211.12572\r\n主要内容\r\n这篇论文提出Specialist\r\nDiffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，content\r\nloss to facilitate content-style disentanglement，sparsely updating\r\ndiffusion time\r\nsteps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。\r\nData\r\nAugmentations for Text2Image Diffusion（数据增强）\r\nImage Augmentation\r\nText Prompt Augmentation\r\nCaption Retrieval\r\nAugmentation 标题搜索增强\r\nSynonym Augmentation\r\n同义词增强\r\nDoubled Augmentation\r\n双重增强\r\nContent Loss\r\nSparse Updating\r\n相关概念\r\n增强泄露问题 augmentation\r\nleakage\r\n生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。\r\n举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能\r\n“bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended”\r\n，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏”\r\n到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentation\r\nleakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的\r\n“虚假模式”，而非真实场景的合理特征，影响生成效果。\r\n正则化 Regularization\r\n正则化是用来防止模型过拟合而采取的手段，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大\r\n参考：https://blog.csdn.net/weixin_41960890/article/details/104891561\r\n一.LoRA原理\r\n参考：https://zhuanlan.zhihu.com/p/702629428 原论文：https://arxiv.org/pdf/2106.09685 LoRA(Low-Rank\r\nAdaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。\r\nLoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。\r\n1.1实现流程\r\n\r\n\r\n在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；\r\n\r\n用随机高斯分布初始化\r\nA，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵\r\nB；\r\n训练完成后，将 B 矩阵与 A\r\n矩阵相乘后合并预训练模型参数作为微调后的模型参数。\r\n\r\n具体来讲，预训练权重矩阵 W0 ∈ ℝd × d\r\n，\r\n将增量参数矩阵 ΔW\r\n，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式\r\nW0 + ΔW = W0 + BA\r\n其中 B ∈ ℝd × r\r\n，A ∈ ℝr × d\r\n，秩r远小于d\r\n给定输入.x ∈ ℝd\r\n,添加LoRA后的输出.h ∈ ℝd\r\nh = (W0 + ΔW)x = W0x + BAx\r\nΔh = BAx\r\n1.2LoRA参数合并系数\r\n实际实现时以以下形式合并，其中α为超参数\r\n$\\mathbf{h}=(\\mathbf{W}_{0}+\\frac{\\alpha}{r}\\Delta\\mathbf{W})\\mathbf{x}$\r\n系数$\\frac{\\alpha}{r}$越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合\r\n系数$\\frac{\\alpha}{r}$越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）\r\n一般来说，在给定任务上LoRA微调，让α为r的2倍数。\r\n1.3 LoRA的秩r如何选择\r\n目标：找到一个秩r，使BA无限接近ΔW的表达能力。\r\n秩r越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。\r\n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"week5","url":"/2025/07/13/week5/","content":"一、论文阅读笔记\r\nFew-shot Image Generation with Diffusion Models\r\n论文：https://arxiv.org/pdf/2211.03264\r\n主要内容：\r\n提出Few-shot Diffusion Models (FDM)，在仅使用 10\r\n张训练图像时，就能生成具有合理多样性和质量的图像。\r\n主要挑战\r\n过拟合和模式崩溃（模型只能生成训练集中见过的少数几种样本）\r\n核心方法\r\n结构感知数据增强\r\n(Structure-Aware Data Augmentation)\r\n使用预训练的CLIP模型提取图像的语义特征，然后基于这些特征计算图像之间的相似性，\r\nCLIP相似度计算：$s_{ij}=\\frac{\\phi(I_i)\\cdot\\phi(I_j)}{\\|\\phi(I_i)\\|\\|\\phi(I_j)\\|}$\r\n其中 ϕ(⋅) 是CLIP图像编码器，sij ∈ [−1, 1]表示图像\r\nIi 和\r\nIj\r\n的语义相似度\r\n相似度高的图像对：应用更强的几何变换（如大幅旋转、裁剪），能提供更多样的“视角”而不会完全破坏结构。\r\n相似度低的图像对：应用较弱的变换，避免破坏其各自独特的结构信息。\r\n自适应变换强度: λij = λmin + (λmax − λmin)⋯ij\r\nλmin和λmax是最小/最大变换强度，相似度越高，变换强度越大\r\n层级优化机制\r\n(Hierarchical Optimization)\r\nFDM 将扩散模型（如DDPM）的UNet结构划分为两个层级：\r\n\r\n基础层：负责捕捉图像的全局结构和基本语义（一般是UNet的深层/瓶颈层）\r\n细节层：负责生成图像的局部细节（一般是UNet的浅层）\r\n\r\n采用交替优化策略： 阶段一 (Freeze Detail\r\nLayers)：冻结西接层参数，只优化基础层 阶段二 (Freeze Base\r\nLayers)：冻结基础层参数，只优化细节层 ### 自适应卷积模块 (Adaptive\r\nConvolution Module)\r\n引入自适应卷积模块，根据输入特征图动态生成卷积核的偏移量 (offset)\r\n和调制标量 (modulation scalar) 偏移量：\r\n卷积核的采样位置根据输入内容进行微调\r\nΔpk = foffset(F; ϕ)\r\nfoffset是轻量子网络，F是输入特征图\r\n调制标量： 动态调整卷积核的权重，增强模型对输入变化的适应能力\r\nmk = σ(gmod(F; ψ))\r\no\r\n是sigmoid激活函数，限制输出在(0,1)范围\r\n自适应卷积公式： $\\mathbf{y}(p)=\\sum_{k=1}^K\\mathbf{w}_k\\cdot\\mathbf{F}(p+p_k+\\Delta\r\np_k)\\cdot m_k$\r\n模式崩溃\r\n对于某一个训练数据集，其中样本的概率分布为一个简单的一维高斯混合分布，包含两个峰，如下图\r\n\r\n模式崩溃问题是针对于生成样本的多样性，即生成的样本大量重复类似，如下图\r\n\r\n虽然生成样本的质量比较高，但是生成器完全没有捕捉到右边的峰的模式。\r\n解决思路：\r\n参考：https://cloud.tencent.com/developer/article/1522756\r\n二、代码改进\r\n改进代码，\r\n（1）由原来只替换注意力层改进为替换UNet的所有线性层和1x1卷积层\r\n（2）改进数据集的选择，原来是随机挑选了10个样本训练lora参数，应改进为挑选部分dpm和少量的irt4_car样本去训练\r\n7.9遇到的问题：替换Swin Transformer中的层，需要访问weight属性\r\n尝试解决 （1）：跳过Swin Transformer中的层 （2）：当win\r\nTransformer访问qkv.weight时，返回原始层的权重\r\n7.12 解决了LoRA注入失败的问题 下一步：测试训练效果\r\n改进用于微调的样本的选择\r\n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"串口重定向","url":"/2025/07/08/%E4%B8%B2%E5%8F%A3%E9%87%8D%E5%AE%9A%E5%90%91/","content":"stm32串口重定向HAL库\n#include &lt;stdio.h&gt;// 包含标准输入输出头文件 int fputc(int ch,FILE *f)&#123;//采用轮询方式发送1字节数据，超时时间设置为无限等待HAL_UART_Transmit(&amp;huart1,(uint8_t *)&amp;ch,1,HAL_MAX_DELAY);return ch;&#125;int fgetc(FILE *f)&#123;uint8_t ch;// 采用轮询方式接收 1字节数据，超时时间设置为无限等待HAL_UART_Receive( &amp;huart1,(uint8_t*)&amp;ch,1, HAL_MAX_DELAY );return ch;&#125;\n","categories":["-嵌入式 -单片机 -stm32"],"tags":["stm32"]},{"title":"使用循环缓冲区进行串口数据解析","url":"/2025/06/29/%E4%BD%BF%E7%94%A8%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E8%A1%8C%E4%B8%B2%E5%8F%A3%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/","content":"stm32cubemx配置开启串口收发异步模式，开启串口空闲中断\n代码实现#include &quot;command.h&quot;// 指令的最小长度#define COMMAND_MIN_LENGTH 4// 循环缓冲区大小#define BUFFER_SIZE 128// 循环缓冲区uint8_t buffer[BUFFER_SIZE];// 循环缓冲区读索引uint8_t readIndex = 0;// 循环缓冲区写索引uint8_t writeIndex = 0;/*** @brief 增加读索引* @param length 要增加的长度*/void Command_AddReadIndex(uint8_t length) &#123;    readIndex += length;    readIndex %= BUFFER_SIZE;&#125;/*** @brief 读取第i位数据 超过缓存区长度自动循环* @param i 要读取的数据索引*/uint8_t Command_Read(uint8_t i) &#123;    uint8_t index = i % BUFFER_SIZE;    return buffer[index];&#125;/*** @brief 计算未处理的数据长度* @return 未处理的数据长度* @retval 0 缓冲区为空* @retval 1~BUFFER_SIZE-1 未处理的数据长度* @retval BUFFER_SIZE 缓冲区已满*///uint8_t Command_GetLength() &#123;//  // 读索引等于写索引时，缓冲区为空//  if (readIndex == writeIndex) &#123;//    return 0;//  &#125;//  // 如果缓冲区已满,返回BUFFER_SIZE//  if (writeIndex + 1 == readIndex || (writeIndex == BUFFER_SIZE - 1 &amp;&amp; readIndex == 0)) &#123;//    return BUFFER_SIZE;//  &#125;//  // 如果缓冲区未满,返回未处理的数据长度//  if (readIndex &lt;= writeIndex) &#123;//    return writeIndex - readIndex;//  &#125; else &#123;//    return BUFFER_SIZE - readIndex + writeIndex;//  &#125;//&#125;uint8_t Command_GetLength() &#123;    return (writeIndex + BUFFER_SIZE - readIndex) % BUFFER_SIZE;&#125;/*** @brief 计算缓冲区剩余空间* @return 剩余空间* @retval 0 缓冲区已满* @retval 1~BUFFER_SIZE-1 剩余空间* @retval BUFFER_SIZE 缓冲区为空*/uint8_t Command_GetRemain() &#123;    return BUFFER_SIZE - Command_GetLength();&#125;/*** @brief 向缓冲区写入数据* @param data 要写入的数据指针* @param length 要写入的数据长度* @return 写入的数据长度*/uint8_t Command_Write(uint8_t *data, uint8_t length) &#123;    // 如果缓冲区不足 则不写入数据 返回0    if (Command_GetRemain() &lt; length) &#123;        return 0;    &#125;    // 使用memcpy函数将数据写入缓冲区    if (writeIndex + length &lt; BUFFER_SIZE) &#123;        memcpy(buffer + writeIndex, data, length);        writeIndex += length;    &#125; else &#123;        uint8_t firstLength = BUFFER_SIZE - writeIndex;        memcpy(buffer + writeIndex, data, firstLength);        memcpy(buffer, data + firstLength, length - firstLength);        writeIndex = length - firstLength;    &#125;    return length;&#125;/*** @brief 尝试获取一条指令* @param command 指令存放指针* @return 获取的指令长度* @retval 0 没有获取到指令*/uint8_t Command_GetCommand(uint8_t *command) &#123;    // 寻找完整指令    while (1) &#123;        // 如果缓冲区长度小于COMMAND_MIN_LENGTH 则不可能有完整的指令        if (Command_GetLength() &lt; COMMAND_MIN_LENGTH) &#123;        return 0;        &#125;        // 如果不是包头 则跳过 重新开始寻找        if (Command_Read(readIndex) != 0xAA) &#123;        Command_AddReadIndex(1);        continue;        &#125;        // 如果缓冲区长度小于指令长度 则不可能有完整的指令        uint8_t length = Command_Read(readIndex + 1);        if (Command_GetLength() &lt; length) &#123;        return 0;        &#125;        // 如果校验和不正确 则跳过 重新开始寻找        uint8_t sum = 0;        for (uint8_t i = 0; i &lt; length - 1; i++) &#123;        sum += Command_Read(readIndex + i);        &#125;        if (sum != Command_Read(readIndex + length - 1)) &#123;        Command_AddReadIndex(1);        continue;        &#125;        // 如果找到完整指令 则将指令写入command 返回指令长度        for (uint8_t i = 0; i &lt; length; i++) &#123;        command[i] = Command_Read(readIndex + i);        &#125;        Command_AddReadIndex(length);        return length;    &#125;&#125;\n\n头文件：\n#ifndef INC_COMMAND_H_#define INC_COMMAND_H_#include &quot;main.h&quot;#include &lt;string.h&gt;uint8_t Command_Write(uint8_t *data, uint8_t length);uint8_t Command_GetCommand(uint8_t *command);#endif /* INC_COMMAND_H_ */\n\nmain.c:\n/* Private define ------------------------------------------------------------*//* USER CODE BEGIN PD */uint8_t readBuffer[10];/* USER CODE END PD */\n\n/* USER CODE BEGIN 0 */void HAL_UARTEx_RxEventCallback(UART_HandleTypeDef *huart, uint16_t Size)&#123;\tif (huart == &amp;huart2)&#123;\t\tCommand_Write(readBuffer, Size);\t\tHAL_UARTEx_ReceiveToIdle_IT(&amp;huart2, readBuffer, sizeof(readBuffer));\t&#125;&#125;/* USER CODE END 0 */\n\n/* USER CODE BEGIN 2 */HAL_UARTEx_ReceiveToIdle_IT(&amp;huart2, readBuffer, sizeof(readBuffer));uint8_t command[50];int commandLength = 0;/* USER CODE END 2 *//* Infinite loop *//* USER CODE BEGIN WHILE */while (1)&#123;    commandLength = Command_GetCommand(command);    if (commandLength != 0)&#123;        HAL_UART_Transmit(&amp;huart2, command, commandLength, HAL_MAX_DELAY);        for (int i = 2; i &lt; commandLength - 1; i += 2)&#123;            GPIO_PinState state = GPIO_PIN_SET;            if (command[i + 1] == 0x00)&#123;                state = GPIO_PIN_RESET;            &#125;            if (command[i] == 0x01)&#123;                HAL_GPIO_WritePin(RED_GPIO_Port, RED_Pin, state);            &#125;else if (command[i] == 0x02)&#123;                HAL_GPIO_WritePin(GREEN_GPIO_Port, GREEN_Pin, state);            &#125;else if (command[i] == 0x03)&#123;                HAL_GPIO_WritePin(BLUE_GPIO_Port, BLUE_Pin, state);            &#125;        &#125;    &#125;/* USER CODE END WHILE *//* USER CODE BEGIN 3 */&#125;\n","categories":["-嵌入式 -单片机 -stm32"],"tags":["stm32"]},{"title":"决策树","url":"/2025/07/15/%E5%86%B3%E7%AD%96%E6%A0%91/","content":"1.决策树介绍\r\n决策树（Decision\r\nTree）是一种以树形数据结构来展示决策规则和分类结果的模型，代表对象属性和对象值之间的一种映射关系。\r\n以下图为例：\r\n\r\n一个决策树包含三种类型的节点：\r\n1.决策节点：通常用矩形框来表示\r\n2.机会节点：通常用圆圈来表示\r\n3.终结节点：通常用三角形来表示\r\n构建决策树的一般流程如下图：\r\n\r\n2.决策树的构建标准\r\n2.1 信息增益\r\n2.1.1 信息熵\r\n$H\\left(S\\right)=-\\sum_{i=1}^{c}p_{i}\\log_{2}\\left(p_{i}\\right)$\r\n其中，S 表示样本集，C 表示样本集合中类别个数（只含有正负样本，则\r\nC=2），pᵢ表示第 i 个类的概率，（pᵢ可由类别 i\r\n中含有样本的个数除以总样本数得到）\r\n取值范围：0 ≤ H(X) ≤ log2n\r\n即所有结果等概率时熵最大\r\n直观理解：不确定性越大，信息熵越大。\r\n2.1.2 条件熵\r\nH(X|Y) = −∑x, yp(x, y)log (p(x|y))\r\n条件熵H(X|Y)表示在移植随机变量Y的条件下，随机变量X的不确定性。\r\n\r\n\r\n举例说明条件熵\r\n\r\n2.1.3 信息增益\r\n信息增益是知道了某个条件后，事件不确定性降低的幅度。信息增益是非对称的，用以度量两种概率分布P和Q的差异，从P到Q的信息增益通常不等于从Q到P的信息增益。\r\n公式：IG(S, A) = H(S) − H(S|A)\r\n表示特征 A\r\n带来的不确定性减少量\r\n2.2 基尼系数\r\n基尼系数可以在样本集中随机抽出两个样本不同类别的概率。\r\n数据集的基尼系数：$Gini(D)=\\sum_{k=1}^n\\sum_{k\\prime\\neq\r\nk}p_kp_{k\\prime}=1-\\sum_{k=1}^\\mathrm{n}p_k^2$\r\npk表示第k类样本在数据集中的比例\r\n值域：[0, 0.5]，（二分类时最大值为\r\n0.5，K分类时最大为1-1/K）\r\n特征划分后的加权基尼系数：$Gini(S,A)=\\sum_{v=1}^m\\frac{|S_v|}{|S|}\\cdot\r\nGini(S_v)$\r\nS：特征A取第v个值时对应的子集\r\n$\\frac{|S_{v}|}{|S|}$：子集的样本权重\r\nGini(Sv)：\r\n子集的基尼系数\r\n2.3 增益比\r\n信息增益比较偏好可取值较多的属性，比如我们的样本有一个属性叫序号，每一个样本都具有一个单独的序号，因此使用序号划分后，每个子结点只有一个样本，熵为0。这样的话信息增益最大，算法就会以此属性作为最优划分属性。这显然与我们的意愿不同。因此引申出了增益比的思想。可以说，增益比就是为了矫正信息增益偏好的问题。为了使算法不偏向可取值较多的属性。\r\n$Gain_ratio(D,a)=\\frac{Gain(D,a)}{IV(a)}$\r\n其中$IV(a)=-\\sum_{\\mathrm{i}=1}^V\\frac{|D^i|}{|D|}log_2\\frac{|D^i|}{|D|}$，是a的固有属性\r\n2.4 均方误差\r\n$\\mathrm{MSE}=\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^{2}$\r\nn：样本数量\r\nyi：第\r\ni 个样本的真实值\r\nŷi：第\r\ni 个样本的预测值\r\n用于回归问题，衡量预测值和真实值的差异。MSE\r\n越小，表示回归树的预测效果越好。\r\n3.算法分类\r\n\r\n4.将使用Python的scikit-learn库实现决策树\r\npip install scikit-learn\r\nfrom sklearn.tree import DecisionTreeClassifier #导入分类模型from sklearn.tree import DecisionTreeRegressor  #导入回归模型model_c = DecisionTreeClassifier(max_depth=10,max_features=5) #括号内加入要人工设定的参数model_r = DecisionTreeRegressor(max_depth=10,max_features=5)  #同样的，加入参数设定值，不仅局限于这几个model_c.fit(x_train,y_train)  #训练分类模型model_r.fit(x_train,y_train)  #训练回归模型result_c = model_c.predict(x_test)  #使用模型预测分类结果result_r = model_r.predict(x_test)  #使用模型预测回归结果\r\n参数解释参考:https://blog.csdn.net/GreenYang5277/article/details/104500739\r\n5.剪枝处理\r\n剪枝处理是防止决策树过拟合的有效手段。剪枝分为“预剪枝”和“后剪枝”。\r\n\r\n预剪枝：在决策树生成过程中，对每个结点在划分前先进性估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。它的位置在每一次生成分支节点前，先判断有没有必要生成，如没有必要，则停止划分。\r\n后剪枝：先从训练集生成一棵完整的决策树（相当于结束位置），然后自底向上的对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点，相当于将子树剪去。值得注意的是，后剪枝时要用到一个测试数据集合，如果存在某个叶子剪去后能使得在测试集上的准确度或其他测度不降低（不变得更坏），则剪去该叶子。\r\n理论上讲，后剪枝生成的决策树要比预剪枝生成的效果好，但是后剪枝在计算复杂度上比预剪枝高。\r\n\r\n","categories":["模型与算法"],"tags":["模型与算法","机器学习"]},{"title":"注意力机制","url":"/2025/07/02/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/","content":"注意力机制\r\n原论文：https://arxiv.org/pdf/1706.03762\r\n什么是注意力机制\r\n注意力机制就是让模型重点关注重要信息，忽略次要信息。注意力机制分为空间注意力和时间注意力，前者用于图像处理，后者用于自然语言处理.\r\n原理\r\nQuery：当前需要查询的目标，即当前输入的特征表示。\r\nKey：可以将每个单词的重要特征表示看作成 Key。\r\nValue：每个单词本身的特征向量看作为 Value，一般和\r\nKey成对出现，也就是我们常说的”键-值”对。\r\n\r\n核心公式（原论文中）：\r\n$Attention(Q,K,V)=Softmax(\\frac{QK^\\top}{\\sqrt{d_k}})V$\r\n步骤：\r\n\r\n先根据 Query，Key计算两者的相关性，然后再通过 softmax 函数得到\r\n注意力分数，使用 softmax 函数是为了使得所有的注意力分数在 [0,1]\r\n之间，并且和为1。\r\n相关性公式一般表示如下：\r\n$score(q,k_i)=softmax(\\alpha(q,k_i))=\\frac{exp(\\alpha(q,k_i))}{\\sum_1^jexp(\\alpha(q,k_j))}$\r\n其中α(q, ki)有很多变体：\r\ne.g. 在加性注意力中\r\nα(q, ki) = wvTtanh(Wqq + Wkk)\r\nW_q：Query对应的可训练矩阵\r\nW_k: Key对应的可训练矩阵\r\nw_v^T: Value对应的可训练矩阵\r\n(tanh为双曲正切函数，作为一种常见的激活函数)\r\ne.g.在缩放点积注意力中\r\n$\\alpha(q,k_i)=\\frac{QK^T}{\\sqrt{d}}$\r\n其中d为Keys的维度大小，除以sqrt{d}是为了使方差变小，训练梯度更新时更稳定\r\n将注意力分数加权求和，得到带注意力分数的Value\r\n\r\n自注意力机制（Self-Attention\r\nMechanism）\r\n\r\n2.1 Embedding 操作, 将向量x转化为a,a作为注意力机制的input data\r\n2.2 q, k 操作\r\nqi = Wqai\r\nki = Wkai\r\nvi = Wvai\r\n一般用 $\\alpha_{1,i}=q^1\\cdot\r\nk^i/\\sqrt{d}$ 表示 a1 与 ai\r\n之间的关系，\r\n其中d表示 q和k\r\n矩阵的维度\r\n\r\n2.3 v操作\r\nb1 = ∑iα̃1, ivi\r\nb2 = ∑iα̃2, ivi\r\n以此类推\r\n\r\n多头注意力机制\r\nq,k操作\r\n这里以两头为例\r\nqi, 1 = Wq, 1qi\r\nqi, 2 = Wq, 2qi\r\nk也是同样的操作\r\nv操作\r\n与自注意力机制相同\r\n\r\n通道注意力机制\r\n通道注意力机制是通过计算每个通道channel的重要性程度；因此，常常被用在卷积神经网络里面。目前，比较经典的通道注意力机制方法就是SENet模型，SENet通过学习通道间的关系（每个通道的重要性），提升了网络在特征表示中的表达能力，进而提升了模型的性能。\r\nSENet介绍\r\n参考：https://zhuanlan.zhihu.com/p/631398525\r\n空间注意力机制\r\n通过引入注意力模块，使模型能够自适应地学习不同区域的注意力权重。这样，模型可以更加关注重要的图像区域，而忽略不重要的区域。其中，最为典型的是\r\nCBAM（Convolutional Block Attention Module），CBAM\r\n是一种结合了通道注意力和空间注意力的模型，旨在增强卷积神经网络对图像的关注能力。\r\n","categories":["-科研实习 -深度学习"],"tags":["深度学习"]},{"title":"调制与解调","url":"/2025/07/13/%E8%B0%83%E5%88%B6%E4%B8%8E%E8%A7%A3%E8%B0%83/","content":"1.基本概念\r\n调制时将基带信号搬移到高频载波，实现频谱搬移的过程。解调则是调制的逆过程。\r\n1.1 为什么要进行调制：\r\na.高频信号更容易收发传输，天线尺寸需要是波长的1/4，使用高频信号可以减小天线尺寸;\r\nb.无线频谱资源有限，需要在指定的频率上进行发射接收，调制实现频率复用\r\nc.增加信号在信道中传输时的抗干扰性能，提高频率效率\r\n1.2 调制中包含哪些信号类型\r\na.消息信号\r\nb.载波信号\r\nc.调制信号\r\n2.调制的类型\r\n\r\n模拟调制：指模拟消息信号直接调制在载波上，让载波的特性跟随其幅度进行变化。包括调幅（AM）、调相（PM）、调频（FM）、模拟脉冲调制（后面会讲）\r\n数字调制：指调制信号或者消息信号已经不在是模拟形式，而是进行了模数转换，将数字基带信号调制到载波上进行传输，它的优点有高抗噪性、高可用带宽和容许功率。\r\n数字调控由三种基本的方式：幅移键控(ASK)、频移键控(FSK)和相移键控(PSK)。它们分别对应于用载波（正弦波）的幅度、频率和相位来传递数字基带信号。（后面会仔细讲）\r\n3.解调的类型\r\n相干解调与非相干解调。相干解调（也被称为同步检波）适用于所有线性调制信号的解调。\r\n4.模拟调制与解调\r\n参考：https://blog.csdn.net/weixin_50493296/article/details/121048869\r\n4.1 幅度调制（线性调制）的原理\r\n\r\nSm(t) = [m(t)cos ωct] * h(t)\r\n$\\mathrm{S}_{\\mathrm{m}}(\\omega)=\\frac{1}{2}\\left[\\mathrm{M}(\\omega+\\omega_{\\mathrm{c}})+\\mathrm{M}(\\omega-\\omega_{\\mathrm{c}})\\right]\\mathrm{H}(\\omega)$\r\n4.1.1 常规 调幅（AM）\r\n4.1.2 双边带调制（DSB-SC）\r\n4.1.3 单边带调制（SSB）\r\n4.1.4 残留边带调制（VSB）\r\n4.1.5 相干解调与包络检波\r\n4.2 非线性调制（角度调制）原理\r\n角度调制时FM和PM的总称，载波的幅度恒定，而频率或相位受调制，抗噪声性能优于幅度调制\r\n4.2.1 宽带 调频\r\n4.3 模拟脉冲调制\r\n5.数字调制\r\n\r\n5.1 ASK （幅移键控法）\r\n载波幅度是随着调制信号而变化的，分为2ASK（2进制调制）,MASK（多进制数字调制法）\r\n5.2 PSK（相移键控法）\r\n根据数字基带信号的两个电平使载波相位在两个不同的数值之间切换的一种相位调制方法。\r\n产生PSK信号的两种方法：\r\n\r\n调相法：将基带数字信号（双极性）与载波信号直接相乘的方法：\r\n选择法：用数字基带信号去对相位相差180度的两个载波进行选择。两个载波相位通常相差180度，此时称为反向键控（PSK）。\r\n\r\n5.3 FSK（频移键控法）\r\n载波信号的频率根据离散数字变化而变化，FSK\r\n调制波的输出对于二进制高电平输入频率较高，对于二进制低电平输入频率较低。\r\n5.4 QAM（正交幅度调制法）\r\n利用正交载波对两路信号分别进行双边带抑制载波调幅形成的。通常有二进制\r\nQAM，四进制QAM（16QAM），八进制QAM（64QAM）等。\r\n\r\n","categories":["信号处理"],"tags":["信号处理"]},{"title":"week6","url":"/2025/07/21/week6/","content":"微调效果测试用lora层替换unet中所有可替换的线性层和1×1卷积层，测试效果较差，有明显失真，指标相比上一次微调均有下降\n论文代码学习学习论文 Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption 的开源代码，微调部分实现方法如下：\n1. 内容融合模块微调 (train-recon.py)#创建一个Adam优化器，只优化扩散模型中条件模块(c_content_condition)的参数optimizer = Adam(diffusion.model.c_content_condition.parameters(), lr=1e-4)#遍历数据集中的所有批次for batch in dataloader:       real_image = batch.cuda()          condition = real_image  # 使用自身作为条件          t, (x, loss_diffusion) = diffusion.few_shot_forward(        real_image,           x_self_cond=condition,          max_step=1000      )      # 计算扩散损失的平均值（预测噪声与真实噪声的差异）      loss_diffusion.mean().backward()  # 反向传播计算梯度      optimizer.step()     if global_step % 200 == 0:        # 使用DDIM采样器生成重建图像        output_image = diffusion.ddim_sample(            real_image.shape,              condition=condition,              sample_step=50,                 max_step=800          #从噪声步800开始逆向扩散（跳过前200步）        )              \n\n通过 c_content_condition 模块分离内容&#x2F;风格学习:\nmodel_target.prepare(style_condition=True, two_stage_step=300)\n\n2. 少样本域适应微调 (train-whole.py)a.分阶段训练策略：大t步学内容&#x2F;风格，小t步学细节, 具体是大t：学习全局内容&#x2F;风格 (step&#x3D;300-1000)  小t：学习局部细节 (t~rand(0,300))\nb.方向分布一致性：feature_dir &#x3D; (target_feature - source_feature) 引导特征迁移\nL_DDC &#x3D; ||φ(G(x)) - (φ(x) + Δ)||^2\n其中 Δ &#x3D; E[φ(y)] - E[φ(x)] 是域间特征方向\nc.动态加权\nα &#x3D; 20^{t&#x2F;T} \\quad (T&#x3D;1000)\n#创建一个优化器，只优化需要梯度的参数# 使用filter+lambda过滤出requires_grad=True的参数，冻结有些参数optimizer = Adam(    filter(lambda p: p.requires_grad, diffusion_target.parameters()),     lr=1e-4  #使用相对较小的学习率防止过拟合)# 遍历源域和目标域的数据加载器# 使用zip确保每次迭代获取一对源域和目标域批次数据for (target_batch, source_batch) in zip(target_dataloader, source_dataloader):    # 阶段1：内容保持（大t）      if global_step % 2 == 0:  # 每两步执行一次                    # step=300 表示在扩散过程的前300步进行内容融合        t, (x, _) = diffusion.few_shot_forward(            source_image,     # 源域输入图像            step=300,                   x_self_cond=condition  #内容条件输入        )              # 方向分布一致性损失              # 使用CLIP模型提取源域图像特征        feature_source = clip_model.encode_img(source_image)              feature_target = clip_model.encode_img(generated_image)                    #feature_dir = E[φ(y)] - E[φ(x)] 预计算的域间特征方向        loss_feature = mse_loss(            feature_target,             feature_source + feature_dir  # 特征方向约束        ) * opts.beta_f  #可调节的损失权重              # 风格损失              # 使用预定义的风格损失函数(训练的VGG)              loss_style = style_loss(generated_image, style_imgs) * opts.beta_style        # 阶段2：细节学习（小t）       else:  #与阶段1交替执行              t = torch.randint(0, 300, (batch_size,))                #使用目标域图像进行前向传播             _, (_, loss_diffusion) = diffusion.few_shot_forward(            target_image,              t=t                  )         #时间步相关加权          alpha = 20 ** (t / 1000)  #权重函数      #加权总损失       total_loss = (alpha * (loss_feature + loss_style)).mean()        total_loss.backward()     \n","categories":["科研实习周记"],"tags":["Few-Shot","diffusion model","科研实习周记"]},{"title":"Cache及DMA缓存一致性处理","url":"/2025/07/21/Cache%E5%8F%8ADMA%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%A4%84%E7%90%86/","content":"\r\n"}]