<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.23.2","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="这里记录我的学习与生活">
<meta property="og:type" content="website">
<meta property="og:title" content="九大山人">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="九大山人">
<meta property="og:description" content="这里记录我的学习与生活">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="gzx">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>九大山人</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">九大山人</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">天地一痴翁</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-links"><a href="/links" rel="section"><i class="fa fa-link fa-fw"></i>links</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="gzx"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">gzx</p>
  <div class="site-description" itemprop="description">这里记录我的学习与生活</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/13/week5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/13/week5/" class="post-title-link" itemprop="url">week4</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-07-13 14:05:07 / Modified: 17:05:50" itemprop="dateCreated datePublished" datetime="2025-07-13T14:05:07+08:00">2025-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%91%A8%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">科研实习周记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1
id="一论文阅读笔记-few-shot-image-generation-with-diffusion-models">一、论文阅读笔记
Few-shot Image Generation with Diffusion Models</h1>
<p>论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.03264"
class="uri">https://arxiv.org/pdf/2211.03264</a></p>
<h2 id="主要内容">主要内容：</h2>
<p>提出Few-shot Diffusion Models (FDM)，在仅使用 10
张训练图像时，就能生成具有合理多样性和质量的图像。</p>
<h2 id="主要挑战">主要挑战</h2>
<p>过拟合和模式崩溃（模型只能生成训练集中见过的少数几种样本）</p>
<h2 id="核心方法">核心方法</h2>
<h3
id="结构感知数据增强-structure-aware-data-augmentation">结构感知数据增强
(Structure-Aware Data Augmentation)</h3>
<p>使用预训练的CLIP模型提取图像的语义特征，然后基于这些特征计算图像之间的相似性，</p>
<p>CLIP相似度计算：<span
class="math inline">$s_{ij}=\frac{\phi(I_i)\cdot\phi(I_j)}{\|\phi(I_i)\|\|\phi(I_j)\|}$</span></p>
<p>其中 ϕ(⋅) 是CLIP图像编码器，<span
class="math inline"><em>s</em><sub><em>i</em><em>j</em></sub> ∈ [−1, 1]</span>表示图像
<span class="math inline"><em>I</em><sub><em>i</em></sub></span> 和
<span class="math inline"><em>I</em><sub><em>j</em></sub></span>
的语义相似度</p>
<p>相似度高的图像对：应用更强的几何变换（如大幅旋转、裁剪），能提供更多样的“视角”而不会完全破坏结构。</p>
<p>相似度低的图像对：应用较弱的变换，避免破坏其各自独特的结构信息。</p>
<p>自适应变换强度: <span
class="math inline"><em>λ</em><sub><em>i</em><em>j</em></sub> = <em>λ</em><sub>min</sub> + (<em>λ</em><sub>max</sub> − <em>λ</em><sub>min</sub>)⋯<sub><em>i</em><em>j</em></sub></span></p>
<p><span class="math inline"><em>λ</em><sub>min</sub></span>和<span
class="math inline"><em>λ</em><sub>max</sub></span>是最小/最大变换强度，相似度越高，变换强度越大</p>
<h3 id="层级优化机制-hierarchical-optimization">层级优化机制
(Hierarchical Optimization)</h3>
<p>FDM 将扩散模型（如DDPM）的UNet结构划分为两个层级：</p>
<ol type="1">
<li><p>基础层：负责捕捉图像的全局结构和基本语义（一般是UNet的深层/瓶颈层）</p></li>
<li><p>细节层：负责生成图像的局部细节（一般是UNet的浅层）</p></li>
</ol>
<p>采用交替优化策略： 阶段一 (Freeze Detail
Layers)：冻结西接层参数，只优化基础层 阶段二 (Freeze Base
Layers)：冻结基础层参数，只优化细节层 ### 自适应卷积模块 (Adaptive
Convolution Module)
引入自适应卷积模块，根据输入特征图动态生成卷积核的偏移量 (offset)
和调制标量 (modulation scalar) 偏移量：
卷积核的采样位置根据输入内容进行微调</p>
<p><span
class="math inline"><em>Δ</em><em>p</em><sub><em>k</em></sub> = <em>f</em><sub>offset</sub>(<strong>F</strong>; <em>ϕ</em>)</span></p>
<p><span
class="math inline"><em>f</em><sub>offset</sub></span>是轻量子网络，<span
class="math inline">F</span>是输入特征图</p>
<p>调制标量： 动态调整卷积核的权重，增强模型对输入变化的适应能力</p>
<p><span
class="math inline"><em>m</em><sub><em>k</em></sub> = <em>σ</em>(<em>g</em><sub>mod</sub>(<strong>F</strong>; <em>ψ</em>))</span></p>
<p><span class="math inline">o</span>
是sigmoid激活函数，限制输出在(0,1)范围</p>
<p>自适应卷积公式： <span
class="math inline">$\mathbf{y}(p)=\sum_{k=1}^K\mathbf{w}_k\cdot\mathbf{F}(p+p_k+\Delta
p_k)\cdot m_k$</span></p>
<h3 id="模式崩溃">模式崩溃</h3>
<p>对于某一个训练数据集，其中样本的概率分布为一个简单的一维高斯混合分布，包含两个峰，如下图
<img src="z21ukb0wsa.jpeg" /></p>
<p>模式崩溃问题是针对于生成样本的多样性，即生成的样本大量重复类似，如下图</p>
<p><img src="g9kyvxsbu2.jpeg" />
虽然生成样本的质量比较高，但是生成器完全没有捕捉到右边的峰的模式。</p>
<p>解决思路：</p>
<p>参考：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1522756"
class="uri">https://cloud.tencent.com/developer/article/1522756</a></p>
<h1 id="二代码改进">二、代码改进</h1>
<p>改进代码，</p>
<p>（1）由原来只替换注意力层改进为替换UNet的所有线性层和1x1卷积层</p>
<p>（2）改进数据集的选择，原来是随机挑选了10个样本训练lora参数，应改进为挑选部分dpm和少量的irt4_car样本去训练</p>
<p>7.9遇到的问题：替换Swin Transformer中的层，需要访问weight属性</p>
<p>尝试解决 （1）：跳过Swin Transformer中的层 （2）：当win
Transformer访问qkv.weight时，返回原始层的权重</p>
<p>7.12 解决了LoRA注入失败的问题 下一步：测试训练效果
改进用于微调的样本的选择</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/08/%E4%B8%B2%E5%8F%A3%E9%87%8D%E5%AE%9A%E5%90%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/08/%E4%B8%B2%E5%8F%A3%E9%87%8D%E5%AE%9A%E5%90%91/" class="post-title-link" itemprop="url">串口重定向</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-07-08 21:32:54" itemprop="dateCreated datePublished" datetime="2025-07-08T21:32:54+08:00">2025-07-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-11 20:09:35" itemprop="dateModified" datetime="2025-07-11T20:09:35+08:00">2025-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%95%E7%89%87%E6%9C%BA-stm32/" itemprop="url" rel="index"><span itemprop="name">-单片机 -stm32</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>344</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>stm32串口重定向HAL库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;// 包含标准输入输出头文件</span><br><span class="line"> </span><br><span class="line">int fputc(int ch,FILE *f)</span><br><span class="line">&#123;</span><br><span class="line">//采用轮询方式发送1字节数据，超时时间设置为无限等待</span><br><span class="line">HAL_UART_Transmit(&amp;huart1,(uint8_t *)&amp;ch,1,HAL_MAX_DELAY);</span><br><span class="line">return ch;</span><br><span class="line">&#125;</span><br><span class="line">int fgetc(FILE *f)</span><br><span class="line">&#123;</span><br><span class="line">uint8_t ch;</span><br><span class="line">// 采用轮询方式接收 1字节数据，超时时间设置为无限等待</span><br><span class="line">HAL_UART_Receive( &amp;huart1,(uint8_t*)&amp;ch,1, HAL_MAX_DELAY );</span><br><span class="line">return ch;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/02/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/02/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" class="post-title-link" itemprop="url">注意力机制</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-07-02 14:05:35" itemprop="dateCreated datePublished" datetime="2025-07-02T14:05:35+08:00">2025-07-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-12 17:50:30" itemprop="dateModified" datetime="2025-07-12T17:50:30+08:00">2025-07-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">-科研实习 -深度学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1>注意力机制</h1>
<p>原论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762">https://arxiv.org/pdf/1706.03762</a></p>
<h2 id="什么是注意力机制">什么是注意力机制</h2>
<p>注意力机制就是让模型重点关注重要信息，忽略次要信息。注意力机制分为空间注意力和时间注意力，前者用于图像处理，后者用于自然语言处理.</p>
<h2 id="原理">原理</h2>
<p>Query：当前需要查询的目标，即当前输入的特征表示。</p>
<p>Key：可以将每个单词的重要特征表示看作成 Key。</p>
<p>Value：每个单词本身的特征向量看作为 Value，一般和 Key成对出现，也就是我们常说的&quot;键-值&quot;对。</p>
<p><img src="mkmroptvcwdrc_2696c13c0c654516bee3bc20714995c6.webp" alt=""></p>
<p>核心公式（原论文中）：</p>
<p>$Attention(Q,K,V)=Softmax(\frac{QK^\top}{\sqrt{d_k}})V$</p>
<p>步骤：</p>
<ol>
<li>
<p>先根据 Query，Key计算两者的相关性，然后再通过 softmax 函数得到 注意力分数，使用 softmax 函数是为了使得所有的注意力分数在 [0,1] 之间，并且和为1。</p>
<p>相关性公式一般表示如下：</p>
<p>$score(q,k_i)=softmax(\alpha(q,k_i))=\frac{exp(\alpha(q,k_i))}{\sum_1^jexp(\alpha(q,k_j))}$</p>
<p>其中$\alpha(q,k_{i})$有很多变体：</p>
<p>e.g. 在加性注意力中</p>
<p>$\alpha(q,k_i)=w_v^Ttanh(W_qq+W_kk)$</p>
<p>W_q：Query对应的可训练矩阵</p>
<p>W_k: Key对应的可训练矩阵</p>
<p>w_v^T: Value对应的可训练矩阵</p>
<p>(tanh为双曲正切函数，作为一种常见的激活函数)</p>
<p>e.g.在缩放点积注意力中</p>
<p>$\alpha(q,k_i)=\frac{QK^T}{\sqrt{d}}$</p>
<p>其中d为Keys的维度大小，除以sqrt{d}是为了使方差变小，训练梯度更新时更稳定</p>
</li>
<li>
<p>将注意力分数加权求和，得到带注意力分数的Value</p>
</li>
</ol>
<h2 id="自注意力机制（Self-Attention-Mechanism）">自注意力机制（Self-Attention Mechanism）</h2>
<p><img src="v2-921a6ccdeed095c9940aa52baee85e8c_r.jpg" alt=""></p>
<p>2.1 Embedding 操作, 将向量x转化为a,a作为注意力机制的input data</p>
<p>2.2 q, k 操作</p>
<p>$q^i=W^qa^i$</p>
<p>$k^i=W^ka^i$</p>
<p>$v^i=W^va^i$</p>
<p>一般用 $\alpha_{1,i}=q^1\cdot k^i/\sqrt{d}$  表示 $a^{1}$ 与 $a^{i}$ 之间的关系，</p>
<p>其中$\mathrm{d}$表示 $\mathrm{q}$和$\mathrm{k}$ 矩阵的维度</p>
<p><img src="v2-22195b05ea273b6d46ee0a7ff4fe71ed_1440w.jpg" alt=""></p>
<p>2.3 v操作</p>
<p>$b^1=\sum_i\tilde{\alpha}_{1,i}v^i$</p>
<p>$b^2=\sum_i\tilde{\alpha}_{2,i}v^i$</p>
<p>以此类推</p>
<p><img src="v2-0851bb5a4fdeb88efa6f96aabef45b65_1440w.jpg" alt=""></p>
<h2 id="多头注意力机制">多头注意力机制</h2>
<h3 id="q-k操作">q,k操作</h3>
<p>这里以两头为例</p>
<p>$q^{i,1}=W^{q,1}q^i$</p>
<p>$q^{i,2}=W^{q,2}q^i$</p>
<p>k也是同样的操作</p>
<h3 id="v操作">v操作</h3>
<p>与自注意力机制相同</p>
<p><img src="v2-18638aafea77d3cf87973a59c08315b8_1440w.jpg" alt=""></p>
<h2 id="通道注意力机制">通道注意力机制</h2>
<p>通道注意力机制是通过计算每个通道channel的重要性程度；因此，常常被用在卷积神经网络里面。目前，比较经典的通道注意力机制方法就是SENet模型，SENet通过学习通道间的关系（每个通道的重要性），提升了网络在特征表示中的表达能力，进而提升了模型的性能。</p>
<h3 id="SENet介绍">SENet介绍</h3>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/631398525">https://zhuanlan.zhihu.com/p/631398525</a></p>
<h2 id="空间注意力机制">空间注意力机制</h2>
<p>通过引入注意力模块，使模型能够自适应地学习不同区域的注意力权重。这样，模型可以更加关注重要的图像区域，而忽略不重要的区域。其中，最为典型的是 CBAM（Convolutional Block Attention Module），CBAM 是一种结合了通道注意力和空间注意力的模型，旨在增强卷积神经网络对图像的关注能力。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/30/week4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/06/30/week4/" class="post-title-link" itemprop="url">week4</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-06-30 22:05:07" itemprop="dateCreated datePublished" datetime="2025-06-30T22:05:07+08:00">2025-06-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-13 14:46:38" itemprop="dateModified" datetime="2025-07-13T14:46:38+08:00">2025-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%91%A8%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">科研实习周记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1>一、LoRA微调</h1>
<h2 id="test1">test1:</h2>
<p>将训练第二阶段注意力机制中的线性层’w_q’,‘w_k’,'w_v’替换为LoRA层</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lora_r: 8                    # LoRA秩大小</span><br><span class="line">lora_alpha: 16               # LoRA缩放因子</span><br></pre></td></tr></table></figure>
<p>预训练模型只加载第二阶段扩散网络权重</p>
<p>结果： _IncompatibleKeys 错误（缺少 encoder/decoder 层）<br>
可能原因：只加载了第二阶段模型，缺少 Autoencoder 部分，无法将输入图像编码为潜在空间表示，无法将生成的潜在编码解码为图像</p>
<h2 id="test2">test2:</h2>
<p>由第一次尝试得，当只微调扩散网络本身时，仍需要</p>
<ol>
<li>
<p>先加载第一阶段Autoencoder</p>
</li>
<li>
<p>再加载第二阶段扩散网络权重</p>
</li>
</ol>
<p>则test2总体流程为：</p>
<ol>
<li>加载完整的加载完整的扩散模型（含 Autoencoder + 扩散网络）</li>
<li>注入 LoRA 参数到扩散网络的特定层</li>
<li>冻结其他参数，随机选择20张图片训练 LoRA 层</li>
</ol>
<p>测试结果：</p>
<table>
<thead>
<tr>
<th>评估指标</th>
<th>微调前</th>
<th>微调后</th>
<th>变化趋势</th>
<th>变化率</th>
</tr>
</thead>
<tbody>
<tr>
<td>NMSE</td>
<td>0.006882</td>
<td>0.005570</td>
<td>↓</td>
<td>-19.06%</td>
</tr>
<tr>
<td>RMSE</td>
<td>0.029842</td>
<td>0.026012</td>
<td>↓</td>
<td>-12.83%</td>
</tr>
<tr>
<td>SSIM</td>
<td>0.945097</td>
<td>0.955175</td>
<td>↑</td>
<td>+1.07%</td>
</tr>
<tr>
<td>PSNR (dB)</td>
<td>30.574329</td>
<td>31.882632</td>
<td>↑</td>
<td>+4.28%</td>
</tr>
</tbody>
</table>
<h1>注意力机制</h1>
<p>原论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762">https://arxiv.org/pdf/1706.03762</a></p>
<h2 id="什么是注意力机制">什么是注意力机制</h2>
<p>注意力机制就是让模型重点关注重要信息，忽略次要信息。注意力机制分为空间注意力和时间注意力，前者用于图像处理，后者用于自然语言处理.</p>
<h2 id="原理">原理</h2>
<p>Query：当前需要查询的目标，即当前输入的特征表示。</p>
<p>Key：可以将每个单词的重要特征表示看作成 Key。</p>
<p>Value：每个单词本身的特征向量看作为 Value，一般和 Key成对出现，也就是我们常说的&quot;键-值&quot;对。</p>
<p><img src="%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/mkmroptvcwdrc_2696c13c0c654516bee3bc20714995c6.webp" alt=""><br>
核心公式（原论文中）：</p>
<p>$$<br>
Attention(Q,K,V)=Softmax(\frac{QK^\top}{\sqrt{d_k}})V<br>
$$</p>
<p>步骤：</p>
<ol>
<li>
<p>先根据 Query，Key计算两者的相关性，然后再通过 softmax 函数得到 注意力分数，使用 softmax 函数是为了使得所有的注意力分数在 [0,1] 之间，并且和为1。</p>
<p>相关性公式一般表示如下：</p>
<p>$$<br>
score(q,k_i)=softmax(\alpha(q,k_i))=\frac{exp(\alpha(q,k_i))}{\sum_1^jexp(\alpha(q,k_j))}<br>
$$</p>
<p>其中$\alpha(q,k_{i})$有很多变体：</p>
<p>e.g. 在加性注意力中</p>
<p>$$<br>
\alpha(q,k_i)=w_v^Ttanh(W_qq+W_kk)<br>
$$</p>
<p>W_q：Query对应的可训练矩阵</p>
<p>W_k: Key对应的可训练矩阵</p>
<p>w_v^T: Value对应的可训练矩阵</p>
<p>(tanh为双曲正切函数，作为一种常见的激活函数)</p>
<p>e.g.在缩放点积注意力中</p>
<p>$$<br>
\alpha(q,k_i)=\frac{QK^T}{\sqrt{d}}<br>
$$</p>
<p>其中d为Keys的维度大小，除以sqrt{d}是为了使方差变小，训练梯度更新时更稳定</p>
</li>
<li>
<p>将注意力分数加权求和，得到带注意力分数的Value</p>
</li>
</ol>
<h2 id="自注意力机制（Self-Attention-Mechanism）">自注意力机制（Self-Attention Mechanism）</h2>
<p><img src="%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/v2-921a6ccdeed095c9940aa52baee85e8c_r.jpg" alt=""></p>
<p>2.1 Embedding 操作, 将向量x转化为a,a作为注意力机制的input data</p>
<p>2.2 q, k 操作</p>
<p>$$q^i=W^qa^i$$</p>
<p>$$k^i=W^ka^i$$</p>
<p>$$v^i=W^va^i$$</p>
<h2 id="多头注意力机制（Multi-head-Self-Attention-Machanism）">多头注意力机制（Multi-head Self-Attention Machanism）</h2>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/631398525">https://zhuanlan.zhihu.com/p/631398525</a></p>
<h2 id="通道注意力机制">通道注意力机制</h2>
<h2 id="空间注意力机制">空间注意力机制</h2>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/30/week3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/06/30/week3/" class="post-title-link" itemprop="url">week3</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-06-30 16:49:08" itemprop="dateCreated datePublished" datetime="2025-06-30T16:49:08+08:00">2025-06-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-13 14:46:48" itemprop="dateModified" datetime="2025-07-13T14:46:48+08:00">2025-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%91%A8%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">科研实习周记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>4.1k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>4 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1>Few-Shot</h1>
<h2 id="Phasic-Content-Fusing-Diffusion-Model-with-Directional-Distribution-Consistency-for-Few-Shot-Model-Adaption">Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2309.03729">https://arxiv.org/pdf/2309.03729</a></p>
<h3 id="Abstract">Abstract</h3>
<ol>
<li>当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节</li>
<li>引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）</li>
<li>跨领域情景的结构一致性</li>
</ol>
<h3 id="Challenges">Challenges</h3>
<ol>
<li>overfit</li>
<li>细节学习阶段（t较小的时候）风格迁移失败</li>
<li>现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转</li>
</ol>
<h3 id="Method">Method</h3>
<h4 id="Training-with-Phasic-Content-Fusion">Training with Phasic Content Fusion</h4>
<p>在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合$E(x^{A})$和噪声$z\sim\mathcal{N}(0,I)$，</p>
<p>$\hat{E}(x^A)=m(t)E(x^A)+(1-m(t))z$</p>
<p>然后使用多个卷积块将 $\hat{E}(x^A)$ 与 $E(x_{t}^{A})$ 融合，得到融合后的特征 $E(x^A,x_t^A)$ ，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的 $x_{t-1}^A$</p>
<h4 id="方向分布一致性损失函数-directional-distribution-consistency-loss-DDC">方向分布一致性损失函数 directional distribution consistency loss (DDC)</h4>
<p>最终的损失函数由以下三个损失函数构成：</p>
<ol>
<li>
<p>Directional distribution consistency loss</p>
<p>$\mathcal{L}_{DDC}=|E(x^A)+w,E(x_0^{A\to B})|^2$</p>
<p>其中w为方向向量，给定源分布 $A={x_{1}^{A},\cdots x_{m}^{A}}$ 和目标分布 $B={x_{1}^{B},\cdots x_{m}^{B}}$ ,特征空间中从源域中心到目标域中心的跨域方向向量w,</p>
<p>$w=\frac{1}{m}\sum_{i=1}^mE(x_i^B)-\frac{1}{n}\sum_{i=1}^nE(x_i^A)$</p>
</li>
<li>
<p>Style loss</p>
<p>$\mathcal{L}<em>{style}=\frac{1}{m}\sum</em>{i=1}^{m}\sum_{l}w_{l}|G^{l}(x_{0}^{A\to B})-G^{l}(x_{i}^{B})|^{2}$</p>
<p>用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵</p>
</li>
<li>
<p>Diffusion Loss</p>
</li>
<li>
<p>$\mathcal{L}<em>{dif}=||\epsilon</em>\theta(x_t^B,t)-\epsilon||^2$</p>
</li>
</ol>
<p>最终的损失函数为：</p>
<p>$\mathcal{L}=m(t)(1-w(t))(\lambda_{DDC}\mathcal{L}<em>{DDC}(x^{A},x</em>{0}^{A\to B})+\lambda_{style}\mathcal{L}<em>{style}(x</em>{0}^{A\to B},x^{B}))+w(t)\mathcal{L}_{dif}(x^{B})$</p>
<h4 id="迭代跨域结构引导-Iterative-Cross-domain-Structure-Guidance-ICSG">迭代跨域结构引导 Iterative Cross-domain Structure Guidance(ICSG)</h4>
<p>需要进一步理解</p>
<h3 id="实验及评估过程">实验及评估过程</h3>
<h3 id="相关概念">相关概念</h3>
<h4 id="图像翻译-Image-to-Image-Translation">图像翻译 Image-to-Image Translation</h4>
<p>将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。</p>
<h4 id="Gram矩阵">Gram矩阵</h4>
<h5 id="原理">原理</h5>
<p>n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Gram matrix)，很明显，这是一个对称矩阵。<br>
输入图像的feature map为[ ch, h, w]。我们经过flatten（即是将h* w 进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w, ch]的矩阵。再对两个作内积得到Gram矩阵。</p>
<h5 id="应用">应用</h5>
<p>Gram matrix的应用-风格迁移：</p>
<ol>
<li>
<p>准备基准图像和风格图像</p>
</li>
<li>
<p>使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图feature map）</p>
</li>
<li>
<p>分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像</p>
</li>
</ol>
<p>一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。</p>
<h4 id="消融实验-Ablation-Study">消融实验 Ablation Study</h4>
<p>类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。</p>
<h2 id="Specialist-Diffusion-Plug-and-Play-Sample-Efficient-Fine-Tuning-of-Text-to-Image-Diffusion-Models-to-Learn-Any-Unseen-Style">Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models to Learn Any Unseen Style</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.12572">https://arxiv.org/pdf/2211.12572</a></p>
<h3 id="主要内容">主要内容</h3>
<p>这篇论文提出Specialist Diffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，content loss to facilitate content-style disentanglement，sparsely updating diffusion time steps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。</p>
<h4 id="Data-Augmentations-for-Text2Image-Diffusion（数据增强）">Data Augmentations for Text2Image Diffusion（数据增强）</h4>
<h5 id="Image-Augmentation">Image Augmentation</h5>
<h5 id="Text-Prompt-Augmentation">Text Prompt Augmentation</h5>
<h6 id="Caption-Retrieval-Augmentation-标题搜索增强">Caption Retrieval Augmentation 标题搜索增强</h6>
<h6 id="Synonym-Augmentation-同义词增强">Synonym Augmentation 同义词增强</h6>
<h6 id="Doubled-Augmentation-双重增强">Doubled Augmentation 双重增强</h6>
<h4 id="Content-Loss">Content Loss</h4>
<h4 id="Sparse-Updating">Sparse Updating</h4>
<h3 id="相关概念-2">相关概念</h3>
<h4 id="增强泄露问题-augmentation-leakage">增强泄露问题 augmentation leakage</h4>
<p>生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。<br>
举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能 “bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended” ，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏” 到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentation leakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的 “虚假模式”，而非真实场景的合理特征，影响生成效果。</p>
<h4 id="正则化-Regularization">正则化 Regularization</h4>
<p><strong>正则化是用来防止模型过拟合而采取的手段</strong>，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大</p>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41960890/article/details/104891561">https://blog.csdn.net/weixin_41960890/article/details/104891561</a></p>
<h1>一.LoRA原理</h1>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/702629428">https://zhuanlan.zhihu.com/p/702629428</a><br>
原论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.09685">https://arxiv.org/pdf/2106.09685</a><br>
LoRA(Low-Rank Adaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。</p>
<p>LoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。</p>
<h2 id="1-1实现流程">1.1实现流程</h2>
<p><img src="v2-10ce9e224defb3732e09a257911821aa_1440w.png" alt=""></p>
<ol>
<li>在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；</li>
<li>用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B；</li>
<li>训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数。</li>
</ol>
<p>具体来讲，预训练权重矩阵 $\mathbf{W}_0\in\mathbb{R}^{d\times d}$ ，</p>
<p>将增量参数矩阵 $\Delta\mathbf{W}$ ，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式</p>
<p>$\mathbf{W}<em>{0}+\Delta\mathbf{W}=\mathbf{W}</em>{0}+\mathbf{BA}$</p>
<p>其中 $\mathbf{B}\in\mathbb{R}^{d\times r}$ ，$\mathbf{A}\in\mathbb{R}^{r\times d}$ ，秩$\mathrm{r}$远小于$\mathrm{d}$</p>
<p>给定输入$.\mathbf{x}\in\mathbb{R}^d$ ,添加LoRA后的输出$.\mathbf{h}\in\mathbb{R}^d$</p>
<p>$\mathbf{h}=(\mathbf{W}<em>{0}+\Delta\mathbf{W})\mathbf{x}=\mathbf{W}</em>{0}\mathbf{x}+\mathbf{BA}\mathbf{x}$</p>
<p>$\Delta\mathbf{h}=\mathbf{BAx}$</p>
<h2 id="1-2LoRA参数合并系数">1.2LoRA参数合并系数</h2>
<p>实际实现时以以下形式合并，其中$\alpha$为超参数</p>
<p>$\mathbf{h}=(\mathbf{W}_{0}+\frac{\alpha}{r}\Delta\mathbf{W})\mathbf{x}$</p>
<p>系数$\frac{\alpha}{r}$越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合</p>
<p>系数$\frac{\alpha}{r}$越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）</p>
<p>一般来说，在给定任务上LoRA微调，让$\alpha$为$\mathbf{r}$的2倍数。</p>
<h2 id="1-3-LoRA的秩-mathbf-r-如何选择">1.3 LoRA的秩$\mathbf{r}$如何选择</h2>
<p>目标：找到一个秩$\mathbf{r}$，使$\mathrm{BA}$无限接近$\Delta\mathbf{W}$的表达能力。</p>
<p>秩$\mathbf{r}$越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/29/%E4%BD%BF%E7%94%A8%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E8%A1%8C%E4%B8%B2%E5%8F%A3%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/06/29/%E4%BD%BF%E7%94%A8%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E8%A1%8C%E4%B8%B2%E5%8F%A3%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">使用循环缓冲区进行串口数据解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-06-29 10:22:41 / Modified: 12:18:08" itemprop="dateCreated datePublished" datetime="2025-06-29T10:22:41+08:00">2025-06-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%95%E7%89%87%E6%9C%BA-stm32/" itemprop="url" rel="index"><span itemprop="name">-单片机 -stm32</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>4.4k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>4 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1>stm32cubemx配置</h1>
<p>开启串口收发异步模式，开启串口空闲中断</p>
<h1>代码实现</h1>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;command.h&quot;</span><br><span class="line"></span><br><span class="line">// 指令的最小长度</span><br><span class="line">#define COMMAND_MIN_LENGTH 4</span><br><span class="line"></span><br><span class="line">// 循环缓冲区大小</span><br><span class="line">#define BUFFER_SIZE 128</span><br><span class="line">// 循环缓冲区</span><br><span class="line">uint8_t buffer[BUFFER_SIZE];</span><br><span class="line">// 循环缓冲区读索引</span><br><span class="line">uint8_t readIndex = 0;</span><br><span class="line">// 循环缓冲区写索引</span><br><span class="line">uint8_t writeIndex = 0;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* @brief 增加读索引</span><br><span class="line">* @param length 要增加的长度</span><br><span class="line">*/</span><br><span class="line">void Command_AddReadIndex(uint8_t length) &#123;</span><br><span class="line">    readIndex += length;</span><br><span class="line">    readIndex %= BUFFER_SIZE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* @brief 读取第i位数据 超过缓存区长度自动循环</span><br><span class="line">* @param i 要读取的数据索引</span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">uint8_t Command_Read(uint8_t i) &#123;</span><br><span class="line">    uint8_t index = i % BUFFER_SIZE;</span><br><span class="line">    return buffer[index];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* @brief 计算未处理的数据长度</span><br><span class="line">* @return 未处理的数据长度</span><br><span class="line">* @retval 0 缓冲区为空</span><br><span class="line">* @retval 1~BUFFER_SIZE-1 未处理的数据长度</span><br><span class="line">* @retval BUFFER_SIZE 缓冲区已满</span><br><span class="line">*/</span><br><span class="line">//uint8_t Command_GetLength() &#123;</span><br><span class="line">//  // 读索引等于写索引时，缓冲区为空</span><br><span class="line">//  if (readIndex == writeIndex) &#123;</span><br><span class="line">//    return 0;</span><br><span class="line">//  &#125;</span><br><span class="line">//  // 如果缓冲区已满,返回BUFFER_SIZE</span><br><span class="line">//  if (writeIndex + 1 == readIndex || (writeIndex == BUFFER_SIZE - 1 &amp;&amp; readIndex == 0)) &#123;</span><br><span class="line">//    return BUFFER_SIZE;</span><br><span class="line">//  &#125;</span><br><span class="line">//  // 如果缓冲区未满,返回未处理的数据长度</span><br><span class="line">//  if (readIndex &lt;= writeIndex) &#123;</span><br><span class="line">//    return writeIndex - readIndex;</span><br><span class="line">//  &#125; else &#123;</span><br><span class="line">//    return BUFFER_SIZE - readIndex + writeIndex;</span><br><span class="line">//  &#125;</span><br><span class="line">//&#125;</span><br><span class="line"></span><br><span class="line">uint8_t Command_GetLength() &#123;</span><br><span class="line">    return (writeIndex + BUFFER_SIZE - readIndex) % BUFFER_SIZE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* @brief 计算缓冲区剩余空间</span><br><span class="line">* @return 剩余空间</span><br><span class="line">* @retval 0 缓冲区已满</span><br><span class="line">* @retval 1~BUFFER_SIZE-1 剩余空间</span><br><span class="line">* @retval BUFFER_SIZE 缓冲区为空</span><br><span class="line">*/</span><br><span class="line">uint8_t Command_GetRemain() &#123;</span><br><span class="line">    return BUFFER_SIZE - Command_GetLength();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* @brief 向缓冲区写入数据</span><br><span class="line">* @param data 要写入的数据指针</span><br><span class="line">* @param length 要写入的数据长度</span><br><span class="line">* @return 写入的数据长度</span><br><span class="line">*/</span><br><span class="line">uint8_t Command_Write(uint8_t *data, uint8_t length) &#123;</span><br><span class="line">    // 如果缓冲区不足 则不写入数据 返回0</span><br><span class="line">    if (Command_GetRemain() &lt; length) &#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    // 使用memcpy函数将数据写入缓冲区</span><br><span class="line">    if (writeIndex + length &lt; BUFFER_SIZE) &#123;</span><br><span class="line">        memcpy(buffer + writeIndex, data, length);</span><br><span class="line">        writeIndex += length;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        uint8_t firstLength = BUFFER_SIZE - writeIndex;</span><br><span class="line">        memcpy(buffer + writeIndex, data, firstLength);</span><br><span class="line">        memcpy(buffer, data + firstLength, length - firstLength);</span><br><span class="line">        writeIndex = length - firstLength;</span><br><span class="line">    &#125;</span><br><span class="line">    return length;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* @brief 尝试获取一条指令</span><br><span class="line">* @param command 指令存放指针</span><br><span class="line">* @return 获取的指令长度</span><br><span class="line">* @retval 0 没有获取到指令</span><br><span class="line">*/</span><br><span class="line">uint8_t Command_GetCommand(uint8_t *command) &#123;</span><br><span class="line">    // 寻找完整指令</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        // 如果缓冲区长度小于COMMAND_MIN_LENGTH 则不可能有完整的指令</span><br><span class="line">        if (Command_GetLength() &lt; COMMAND_MIN_LENGTH) &#123;</span><br><span class="line">        return 0;</span><br><span class="line">        &#125;</span><br><span class="line">        // 如果不是包头 则跳过 重新开始寻找</span><br><span class="line">        if (Command_Read(readIndex) != 0xAA) &#123;</span><br><span class="line">        Command_AddReadIndex(1);</span><br><span class="line">        continue;</span><br><span class="line">        &#125;</span><br><span class="line">        // 如果缓冲区长度小于指令长度 则不可能有完整的指令</span><br><span class="line">        uint8_t length = Command_Read(readIndex + 1);</span><br><span class="line">        if (Command_GetLength() &lt; length) &#123;</span><br><span class="line">        return 0;</span><br><span class="line">        &#125;</span><br><span class="line">        // 如果校验和不正确 则跳过 重新开始寻找</span><br><span class="line">        uint8_t sum = 0;</span><br><span class="line">        for (uint8_t i = 0; i &lt; length - 1; i++) &#123;</span><br><span class="line">        sum += Command_Read(readIndex + i);</span><br><span class="line">        &#125;</span><br><span class="line">        if (sum != Command_Read(readIndex + length - 1)) &#123;</span><br><span class="line">        Command_AddReadIndex(1);</span><br><span class="line">        continue;</span><br><span class="line">        &#125;</span><br><span class="line">        // 如果找到完整指令 则将指令写入command 返回指令长度</span><br><span class="line">        for (uint8_t i = 0; i &lt; length; i++) &#123;</span><br><span class="line">        command[i] = Command_Read(readIndex + i);</span><br><span class="line">        &#125;</span><br><span class="line">        Command_AddReadIndex(length);</span><br><span class="line">        return length;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>头文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#ifndef INC_COMMAND_H_</span><br><span class="line">#define INC_COMMAND_H_</span><br><span class="line"></span><br><span class="line">#include &quot;main.h&quot;</span><br><span class="line">#include &lt;string.h&gt;</span><br><span class="line"></span><br><span class="line">uint8_t Command_Write(uint8_t *data, uint8_t length);</span><br><span class="line"></span><br><span class="line">uint8_t Command_GetCommand(uint8_t *command);</span><br><span class="line"></span><br><span class="line">#endif /* INC_COMMAND_H_ */</span><br></pre></td></tr></table></figure>
<p>main.c:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/* Private define ------------------------------------------------------------*/</span><br><span class="line">/* USER CODE BEGIN PD */</span><br><span class="line">uint8_t readBuffer[10];</span><br><span class="line">/* USER CODE END PD */</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/* USER CODE BEGIN 0 */</span><br><span class="line">void HAL_UARTEx_RxEventCallback(UART_HandleTypeDef *huart, uint16_t Size)&#123;</span><br><span class="line">	if (huart == &amp;huart2)&#123;</span><br><span class="line">		Command_Write(readBuffer, Size);</span><br><span class="line">		HAL_UARTEx_ReceiveToIdle_IT(&amp;huart2, readBuffer, sizeof(readBuffer));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">/* USER CODE END 0 */</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">/* USER CODE BEGIN 2 */</span><br><span class="line">HAL_UARTEx_ReceiveToIdle_IT(&amp;huart2, readBuffer, sizeof(readBuffer));</span><br><span class="line">uint8_t command[50];</span><br><span class="line">int commandLength = 0;</span><br><span class="line">/* USER CODE END 2 */</span><br><span class="line"></span><br><span class="line">/* Infinite loop */</span><br><span class="line">/* USER CODE BEGIN WHILE */</span><br><span class="line">while (1)</span><br><span class="line">&#123;</span><br><span class="line">    commandLength = Command_GetCommand(command);</span><br><span class="line">    if (commandLength != 0)&#123;</span><br><span class="line">        HAL_UART_Transmit(&amp;huart2, command, commandLength, HAL_MAX_DELAY);</span><br><span class="line">        for (int i = 2; i &lt; commandLength - 1; i += 2)&#123;</span><br><span class="line">            GPIO_PinState state = GPIO_PIN_SET;</span><br><span class="line">            if (command[i + 1] == 0x00)&#123;</span><br><span class="line">                state = GPIO_PIN_RESET;</span><br><span class="line">            &#125;</span><br><span class="line">            if (command[i] == 0x01)&#123;</span><br><span class="line">                HAL_GPIO_WritePin(RED_GPIO_Port, RED_Pin, state);</span><br><span class="line">            &#125;else if (command[i] == 0x02)&#123;</span><br><span class="line">                HAL_GPIO_WritePin(GREEN_GPIO_Port, GREEN_Pin, state);</span><br><span class="line">            &#125;else if (command[i] == 0x03)&#123;</span><br><span class="line">                HAL_GPIO_WritePin(BLUE_GPIO_Port, BLUE_Pin, state);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">/* USER CODE END WHILE */</span><br><span class="line"></span><br><span class="line">/* USER CODE BEGIN 3 */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/26/LoRA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/06/26/LoRA/" class="post-title-link" itemprop="url">LoRA</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-06-26 20:48:33 / Modified: 21:49:36" itemprop="dateCreated datePublished" datetime="2025-06-26T20:48:33+08:00">2025-06-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0-RadioDiff%E5%BE%AE%E8%B0%83/" itemprop="url" rel="index"><span itemprop="name">-科研实习 -RadioDiff微调</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>1.2k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1>一.LoRA原理</h1>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/702629428">https://zhuanlan.zhihu.com/p/702629428</a><br>
原论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.09685">https://arxiv.org/pdf/2106.09685</a><br>
LoRA(Low-Rank Adaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。</p>
<p>LoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。</p>
<h2 id="1-1实现流程">1.1实现流程</h2>
<p><img src="v2-10ce9e224defb3732e09a257911821aa_1440w.png" alt=""></p>
<ol>
<li>在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；</li>
<li>用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B；</li>
<li>训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数。</li>
</ol>
<p>具体来讲，预训练权重矩阵 $\mathbf{W}_0\in\mathbb{R}^{d\times d}$ ，</p>
<p>将增量参数矩阵 $\Delta\mathbf{W}$ ，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式</p>
<p>$$\mathbf{W}<em>{0}+\Delta\mathbf{W}=\mathbf{W}</em>{0}+\mathbf{BA}$$</p>
<p>其中 $\mathbf{B}\in\mathbb{R}^{d\times r}$ ，$\mathbf{A}\in\mathbb{R}^{r\times d}$ ，秩$\mathrm{r}$远小于$\mathrm{d}$</p>
<p>给定输入$.\mathbf{x}\in\mathbb{R}^d$ ,添加LoRA后的输出$.\mathbf{h}\in\mathbb{R}^d$</p>
<p>$$\mathbf{h}=(\mathbf{W}<em>{0}+\Delta\mathbf{W})\mathbf{x}=\mathbf{W}</em>{0}\mathbf{x}+\mathbf{BA}\mathbf{x}$$</p>
<p>$$\Delta\mathbf{h}=\mathbf{BAx}$$</p>
<h2 id="1-2LoRA参数合并系数">1.2LoRA参数合并系数</h2>
<p>实际实现时以以下形式合并，其中$\alpha$为超参数</p>
<p>$$\mathbf{h}=(\mathbf{W}_{0}+\frac{\alpha}{r}\Delta\mathbf{W})\mathbf{x}$$</p>
<p>系数$\frac{\alpha}{r}$越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合</p>
<p>系数$\frac{\alpha}{r}$越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）</p>
<p>一般来说，在给定任务上LoRA微调，让$\alpha$为$\mathbf{r}$的2倍数。</p>
<h2 id="1-3-LoRA的秩-mathbf-r-如何选择">1.3 LoRA的秩$\mathbf{r}$如何选择</h2>
<p>目标：找到一个秩$\mathbf{r}$，使$\mathrm{BA}$无限接近$\Delta\mathbf{W}$的表达能力。</p>
<p>秩$\mathbf{r}$越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/26/Specialist-Diffusion/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/06/26/Specialist-Diffusion/" class="post-title-link" itemprop="url">Specialist Diffusion</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-06-26 17:20:22" itemprop="dateCreated datePublished" datetime="2025-06-26T17:20:22+08:00">2025-06-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-13 14:47:40" itemprop="dateModified" datetime="2025-07-13T14:47:40+08:00">2025-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文阅读笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>986</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1>Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models to Learn Any Unseen Style</h1>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.12572">https://arxiv.org/pdf/2211.12572</a></p>
<h2 id="主要内容">主要内容</h2>
<p>这篇论文提出Specialist Diffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，content loss to facilitate content-style disentanglement，sparsely updating diffusion time steps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。</p>
<h3 id="Data-Augmentations-for-Text2Image-Diffusion（数据增强）">Data Augmentations for Text2Image Diffusion（数据增强）</h3>
<h4 id="Image-Augmentation">Image Augmentation</h4>
<h4 id="Text-Prompt-Augmentation">Text Prompt Augmentation</h4>
<h5 id="Caption-Retrieval-Augmentation-标题搜索增强">Caption Retrieval Augmentation 标题搜索增强</h5>
<h5 id="Synonym-Augmentation-同义词增强">Synonym Augmentation 同义词增强</h5>
<h5 id="Doubled-Augmentation-双重增强">Doubled Augmentation 双重增强</h5>
<h3 id="Content-Loss">Content Loss</h3>
<h3 id="Sparse-Updating">Sparse Updating</h3>
<h2 id="相关概念">相关概念</h2>
<h3 id="增强泄露问题-augmentation-leakage">增强泄露问题 augmentation leakage</h3>
<p>生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。<br>
举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能 “bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended” ，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏” 到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentation leakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的 “虚假模式”，而非真实场景的合理特征，影响生成效果。</p>
<h3 id="正则化-Regularization">正则化 Regularization</h3>
<p><strong>正则化是用来防止模型过拟合而采取的手段</strong>，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大<br>
参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41960890/article/details/104891561">https://blog.csdn.net/weixin_41960890/article/details/104891561</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/26/Phasic%20Content%20Fusing%20Diffusion%20Model%20with%20Directional%20Distribution%20Consistency%20for%20Few-Shot%20Model%20Adaption/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/06/26/Phasic%20Content%20Fusing%20Diffusion%20Model%20with%20Directional%20Distribution%20Consistency%20for%20Few-Shot%20Model%20Adaption/" class="post-title-link" itemprop="url">Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-06-26 13:45:38" itemprop="dateCreated datePublished" datetime="2025-06-26T13:45:38+08:00">2025-06-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-13 14:47:52" itemprop="dateModified" datetime="2025-07-13T14:47:52+08:00">2025-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文阅读笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>1.9k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>2 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1>Few-Shot</h1>
<h2 id="Phasic-Content-Fusing-Diffusion-Model-with-Directional-Distribution-Consistency-for-Few-Shot-Model-Adaption">Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption</h2>
<h3 id="Abstract">Abstract</h3>
<ol>
<li>当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节</li>
<li>引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）</li>
<li>跨领域情景的结构一致性</li>
</ol>
<h3 id="Challenges">Challenges</h3>
<ol>
<li>overfit</li>
<li>细节学习阶段（t较小的时候）风格迁移失败</li>
<li>现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转</li>
</ol>
<h3 id="Method">Method</h3>
<h4 id="Training-with-Phasic-Content-Fusion">Training with Phasic Content Fusion</h4>
<p>在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合$E(x^{A})$和噪声$z\sim\mathcal{N}(0,I)$，<br>
$\hat{E}(x^A)=m(t)E(x^A)+(1-m(t))z$<br>
然后使用多个卷积块将 $\hat{E}(x^A)$ 与 $E(x_{t}^{A})$ 融合，得到融合后的特征 $E(x^A,x_t^A)$ ，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的 $x_{t-1}^A$</p>
<h4 id="方向分布一致性损失函数-directional-distribution-consistency-loss-DDC">方向分布一致性损失函数 directional distribution consistency loss (DDC)</h4>
<p>最终的损失函数由以下三个损失函数构成：</p>
<ol>
<li>
<p>Directional distribution consistency loss</p>
<p>$\mathcal{L}_{DDC}=|E(x^A)+w,E(x_0^{A\to B})|^2$</p>
<p>其中w为方向向量，给定源分布 $A={x_{1}^{A},\cdots x_{m}^{A}}$ 和目标分布 $B={x_{1}^{B},\cdots x_{m}^{B}}$ ,特征空间中从源域中心到目标域中心的跨域方向向量w,</p>
<p>$w=\frac{1}{m}\sum_{i=1}^mE(x_i^B)-\frac{1}{n}\sum_{i=1}^nE(x_i^A)$</p>
</li>
<li>
<p>Style loss</p>
<p>$\mathcal{L}<em>{style}=\frac{1}{m}\sum</em>{i=1}^{m}\sum_{l}w_{l}|G^{l}(x_{0}^{A\to B})-G^{l}(x_{i}^{B})|^{2}$</p>
<p>用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵</p>
</li>
<li>
<p>Diffusion Loss</p>
</li>
<li>
<p>$\mathcal{L}<em>{dif}=||\epsilon</em>\theta(x_t^B,t)-\epsilon||^2$</p>
</li>
</ol>
<p>最终的损失函数为：</p>
<p>$\mathcal{L}=m(t)(1-w(t))(\lambda_{DDC}\mathcal{L}<em>{DDC}(x^{A},x</em>{0}^{A\to B})+\lambda_{style}\mathcal{L}<em>{style}(x</em>{0}^{A\to B},x^{B}))+w(t)\mathcal{L}_{dif}(x^{B})$</p>
<h4 id="迭代跨域结构引导-Iterative-Cross-domain-Structure-Guidance-ICSG">迭代跨域结构引导 Iterative Cross-domain Structure Guidance(ICSG)</h4>
<p>需要进一步理解</p>
<h3 id="实验及评估过程">实验及评估过程</h3>
<h3 id="相关概念">相关概念</h3>
<h4 id="图像翻译-Image-to-Image-Translation">图像翻译 Image-to-Image Translation</h4>
<p>将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。</p>
<h4 id="Gram矩阵">Gram矩阵</h4>
<h5 id="原理">原理</h5>
<p>n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Gram matrix)，很明显，这是一个对称矩阵。<br>
输入图像的feature map为[ ch, h, w]。我们经过flatten（即是将h* w 进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w, ch]的矩阵。再对两个作内积得到Gram矩阵。</p>
<h5 id="应用">应用</h5>
<p>Gram matrix的应用-风格迁移：</p>
<ol>
<li>
<p>准备基准图像和风格图像</p>
</li>
<li>
<p>使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图feature map）</p>
</li>
<li>
<p>分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像</p>
</li>
</ol>
<p>一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。</p>
<h4 id="消融实验-Ablation-Study">消融实验 Ablation Study</h4>
<p>类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/25/week2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="gzx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="九大山人">
      <meta itemprop="description" content="这里记录我的学习与生活">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | 九大山人">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/06/25/week2/" class="post-title-link" itemprop="url">week2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-06-25 21:41:24" itemprop="dateCreated datePublished" datetime="2025-06-25T21:41:24+08:00">2025-06-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-13 14:47:00" itemprop="dateModified" datetime="2025-07-13T14:47:00+08:00">2025-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E5%91%A8%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">科研实习周记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>986</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          diffusion model (李宏毅)笔记
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/06/25/week2/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">gzx</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">21k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">19 mins.</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>
    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
