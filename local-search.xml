<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>week3</title>
    <link href="/2025/06/30/week3/"/>
    <url>/2025/06/30/week3/</url>
    
    <content type="html"><![CDATA[<h1 id="few-shot">Few-Shot</h1><h2id="phasic-content-fusing-diffusion-model-with-directional-distribution-consistency-for-few-shot-model-adaption">PhasicContent Fusing Diffusion Model with Directional Distribution Consistencyfor Few-Shot Model Adaption</h2><p><a href="https://arxiv.org/pdf/2309.03729"class="uri">https://arxiv.org/pdf/2309.03729</a></p><h3 id="abstract">Abstract</h3><ol type="1"><li>当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节</li><li>引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）</li><li>跨领域情景的结构一致性</li></ol><h3 id="challenges">Challenges</h3><ol type="1"><li>overfit</li><li>细节学习阶段（t较小的时候）风格迁移失败</li><li>现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转</li></ol><h3 id="method">Method</h3><h4 id="training-with-phasic-content-fusion">Training with PhasicContent Fusion</h4><p>在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合<spanclass="math inline"><em>E</em>(<em>x</em><sup><em>A</em></sup>)</span>和噪声<spanclass="math inline"><em>z</em> ∼ 𝒩(0, <em>I</em>)</span>， <spanclass="math display"><em>Ê</em>(<em>x</em><sup><em>A</em></sup>) = <em>m</em>(<em>t</em>)<em>E</em>(<em>x</em><sup><em>A</em></sup>) + (1 − <em>m</em>(<em>t</em>))<em>z</em></span>然后使用多个卷积块将 <spanclass="math inline"><em>Ê</em>(<em>x</em><sup><em>A</em></sup>)</span>与 <spanclass="math inline"><em>E</em>(<em>x</em><sub><em>t</em></sub><sup><em>A</em></sup>)</span>融合，得到融合后的特征 <spanclass="math inline"><em>E</em>(<em>x</em><sup><em>A</em></sup>, <em>x</em><sub><em>t</em></sub><sup><em>A</em></sup>)</span>，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的<spanclass="math inline"><em>x</em><sub><em>t</em> − 1</sub><sup><em>A</em></sup></span>#### 方向分布一致性损失函数 directional distribution consistency loss(DDC) 最终的损失函数由以下三个损失函数构成： 1. Directional distributionconsistency loss <spanclass="math display">ℒ<sub><em>D</em><em>D</em><em>C</em></sub> = ∥<em>E</em>(<em>x</em><sup><em>A</em></sup>) + <em>w</em>, <em>E</em>(<em>x</em><sub>0</sub><sup><em>A</em> → <em>B</em></sup>)∥<sup>2</sup></span>其中w为方向向量，给定源分布 <spanclass="math inline"><em>A</em> = {<em>x</em><sub>1</sub><sup><em>A</em></sup>, ⋯<em>x</em><sub><em>m</em></sub><sup><em>A</em></sup>}</span>和目标分布 <spanclass="math inline"><em>B</em> = {<em>x</em><sub>1</sub><sup><em>B</em></sup>, ⋯<em>x</em><sub><em>m</em></sub><sup><em>B</em></sup>}</span>,特征空间中从源域中心到目标域中心的跨域方向向量w, <spanclass="math display">$$w=\frac{1}{m}\sum_{i=1}^mE(x_i^B)-\frac{1}{n}\sum_{i=1}^nE(x_i^A)$$</span>2. Style loss <spanclass="math display">$$\mathcal{L}_{style}=\frac{1}{m}\sum_{i=1}^{m}\sum_{l}w_{l}\|G^{l}(x_{0}^{A\toB})-G^{l}(x_{i}^{B})\|^{2}$$</span>用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵 3. Diffusion Loss<spanclass="math display">ℒ<sub><em>d</em><em>i</em><em>f</em></sub> = ||<em>ϵ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub><sup><em>B</em></sup>, <em>t</em>) − <em>ϵ</em>||<sup>2</sup></span></p><p>最终的损失函数为： <spanclass="math display">ℒ = <em>m</em>(<em>t</em>)(1 − <em>w</em>(<em>t</em>))(<em>λ</em><sub><em>D</em><em>D</em><em>C</em></sub>ℒ<sub><em>D</em><em>D</em><em>C</em></sub>(<em>x</em><sup><em>A</em></sup>, <em>x</em><sub>0</sub><sup><em>A</em> → <em>B</em></sup>) + <em>λ</em><sub><em>s</em><em>t</em><em>y</em><em>l</em><em>e</em></sub>ℒ<sub><em>s</em><em>t</em><em>y</em><em>l</em><em>e</em></sub>(<em>x</em><sub>0</sub><sup><em>A</em> → <em>B</em></sup>, <em>x</em><sup><em>B</em></sup>)) + <em>w</em>(<em>t</em>)ℒ<sub><em>d</em><em>i</em><em>f</em></sub>(<em>x</em><sup><em>B</em></sup>)</span></p><h4id="迭代跨域结构引导-iterative-cross-domain-structure-guidanceicsg">迭代跨域结构引导Iterative Cross-domain Structure Guidance(ICSG)</h4><p>需要进一步理解</p><h3 id="实验及评估过程">实验及评估过程</h3><h3 id="相关概念">相关概念</h3><h4 id="图像翻译-image-to-image-translation">图像翻译 Image-to-ImageTranslation</h4><p>将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。#### Gram矩阵 ##### 原理n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Grammatrix)，很明显，这是一个对称矩阵。 输入图像的feature map为[ ch, h,w]。我们经过flatten（即是将h* w进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w,ch]的矩阵。再对两个作内积得到Gram矩阵。 ##### 应用 Grammatrix的应用-风格迁移： 1. 准备基准图像和风格图像</p><ol start="2" type="1"><li><p>使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图featuremap）</p></li><li><p>分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像</p></li></ol><p>一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。</p><h4 id="消融实验-ablation-study">消融实验 Ablation Study</h4><p>类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。</p><h2id="specialist-diffusion-plug-and-play-sample-efficient-fine-tuning-of-text-to-image-diffusion-models-to-learn-any-unseen-style">SpecialistDiffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-ImageDiffusion Models to Learn Any Unseen Style</h2><p><a href="https://arxiv.org/pdf/2211.12572"class="uri">https://arxiv.org/pdf/2211.12572</a></p><h3 id="主要内容">主要内容</h3><p>这篇论文提出SpecialistDiffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，contentloss to facilitate content-style disentanglement，sparsely updatingdiffusion timesteps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。</p><h4 id="data-augmentations-for-text2image-diffusion数据增强">DataAugmentations for Text2Image Diffusion（数据增强）</h4><h5 id="image-augmentation">Image Augmentation</h5><h5 id="text-prompt-augmentation">Text Prompt Augmentation</h5><h6 id="caption-retrieval-augmentation-标题搜索增强">Caption RetrievalAugmentation 标题搜索增强</h6><h6 id="synonym-augmentation-同义词增强">Synonym Augmentation同义词增强</h6><h6 id="doubled-augmentation-双重增强">Doubled Augmentation双重增强</h6><h4 id="content-loss">Content Loss</h4><h4 id="sparse-updating">Sparse Updating</h4><h3 id="相关概念-1">相关概念</h3><h4 id="增强泄露问题-augmentation-leakage">增强泄露问题 augmentationleakage</h4><p>生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能“bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended”，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏”到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentationleakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的“虚假模式”，而非真实场景的合理特征，影响生成效果。 #### 正则化Regularization<strong>正则化是用来防止模型过拟合而采取的手段</strong>，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大参考：<ahref="https://blog.csdn.net/weixin_41960890/article/details/104891561"class="uri">https://blog.csdn.net/weixin_41960890/article/details/104891561</a></p><h1 id="一.lora原理">一.LoRA原理</h1><p>参考：<a href="https://zhuanlan.zhihu.com/p/702629428"class="uri">https://zhuanlan.zhihu.com/p/702629428</a> 原论文：<ahref="https://arxiv.org/pdf/2106.09685"class="uri">https://arxiv.org/pdf/2106.09685</a> LoRA(Low-RankAdaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。</p><p>LoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。</p><h2 id="实现流程">1.1实现流程</h2><p><img src="v2-10ce9e224defb3732e09a257911821aa_1440w.png" /></p><ol type="1"><li>在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；<br /></li><li>用随机高斯分布初始化A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵B；</li><li>训练完成后，将 B 矩阵与 A矩阵相乘后合并预训练模型参数作为微调后的模型参数。</li></ol><p>具体来讲，预训练权重矩阵 <spanclass="math inline"><strong>W</strong><sub>0</sub> ∈ ℝ<sup><em>d</em> × <em>d</em></sup></span>，</p><p>将增量参数矩阵 <spanclass="math inline"><em>Δ</em><strong>W</strong></span>，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式</p><p><spanclass="math display"><strong>W</strong><sub>0</sub> + <em>Δ</em><strong>W</strong> = <strong>W</strong><sub>0</sub> + <strong>B</strong><strong>A</strong></span></p><p>其中 <spanclass="math inline"><strong>B</strong> ∈ ℝ<sup><em>d</em> × <em>r</em></sup></span>，<spanclass="math inline"><strong>A</strong> ∈ ℝ<sup><em>r</em> × <em>d</em></sup></span>，秩<span class="math inline">r</span>远小于<spanclass="math inline">d</span></p><p>给定输入<spanclass="math inline">.<strong>x</strong> ∈ ℝ<sup><em>d</em></sup></span>,添加LoRA后的输出<spanclass="math inline">.<strong>h</strong> ∈ ℝ<sup><em>d</em></sup></span></p><p><spanclass="math display"><strong>h</strong> = (<strong>W</strong><sub>0</sub> + <em>Δ</em><strong>W</strong>)<strong>x</strong> = <strong>W</strong><sub>0</sub><strong>x</strong> + <strong>B</strong><strong>A</strong><strong>x</strong></span></p><p><spanclass="math display"><em>Δ</em><strong>h</strong> = <strong>B</strong><strong>A</strong><strong>x</strong></span></p><h2 id="lora参数合并系数">1.2LoRA参数合并系数</h2><p>实际实现时以以下形式合并，其中<spanclass="math inline"><em>α</em></span>为超参数</p><p><spanclass="math display">$$\mathbf{h}=(\mathbf{W}_{0}+\frac{\alpha}{r}\Delta\mathbf{W})\mathbf{x}$$</span></p><p>系数<spanclass="math inline">$\frac{\alpha}{r}$</span>越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合</p><p>系数<spanclass="math inline">$\frac{\alpha}{r}$</span>越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）</p><p>一般来说，在给定任务上LoRA微调，让<spanclass="math inline"><em>α</em></span>为<spanclass="math inline"><strong>r</strong></span>的2倍数。</p><h2 id="lora的秩mathbfr如何选择">1.3 LoRA的秩<spanclass="math inline"><strong>r</strong></span>如何选择</h2><p>目标：找到一个秩<spanclass="math inline"><strong>r</strong></span>，使<spanclass="math inline">BA</span>无限接近<spanclass="math inline"><em>Δ</em><strong>W</strong></span>的表达能力。</p><p>秩<spanclass="math inline"><strong>r</strong></span>越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。</p>]]></content>
    
    
    <categories>
      
      <category>-科研实习 -周记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>使用循环缓冲区进行串口数据解析</title>
    <link href="/2025/06/29/%E4%BD%BF%E7%94%A8%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E8%A1%8C%E4%B8%B2%E5%8F%A3%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/"/>
    <url>/2025/06/29/%E4%BD%BF%E7%94%A8%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA%E8%BF%9B%E8%A1%8C%E4%B8%B2%E5%8F%A3%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="stm32cubemx配置">stm32cubemx配置</h1><p>开启串口收发异步模式，开启串口空闲中断</p><h1 id="代码实现">代码实现</h1><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;command.h&quot;</span></span><br><br><span class="hljs-comment">// 指令的最小长度</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COMMAND_MIN_LENGTH 4</span><br><br><span class="hljs-comment">// 循环缓冲区大小</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BUFFER_SIZE 128</span><br><span class="hljs-comment">// 循环缓冲区</span><br><span class="hljs-type">uint8_t</span> buffer[BUFFER_SIZE];<br><span class="hljs-comment">// 循环缓冲区读索引</span><br><span class="hljs-type">uint8_t</span> readIndex = <span class="hljs-number">0</span>;<br><span class="hljs-comment">// 循环缓冲区写索引</span><br><span class="hljs-type">uint8_t</span> writeIndex = <span class="hljs-number">0</span>;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* @brief 增加读索引</span><br><span class="hljs-comment">* @param length 要增加的长度</span><br><span class="hljs-comment">*/</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">Command_AddReadIndex</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> length)</span> </span>&#123;<br>    readIndex += length;<br>    readIndex %= BUFFER_SIZE;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* @brief 读取第i位数据 超过缓存区长度自动循环</span><br><span class="hljs-comment">* @param i 要读取的数据索引</span><br><span class="hljs-comment">*/</span><br><br><span class="hljs-function"><span class="hljs-type">uint8_t</span> <span class="hljs-title">Command_Read</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> i)</span> </span>&#123;<br>    <span class="hljs-type">uint8_t</span> index = i % BUFFER_SIZE;<br>    <span class="hljs-keyword">return</span> buffer[index];<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* @brief 计算未处理的数据长度</span><br><span class="hljs-comment">* @return 未处理的数据长度</span><br><span class="hljs-comment">* @retval 0 缓冲区为空</span><br><span class="hljs-comment">* @retval 1~BUFFER_SIZE-1 未处理的数据长度</span><br><span class="hljs-comment">* @retval BUFFER_SIZE 缓冲区已满</span><br><span class="hljs-comment">*/</span><br><span class="hljs-comment">//uint8_t Command_GetLength() &#123;</span><br><span class="hljs-comment">//  // 读索引等于写索引时，缓冲区为空</span><br><span class="hljs-comment">//  if (readIndex == writeIndex) &#123;</span><br><span class="hljs-comment">//    return 0;</span><br><span class="hljs-comment">//  &#125;</span><br><span class="hljs-comment">//  // 如果缓冲区已满,返回BUFFER_SIZE</span><br><span class="hljs-comment">//  if (writeIndex + 1 == readIndex || (writeIndex == BUFFER_SIZE - 1 &amp;&amp; readIndex == 0)) &#123;</span><br><span class="hljs-comment">//    return BUFFER_SIZE;</span><br><span class="hljs-comment">//  &#125;</span><br><span class="hljs-comment">//  // 如果缓冲区未满,返回未处理的数据长度</span><br><span class="hljs-comment">//  if (readIndex &lt;= writeIndex) &#123;</span><br><span class="hljs-comment">//    return writeIndex - readIndex;</span><br><span class="hljs-comment">//  &#125; else &#123;</span><br><span class="hljs-comment">//    return BUFFER_SIZE - readIndex + writeIndex;</span><br><span class="hljs-comment">//  &#125;</span><br><span class="hljs-comment">//&#125;</span><br><br><span class="hljs-function"><span class="hljs-type">uint8_t</span> <span class="hljs-title">Command_GetLength</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> (writeIndex + BUFFER_SIZE - readIndex) % BUFFER_SIZE;<br>&#125;<br><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* @brief 计算缓冲区剩余空间</span><br><span class="hljs-comment">* @return 剩余空间</span><br><span class="hljs-comment">* @retval 0 缓冲区已满</span><br><span class="hljs-comment">* @retval 1~BUFFER_SIZE-1 剩余空间</span><br><span class="hljs-comment">* @retval BUFFER_SIZE 缓冲区为空</span><br><span class="hljs-comment">*/</span><br><span class="hljs-function"><span class="hljs-type">uint8_t</span> <span class="hljs-title">Command_GetRemain</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> BUFFER_SIZE - <span class="hljs-built_in">Command_GetLength</span>();<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* @brief 向缓冲区写入数据</span><br><span class="hljs-comment">* @param data 要写入的数据指针</span><br><span class="hljs-comment">* @param length 要写入的数据长度</span><br><span class="hljs-comment">* @return 写入的数据长度</span><br><span class="hljs-comment">*/</span><br><span class="hljs-function"><span class="hljs-type">uint8_t</span> <span class="hljs-title">Command_Write</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> *data, <span class="hljs-type">uint8_t</span> length)</span> </span>&#123;<br>    <span class="hljs-comment">// 如果缓冲区不足 则不写入数据 返回0</span><br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">Command_GetRemain</span>() &lt; length) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-comment">// 使用memcpy函数将数据写入缓冲区</span><br>    <span class="hljs-keyword">if</span> (writeIndex + length &lt; BUFFER_SIZE) &#123;<br>        <span class="hljs-built_in">memcpy</span>(buffer + writeIndex, data, length);<br>        writeIndex += length;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-type">uint8_t</span> firstLength = BUFFER_SIZE - writeIndex;<br>        <span class="hljs-built_in">memcpy</span>(buffer + writeIndex, data, firstLength);<br>        <span class="hljs-built_in">memcpy</span>(buffer, data + firstLength, length - firstLength);<br>        writeIndex = length - firstLength;<br>    &#125;<br>    <span class="hljs-keyword">return</span> length;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* @brief 尝试获取一条指令</span><br><span class="hljs-comment">* @param command 指令存放指针</span><br><span class="hljs-comment">* @return 获取的指令长度</span><br><span class="hljs-comment">* @retval 0 没有获取到指令</span><br><span class="hljs-comment">*/</span><br><span class="hljs-function"><span class="hljs-type">uint8_t</span> <span class="hljs-title">Command_GetCommand</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> *command)</span> </span>&#123;<br>    <span class="hljs-comment">// 寻找完整指令</span><br>    <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) &#123;<br>        <span class="hljs-comment">// 如果缓冲区长度小于COMMAND_MIN_LENGTH 则不可能有完整的指令</span><br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">Command_GetLength</span>() &lt; COMMAND_MIN_LENGTH) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-comment">// 如果不是包头 则跳过 重新开始寻找</span><br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">Command_Read</span>(readIndex) != <span class="hljs-number">0xAA</span>) &#123;<br>        <span class="hljs-built_in">Command_AddReadIndex</span>(<span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <span class="hljs-comment">// 如果缓冲区长度小于指令长度 则不可能有完整的指令</span><br>        <span class="hljs-type">uint8_t</span> length = <span class="hljs-built_in">Command_Read</span>(readIndex + <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">Command_GetLength</span>() &lt; length) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-comment">// 如果校验和不正确 则跳过 重新开始寻找</span><br>        <span class="hljs-type">uint8_t</span> sum = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">uint8_t</span> i = <span class="hljs-number">0</span>; i &lt; length - <span class="hljs-number">1</span>; i++) &#123;<br>        sum += <span class="hljs-built_in">Command_Read</span>(readIndex + i);<br>        &#125;<br>        <span class="hljs-keyword">if</span> (sum != <span class="hljs-built_in">Command_Read</span>(readIndex + length - <span class="hljs-number">1</span>)) &#123;<br>        <span class="hljs-built_in">Command_AddReadIndex</span>(<span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <span class="hljs-comment">// 如果找到完整指令 则将指令写入command 返回指令长度</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">uint8_t</span> i = <span class="hljs-number">0</span>; i &lt; length; i++) &#123;<br>        command[i] = <span class="hljs-built_in">Command_Read</span>(readIndex + i);<br>        &#125;<br>        <span class="hljs-built_in">Command_AddReadIndex</span>(length);<br>        <span class="hljs-keyword">return</span> length;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>头文件： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> INC_COMMAND_H_</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> INC_COMMAND_H_</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;main.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">uint8_t</span> <span class="hljs-title">Command_Write</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> *data, <span class="hljs-type">uint8_t</span> length)</span></span>;<br><br><span class="hljs-function"><span class="hljs-type">uint8_t</span> <span class="hljs-title">Command_GetCommand</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> *command)</span></span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span> <span class="hljs-comment">/* INC_COMMAND_H_ */</span></span><br></code></pre></td></tr></table></figure></p><p>main.c: <figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">/* Private define ------------------------------------------------------------*/<br>/* <span class="hljs-keyword">USER</span> <span class="hljs-title">CODE</span> BEGIN PD */<br>uint8_t readBuffer[<span class="hljs-number">10</span>];<br>/* <span class="hljs-keyword">USER</span> <span class="hljs-title">CODE</span> END PD */<br></code></pre></td></tr></table></figure></p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-comment">/* USER CODE BEGIN 0 */</span><br>void <span class="hljs-built_in">HAL_UARTEx_RxEventCallback</span>(UART_HandleTypeDef *huart, uint16_t Size)&#123;<br>if (huart == &amp;huart2)&#123;<br><span class="hljs-built_in">Command_Write</span>(readBuffer, Size);<br><span class="hljs-built_in">HAL_UARTEx_ReceiveToIdle_IT</span>(&amp;huart2, readBuffer, sizeof(readBuffer));<br>&#125;<br>&#125;<br><span class="hljs-comment">/* USER CODE END 0 */</span><br></code></pre></td></tr></table></figure><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs sas"><span class="hljs-comment">/* USER CODE BEGIN 2 */</span><br>HAL_UARTEx_ReceiveToIdle_IT(<span class="hljs-variable">&amp;huart2</span>, readBuffer, sizeof(readBuffer));<br>uint8_t command[50];<br>int commandLength = 0;<br><span class="hljs-comment">/* USER CODE END 2 */</span><br><br><span class="hljs-comment">/* Infinite loop */</span><br><span class="hljs-comment">/* USER CODE BEGIN WHILE */</span><br><span class="hljs-keyword">while</span> (1)<br>&#123;<br>    commandLength = Command_GetCommand(command);<br>    <span class="hljs-keyword">if</span> (commandLength != 0)&#123;<br>        HAL_UART_Transmit(<span class="hljs-variable">&amp;huart2</span>, command, commandLength, HAL_MAX_DELAY);<br>        for (int i = 2; i &lt; commandLength - 1; i += 2)&#123;<br>            GPIO_PinState state = GPIO_PIN_SET;<br>            <span class="hljs-keyword">if</span> (command[i + 1] == 0x00)&#123;<br>                state = GPIO_PIN_RESET;<br>            &#125;<br>            <span class="hljs-keyword">if</span> (command[i] == 0x01)&#123;<br>                HAL_GPIO_WritePi<span class="hljs-meta">n</span>(RED_GPIO_Port, RED_Pin, state);<br>            &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (command[i] == 0x02)&#123;<br>                HAL_GPIO_WritePi<span class="hljs-meta">n</span>(GREEN_GPIO_Port, GREEN_Pin, state);<br>            &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (command[i] == 0x03)&#123;<br>                HAL_GPIO_WritePi<span class="hljs-meta">n</span>(BLUE_GPIO_Port, BLUE_Pin, state);<br>            &#125;<br>        &#125;<br>    &#125;<br><br><span class="hljs-comment">/* USER CODE END WHILE */</span><br><br><span class="hljs-comment">/* USER CODE BEGIN 3 */</span><br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>-单片机 -stm32</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>LoRA</title>
    <link href="/2025/06/26/LoRA/"/>
    <url>/2025/06/26/LoRA/</url>
    
    <content type="html"><![CDATA[<h1 id="一.lora原理">一.LoRA原理</h1><p>参考：<a href="https://zhuanlan.zhihu.com/p/702629428"class="uri">https://zhuanlan.zhihu.com/p/702629428</a> 原论文：<ahref="https://arxiv.org/pdf/2106.09685"class="uri">https://arxiv.org/pdf/2106.09685</a> LoRA(Low-RankAdaptation of LLMs)，即LLMs的低秩适应，是参数高效微调最常用的方法。</p><p>LoRA的本质就是用更少的训练参数来近似LLM全参数微调所得的增量参数，从而达到使用更少显存占用的高效微调。</p><h2 id="实现流程">1.1实现流程</h2><p><img src="v2-10ce9e224defb3732e09a257911821aa_1440w.png" /></p><ol type="1"><li>在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩；<br /></li><li>用随机高斯分布初始化A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵B；</li><li>训练完成后，将 B 矩阵与 A矩阵相乘后合并预训练模型参数作为微调后的模型参数。</li></ol><p>具体来讲，预训练权重矩阵 <spanclass="math inline"><strong>W</strong><sub>0</sub> ∈ ℝ<sup><em>d</em> × <em>d</em></sup></span>，</p><p>将增量参数矩阵 <spanclass="math inline"><em>Δ</em><strong>W</strong></span>，表示为两个参数量更小的矩阵 B 和 A 的低秩近似,如下式</p><p><spanclass="math display"><strong>W</strong><sub>0</sub> + <em>Δ</em><strong>W</strong> = <strong>W</strong><sub>0</sub> + <strong>B</strong><strong>A</strong></span></p><p>其中 <spanclass="math inline"><strong>B</strong> ∈ ℝ<sup><em>d</em> × <em>r</em></sup></span>，<spanclass="math inline"><strong>A</strong> ∈ ℝ<sup><em>r</em> × <em>d</em></sup></span>，秩<span class="math inline">r</span>远小于<spanclass="math inline">d</span></p><p>给定输入<spanclass="math inline">.<strong>x</strong> ∈ ℝ<sup><em>d</em></sup></span>,添加LoRA后的输出<spanclass="math inline">.<strong>h</strong> ∈ ℝ<sup><em>d</em></sup></span></p><p><spanclass="math display"><strong>h</strong> = (<strong>W</strong><sub>0</sub> + <em>Δ</em><strong>W</strong>)<strong>x</strong> = <strong>W</strong><sub>0</sub><strong>x</strong> + <strong>B</strong><strong>A</strong><strong>x</strong></span></p><p><spanclass="math display"><em>Δ</em><strong>h</strong> = <strong>B</strong><strong>A</strong><strong>x</strong></span></p><h2 id="lora参数合并系数">1.2LoRA参数合并系数</h2><p>实际实现时以以下形式合并，其中<spanclass="math inline"><em>α</em></span>为超参数</p><p><spanclass="math display">$$\mathbf{h}=(\mathbf{W}_{0}+\frac{\alpha}{r}\Delta\mathbf{W})\mathbf{x}$$</span></p><p>系数<spanclass="math inline">$\frac{\alpha}{r}$</span>越大，LoRA微调权重的影响就越大，在下游任务上越容易过拟合</p><p>系数<spanclass="math inline">$\frac{\alpha}{r}$</span>越小，LoRA微调权重的影响就越小（微调的效果不明显，原始模型参数受到的影响也较少）</p><p>一般来说，在给定任务上LoRA微调，让<spanclass="math inline"><em>α</em></span>为<spanclass="math inline"><strong>r</strong></span>的2倍数。</p><h2 id="lora的秩mathbfr如何选择">1.3 LoRA的秩<spanclass="math inline"><strong>r</strong></span>如何选择</h2><p>目标：找到一个秩<spanclass="math inline"><strong>r</strong></span>，使<spanclass="math inline">BA</span>无限接近<spanclass="math inline"><em>Δ</em><strong>W</strong></span>的表达能力。</p><p>秩<spanclass="math inline"><strong>r</strong></span>越大，拟合能力越强（甚至出现过拟合），但参与训练的参数量也随之增加。</p>]]></content>
    
    
    <categories>
      
      <category>-科研实习 -RadioDiff微调</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Specialist Diffusion</title>
    <link href="/2025/06/26/Specialist-Diffusion/"/>
    <url>/2025/06/26/Specialist-Diffusion/</url>
    
    <content type="html"><![CDATA[<h1id="specialist-diffusion-plug-and-play-sample-efficient-fine-tuning-of-text-to-image-diffusion-models-to-learn-any-unseen-style">SpecialistDiffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-ImageDiffusion Models to Learn Any Unseen Style</h1><p><a href="https://arxiv.org/pdf/2211.12572"class="uri">https://arxiv.org/pdf/2211.12572</a></p><h2 id="主要内容">主要内容</h2><p>这篇论文提出SpecialistDiffusion：相当于一个即插即用的微调工具包，包括文本到图像的定制数据增强，contentloss to facilitate content-style disentanglement，sparsely updatingdiffusion timesteps。主要适用于以少量已知风格的图片训练模型，使其能够通过特定的文本提示生成相应风格的图片。</p><h3 id="data-augmentations-for-text2image-diffusion数据增强">DataAugmentations for Text2Image Diffusion（数据增强）</h3><h4 id="image-augmentation">Image Augmentation</h4><h4 id="text-prompt-augmentation">Text Prompt Augmentation</h4><h5 id="caption-retrieval-augmentation-标题搜索增强">Caption RetrievalAugmentation 标题搜索增强</h5><h5 id="synonym-augmentation-同义词增强">Synonym Augmentation同义词增强</h5><h5 id="doubled-augmentation-双重增强">Doubled Augmentation双重增强</h5><h3 id="content-loss">Content Loss</h3><h3 id="sparse-updating">Sparse Updating</h3><h2 id="相关概念">相关概念</h2><h3 id="增强泄露问题-augmentation-leakage">增强泄露问题 augmentationleakage</h3><p>生成模型在训练过程中，会记住训练样本及其经过增强后的版本，这样在推理（生成新内容）阶段，就容易生成与训练时相似的图像。举个文中例子，很多旋转后的图像理论上算自然照片，但在真实自然图像集合里，它们出现的概率其实更低。要是训练时过度用旋转增强，模型就可能“bias（偏向）” 生成更多带旋转的物体，可这些并非实际想要的（“un - tended”，即不符合自然场景常见分布 ），相当于增强操作的影响 “泄漏”到生成结果里，让生成内容偏离真实自然数据的合理分布，这就是 “augmentationleakage” 。简单说，就是数据增强的不当使用，让模型学到了增强带来的“虚假模式”，而非真实场景的合理特征，影响生成效果。</p><h3 id="正则化-regularization">正则化 Regularization</h3><p><strong>正则化是用来防止模型过拟合而采取的手段</strong>，对代价函数增加一个限制条件，限制其较高次的参数大小不能过大参考：<ahref="https://blog.csdn.net/weixin_41960890/article/details/104891561"class="uri">https://blog.csdn.net/weixin_41960890/article/details/104891561</a></p>]]></content>
    
    
    <categories>
      
      <category>-科研实习 -RadioDiff微调 -Few-Shot相关论文阅读笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption</title>
    <link href="/2025/06/26/Phasic%20Content%20Fusing%20Diffusion%20Model%20with%20Directional%20Distribution%20Consistency%20for%20Few-Shot%20Model%20Adaption/"/>
    <url>/2025/06/26/Phasic%20Content%20Fusing%20Diffusion%20Model%20with%20Directional%20Distribution%20Consistency%20for%20Few-Shot%20Model%20Adaption/</url>
    
    <content type="html"><![CDATA[<h1 id="few-shot">Few-Shot</h1><h2id="phasic-content-fusing-diffusion-model-with-directional-distribution-consistency-for-few-shot-model-adaption">PhasicContent Fusing Diffusion Model with Directional Distribution Consistencyfor Few-Shot Model Adaption</h2><h3 id="abstract">Abstract</h3><ol type="1"><li>当t较大时学习目标域内容和风格信息，当t较小时学习目标域的局部细节</li><li>引入一种新的方向分布一致性损失，确保生成分布和原分布之间的一致性，防止过拟合（overfit）</li><li>跨领域情景的结构一致性</li></ol><h3 id="challenges">Challenges</h3><ol type="1"><li>overfit</li><li>细节学习阶段（t较小的时候）风格迁移失败</li><li>现有的少样本GAN适应只约束对应点成对距离（相对位置关系），无法约束分布旋转</li></ol><h3 id="method">Method</h3><h4 id="training-with-phasic-content-fusion">Training with PhasicContent Fusion</h4><p>在前向加噪过程中学习内容和风格信息，引入权重函数m(t),自适应地融合<spanclass="math inline"><em>E</em>(<em>x</em><sup><em>A</em></sup>)</span>和噪声<spanclass="math inline"><em>z</em> ∼ 𝒩(0, <em>I</em>)</span>， <spanclass="math display"><em>Ê</em>(<em>x</em><sup><em>A</em></sup>) = <em>m</em>(<em>t</em>)<em>E</em>(<em>x</em><sup><em>A</em></sup>) + (1 − <em>m</em>(<em>t</em>))<em>z</em></span>然后使用多个卷积块将 <spanclass="math inline"><em>Ê</em>(<em>x</em><sup><em>A</em></sup>)</span>与 <spanclass="math inline"><em>E</em>(<em>x</em><sub><em>t</em></sub><sup><em>A</em></sup>)</span>融合，得到融合后的特征 <spanclass="math inline"><em>E</em>(<em>x</em><sup><em>A</em></sup>, <em>x</em><sub><em>t</em></sub><sup><em>A</em></sup>)</span>，最后将融合后的特征送入UNet解码器对噪声进行预测，得到包含增强内容信息的<spanclass="math inline"><em>x</em><sub><em>t</em> − 1</sub><sup><em>A</em></sup></span>#### 方向分布一致性损失函数 directional distribution consistency loss(DDC) 最终的损失函数由以下三个损失函数构成： 1. Directional distributionconsistency loss <spanclass="math display">ℒ<sub><em>D</em><em>D</em><em>C</em></sub> = ∥<em>E</em>(<em>x</em><sup><em>A</em></sup>) + <em>w</em>, <em>E</em>(<em>x</em><sub>0</sub><sup><em>A</em> → <em>B</em></sup>)∥<sup>2</sup></span>其中w为方向向量，给定源分布 <spanclass="math inline"><em>A</em> = {<em>x</em><sub>1</sub><sup><em>A</em></sup>, ⋯<em>x</em><sub><em>m</em></sub><sup><em>A</em></sup>}</span>和目标分布 <spanclass="math inline"><em>B</em> = {<em>x</em><sub>1</sub><sup><em>B</em></sup>, ⋯<em>x</em><sub><em>m</em></sub><sup><em>B</em></sup>}</span>,特征空间中从源域中心到目标域中心的跨域方向向量w, <spanclass="math display">$$w=\frac{1}{m}\sum_{i=1}^mE(x_i^B)-\frac{1}{n}\sum_{i=1}^nE(x_i^A)$$</span>2. Style loss <spanclass="math display">$$\mathcal{L}_{style}=\frac{1}{m}\sum_{i=1}^{m}\sum_{l}w_{l}\|G^{l}(x_{0}^{A\toB})-G^{l}(x_{i}^{B})\|^{2}$$</span>用于计算生成图像和目标图像之间的分割损失，基于Gram矩阵 3. Diffusion Loss<spanclass="math display">ℒ<sub><em>d</em><em>i</em><em>f</em></sub> = ||<em>ϵ</em><sub><em>θ</em></sub>(<em>x</em><sub><em>t</em></sub><sup><em>B</em></sup>, <em>t</em>) − <em>ϵ</em>||<sup>2</sup></span></p><p>最终的损失函数为：</p><p><spanclass="math display">ℒ = <em>m</em>(<em>t</em>)(1 − <em>w</em>(<em>t</em>))(<em>λ</em><sub><em>D</em><em>D</em><em>C</em></sub>ℒ<sub><em>D</em><em>D</em><em>C</em></sub>(<em>x</em><sup><em>A</em></sup>, <em>x</em><sub>0</sub><sup><em>A</em> → <em>B</em></sup>) + <em>λ</em><sub><em>s</em><em>t</em><em>y</em><em>l</em><em>e</em></sub>ℒ<sub><em>s</em><em>t</em><em>y</em><em>l</em><em>e</em></sub>(<em>x</em><sub>0</sub><sup><em>A</em> → <em>B</em></sup>, <em>x</em><sup><em>B</em></sup>)) + <em>w</em>(<em>t</em>)ℒ<sub><em>d</em><em>i</em><em>f</em></sub>(<em>x</em><sup><em>B</em></sup>)</span></p><h4id="迭代跨域结构引导-iterative-cross-domain-structure-guidanceicsg">迭代跨域结构引导Iterative Cross-domain Structure Guidance(ICSG)</h4><p>需要进一步理解</p><h3 id="实验及评估过程">实验及评估过程</h3><h3 id="相关概念">相关概念</h3><h4 id="图像翻译-image-to-image-translation">图像翻译 Image-to-ImageTranslation</h4><p>将图像中内容从一个图像域Ｘ转换到另一个图像域Ｙ，可以看作是将原始图像的某种属性Ｘ移除，重新赋予其新的属性Ｙ，也即是图像间的跨域转换。</p><h4 id="gram矩阵">Gram矩阵</h4><h5 id="原理">原理</h5><p>n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，称为这k个向量的格拉姆矩阵(Grammatrix)，很明显，这是一个对称矩阵。 输入图像的feature map为[ ch, h,w]。我们经过flatten（即是将h* w进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h* w]和[ h*w,ch]的矩阵。再对两个作内积得到Gram矩阵。</p><h5 id="应用">应用</h5><p>Gram matrix的应用-风格迁移： 1. 准备基准图像和风格图像</p><ol start="2" type="1"><li><p>使用深层网络分别提取基准图像（加白噪声）和风格图像的特征向量（或者说是特征图featuremap）</p></li><li><p>分别计算两个图像的特征向量的Gram矩阵，以两个图像的Gram矩阵的差异最小化为优化目标，不断调整基准图像，使风格不断接近目标风格图像</p></li></ol><p>一般来说浅层网络提取的是局部的细节纹理特征，深层网络提取的是更抽象的轮廓、大小等信息。这些特征总的结合起来表现出来的感觉就是图像的风格，由这些特征向量计算出来的的Gram矩阵，就可以把图像特征之间隐藏的联系提取出来，也就是各个特征之间的相关性高低。</p><h4 id="消融实验-ablation-study">消融实验 Ablation Study</h4><p>类似于“控制变量法”，逐一控制参数来观察结果的变化，以确定不同参数对模型的影响。</p>]]></content>
    
    
    <categories>
      
      <category>-科研实习 -RadioDiff微调 -Few-Shot相关论文阅读笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>week2</title>
    <link href="/2025/06/25/week2/"/>
    <url>/2025/06/25/week2/</url>
    
    <content type="html"><![CDATA[<h1 id="diffusion-model-李宏毅笔记">diffusion model (李宏毅)笔记</h1><h2 id="概念部分">概念部分</h2><h3 id="一般图像生成模型基本框架">一般图像生成模型基本框架</h3><p>text encoder → generation model → decoder</p><h3 id="fidfrechet-inception-distance">FID(Frechet InceptionDistance)</h3><p>FID是一种用于评估生成图像质量的度量标准</p><ol type="1"><li><p>特征提取 使用预训练的 Inception V3 模型（在 ImageNet数据集上训练的图像分类网络）作为特征提取器。输入图像（通常调整为 299×299的分辨率）会通过 Inception V3 前向传播，提取池化层（即 pool3层）的输出特征。这个特征是一个 2048 维的向量。</p></li><li><p>特征分布假设 FID假设提取的特征向量服从多变量正态分布。对于真实图像集合X和生成图像集合G，分别计算特征的均值向量和协方差矩阵：真实图像特征均值 <spanclass="math inline"><em>μ</em><sub><em>r</em></sub></span> 协方差 <spanclass="math inline"><em>Σ</em><sub><em>r</em></sub></span>生成图像特征均值 <spanclass="math inline"><em>μ</em><sub><em>g</em></sub></span> 协方差 <spanclass="math inline"><em>Σ</em><sub><em>g</em></sub></span></p></li><li><p>Fréchet 距离计算 Fréchet 距离用来衡量两个正态分布之间的差异<spanclass="math display">FID = ∥<em>μ</em><sub><em>r</em></sub> − <em>μ</em><sub><em>g</em></sub>∥<sub>2</sub><sup>2</sup> + Tr(<em>Σ</em><sub><em>r</em></sub> + <em>Σ</em><sub><em>g</em></sub> − 2(<em>Σ</em><sub><em>r</em></sub><em>Σ</em><sub><em>g</em></sub>)<sup>1/2</sup>)</span>第一项衡量两个分布均值的欧几里得距离，表示分布中心的偏移，第二项衡量协方差矩阵的差异，反映分布形状和分散度的不同</p></li></ol><h2 id="原理部分">原理部分</h2><p><ahref="https://www.bilibili.com/video/BV14c411J7f2?spm_id_from=333.788.player.switch&amp;vd_source=257a40315247000b85510107fa6b747d&amp;p=4"class="uri">https://www.bilibili.com/video/BV14c411J7f2?spm_id_from=333.788.player.switch&amp;vd_source=257a40315247000b85510107fa6b747d&amp;p=4</a></p><ol type="1"><li><p>最大似然估计 <a href="https://zhuanlan.zhihu.com/p/55791843"class="uri">https://zhuanlan.zhihu.com/p/55791843</a> <imgsrc="image\1747666364704.png" alt="1747666364704" /></p></li><li><p>扩散模型与能量模型，Score-Matching和SDE，ODE的关系 <ahref="https://zhuanlan.zhihu.com/p/576779879"class="uri">https://zhuanlan.zhihu.com/p/576779879</a></p></li></ol><h3 id="疑问">疑问</h3><ol type="1"><li>李宏毅认为噪声实际上不是一步一步加进<spanclass="math inline"><em>x</em><sub>0</sub></span>的,而是一步实现的 <imgsrc="image\Snipaste_2025-05-21_18-49-49.png" />但通过对一致性模型的学习，我了解到diffusionmodel的前向过程和逆向过程实际上都能表示为SDE过程，需要进行多次迭代，而consistencymodel就是为了解决这个问题，将SDE的随机项消除，转变为ODE过程，从而实现减少迭代次数，这是否与上图观点相悖？</li></ol>]]></content>
    
    
    <categories>
      
      <category>-科研实习 -周记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>week1</title>
    <link href="/2025/05/20/week1/"/>
    <url>/2025/05/20/week1/</url>
    
    <content type="html"><![CDATA[<h1 id="一致性模型consistency-modelscm">一致性模型（ConsistencyModels，CM）</h1><p><a href="https://zhuanlan.zhihu.com/p/623402026"class="uri">https://zhuanlan.zhihu.com/p/623402026</a>一致性模型（ConsistencyModels，CM）主要解决扩散生成模型迭代采样过程缓慢的问题，支持一步采样快速生成和多步采样高精度生成，CM的本质就是将任何时间步的点映射到轨迹的起点。CM 的一个关键的性质是self-consistency 性：相同轨迹上的点映射到相同的初始点。</p><h2 id="sde与ode">SDE与ODE</h2><p>前向过程满足的SDE： <spanclass="math display">d<strong>x</strong> = <strong>f</strong>(<strong>x</strong>, <em>t</em>)d<em>t</em> + <em>g</em>(<em>t</em>)d<strong>w</strong>(<em>t</em>)</span>f:漂移因子 g:扩散因子 w:维纳过程(标准布朗运动) score:<spanclass="math display">∇<sub><em>x</em></sub>log <em>p</em>(<em>x</em>)</span>即概率密度对数的梯度</p><p>朗之万动力学<br />边缘概率密度<br />score matching</p><p>逆向过程的SDE为： <spanclass="math display">$$\mathrm{d}\mathbf{x}=[\mathbf{f}(\mathbf{x},t)-g^2(t)\nabla_\mathbf{x}\logp_t(\mathbf{x})]\mathrm{d}t+g(t)\mathrm{d}\bar \\{\mathbf{w}}(t)$$</span></p><p>ODE：SDE去掉维纳过程，变成一个常微分方程<br /><span class="math display">$$\mathrm{d}\mathbf{x}_t=\begin{bmatrix}f(\mathbf{x}_t,t)-\frac{1}{2}g^2(t)\nabla\log p_t(\mathbf{x}_t)\end{bmatrix}\mathrm{d}t$$</span></p><h2 id="如何用神经网络训练一致性模型">如何用神经网络训练一致性模型</h2><p>一致性函数 <span class="math display">$$f(\mathbf{x}_t,t)=\begin{cases}\mathbf{x}_\varepsilon, &amp; t=\varepsilon \\f(\mathbf{x}_{t^{\prime}},t^{\prime}), &amp; t\in(\varepsilon,T],\forallt^{\prime}\in[\varepsilon,T] &amp;\end{cases}$$</span></p><p>一致性模型：即用神经网络模拟一致性函数的特性<br />给定任意神经网络F, <spanclass="math display"><em>f</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>, <em>t</em>) = <em>C</em><sub>skip</sub>(<em>t</em>)<strong>x</strong><sub><em>t</em></sub> + <em>C</em><sub>out</sub>(<em>t</em>)<em>F</em><sub><em>θ</em></sub>(<strong>x</strong><sub><em>t</em></sub>, <em>t</em>)</span>随t变化时C的变化</p><p>EDM–<spanclass="math inline"><em>C</em><sub><em>i</em><em>n</em></sub></span></p><p>损失函数——相邻两个时间输出值差距最小化<spanclass="math display">$$\mathcal{L}^N(\theta)=\mathbb{E}[\|f_\theta(\mathbf{x}_{t_{n+1}},t_{n+1})-f_\theta(\hat{\mathbf{x}}_{t_n},t_n)\|_2^2]$$</span>再经过EMA,最终<spanclass="math display">$$\mathcal{L}^N(\theta,\theta^-)=\mathbb{E}[\|f_\theta(\mathbf{x}_{t_{n+1}},t_{n+1})-f_{\theta^-}(\hat{\mathbf{x}}_{t_n},t_n)\|_2^2]$$</span></p><h3id="一致性蒸馏简称cdconsistency-distillation从已经学好的score-function蒸馏">一致性蒸馏（简称CD，ConsistencyDistillation）——从已经学好的score function蒸馏</h3><p><img src="1747148746366.png" /></p><p>已经有了score function <spanclass="math inline"><strong>s</strong><sub><em>ϕ</em></sub>(<strong>x</strong>(<em>t</em>), <em>t</em>)</span>### 一致性训练(简称CT，Consistency Training)——从数据中直接学 <imgsrc="Snipaste_2025-05-15_01-19-37.png" /></p><p>用<span class="math inline">$\nabla\logp_t(\mathbf{x}_t)=-\mathbb{E}\left[\frac{\mathbf{x}_t-\mathbf{x}}{t^2}|\mathbf{x}_t\right]$</span>来代替一致性蒸馏中的已有的sorefuction</p><h2id="如何通过一致性模型采样获得图像">如何通过一致性模型采样获得图像</h2><h3 id="一步采样">一步采样</h3><p>给定一个<spanclass="math inline"><em>x</em><sub><em>t</em></sub></span>，带入一致性模型</p><h3 id="多步采样">多步采样</h3><p>可提升图像质量</p><h1 id="sr3">SR3</h1><p>SR3 is an approach to image super resolution via iterative refinement通过迭代优化实现生成图像超分辨率</p><h2 id="key-words">key words</h2><ol type="1"><li>iterative refinement</li><li>both faces and natural images</li><li>bicubic interpolation</li><li>flexibility inchoosing number of diffusion steps, and the noiseschedule during inference</li><li>FID</li><li>rather than estimating the posterior mean, SR3 generates samplesfrom the target posterior.</li><li>constant number of refinement steps (often no more than 100).</li><li>onot requireanyauxiliaryobjective function inordertoensureconsistencywith the low resolutioninputs</li><li>our diffusion models do not provide a knob to control sample qualityvs. sample diversity（如何平衡样本质量与样本多样性吗？）, and findingways to do so isinteresting avenue for future research.</li></ol><h2 id="涉及知识点">涉及知识点</h2><ol type="1"><li>score matching</li><li>Langevin dynamics</li><li>PSNR and SSIM</li><li>residual blocks</li><li>级联结构</li><li>Normalizing flows</li><li>anti-aliasing</li><li>ImageNet</li><li>Dropout</li></ol><h2 id="总结">总结</h2><ol type="1"><li>将LR作为条件输入</li><li>不在取离散的t，而是将同样范围内连续t的采样值（即noise）输入或许可以减小推理步数，加快速度？</li><li>级联 分阶段生成：第一阶段：使用无条件生成模型（如DDPM）生成低分辨率图像（如64×64）。第二阶段：将低分辨率图像输入第一个SR3模型，进行4倍上采样（64→256）。第三阶段：将256×256图像输入第二个SR3模型，再次4倍上采样至1024×1024。</li></ol><h2 id="问题">问题</h2><ol type="1"><li>下采样操作，将 HR 图像的尺⼨减半，⽣成对应的 LR 图像下采样方式如何选择（是否采用SR3论文中提到的双三次插值？），以及为什么规定LR为HR尺寸减半后的结果</li><li>SR3采用的是迭代优化实现图像超分辨率重建的方法，是否面临计算和时间成本高的问题，如何解决是否可以参考连续一致性模型的做法</li><li>连续一致性模型有单步采样和多部采样两种方式，多部采样可以理解为牺牲速度换取高质量？是否可以再次基础上实现超分辨率重建？</li><li>尝试<a href="https://github.com/openai/consistency_models"class="uri">https://github.com/openai/consistency_models</a> 和<ahref="https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement"class="uri">https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement</a>时遇到困难</li><li>对数学公式的推导要掌握到什么程度？</li></ol>]]></content>
    
    
    <categories>
      
      <category>-科研实习 -周记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
