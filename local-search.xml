<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>week2</title>
    <link href="/2025/06/25/week2/"/>
    <url>/2025/06/25/week2/</url>
    
    <content type="html"><![CDATA[<h1>diffusion model (李宏毅)笔记</h1><h2 id="概念部分">概念部分</h2><h3 id="一般图像生成模型基本框架">一般图像生成模型基本框架</h3><p>text encoder → generation model → decoder</p><h3 id="FID-Frechet-Inception-Distance">FID(Frechet Inception Distance)</h3><p>FID是一种用于评估生成图像质量的度量标准</p><ol><li><p>特征提取  使用预训练的 Inception V3 模型（在 ImageNet 数据集上训练的图像分类网络）作为特征提取器。输入图像（通常调整为 299×299 的分辨率）会通过 Inception V3 前向传播，提取池化层（即 pool3 层）的输出特征。这个特征是一个 2048 维的向量。</p></li><li><p>特征分布假设  FID 假设提取的特征向量服从多变量正态分布。对于真实图像集合X和生成图像集合G，分别计算特征的均值向量和协方差矩阵：<br>真实图像特征均值 $\mu_{r}$   协方差 $\Sigma_{r}$<br>生成图像特征均值 $\mu_{g}$   协方差 $\Sigma_{g}$</p></li><li><p>Fréchet 距离计算<br>Fréchet 距离用来衡量两个正态分布之间的差异$$\mathrm{FID}=|\mu_r-\mu_g|_2^2+\mathrm{Tr}(\Sigma_r+\Sigma_g-2(\Sigma_r\Sigma_g)^{1/2})$$<br>第一项衡量两个分布均值的欧几里得距离，表示分布中心的偏移，第二项衡量协方差矩阵的差异，反映分布形状和分散度的不同</p></li></ol><h2 id="原理部分">原理部分</h2><p><a href="https://www.bilibili.com/video/BV14c411J7f2?spm_id_from=333.788.player.switch&amp;vd_source=257a40315247000b85510107fa6b747d&amp;p=4">https://www.bilibili.com/video/BV14c411J7f2?spm_id_from=333.788.player.switch&amp;vd_source=257a40315247000b85510107fa6b747d&amp;p=4</a></p><ol><li><p>最大似然估计 <a href="https://zhuanlan.zhihu.com/p/55791843">https://zhuanlan.zhihu.com/p/55791843</a><br><img src="image%5C1747666364704.png" alt="1747666364704"></p></li><li><p>扩散模型与能量模型，Score-Matching和SDE，ODE的关系 <a href="https://zhuanlan.zhihu.com/p/576779879">https://zhuanlan.zhihu.com/p/576779879</a></p></li></ol><h3 id="疑问">疑问</h3><ol><li>李宏毅认为噪声实际上不是一步一步加进$x_{0}$的,而是一步实现的<br><img src="image%5CSnipaste_2025-05-21_18-49-49.png" alt=""><br>但通过对一致性模型的学习，我了解到diffusion model的前向过程和逆向过程实际上都能表示为SDE过程，需要进行多次迭代，而consistency model就是为了解决这个问题，将SDE的随机项消除，转变为ODE过程，从而实现减少迭代次数，这是否与上图观点相悖？</li></ol>]]></content>
    
    
    <categories>
      
      <category>科研实习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>test</title>
    <link href="/2025/05/20/test/"/>
    <url>/2025/05/20/test/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>week1</title>
    <link href="/2025/05/20/week1/"/>
    <url>/2025/05/20/week1/</url>
    
    <content type="html"><![CDATA[<h1>一致性模型（Consistency Models，CM）</h1><p><a href="https://zhuanlan.zhihu.com/p/623402026">https://zhuanlan.zhihu.com/p/623402026</a><br>一致性模型（Consistency Models，CM）主要解决扩散生成模型迭代采样过程缓慢的问题，支持一步采样快速生成和多步采样高精度生成，CM 的本质就是将任何时间步的点映射到轨迹的起点。CM 的一个关键的性质是 self-consistency 性：相同轨迹上的点映射到相同的初始点。</p><h2 id="SDE与ODE">SDE与ODE</h2><p>前向过程满足的SDE：<br>$$\mathrm{d}\mathbf{x}=\mathbf{f}(\mathbf{x},t)\mathrm{d}t+g(t)\mathrm{d}\mathbf{w}(t) $$<br>f:漂移因子 g:扩散因子 w:维纳过程(标准布朗运动)  score:$$\nabla_x\log p(x)$$ 即概率密度对数的梯度</p><p>朗之万动力学<br>边缘概率密度<br>score matching</p><p>逆向过程的SDE为：<br>$$\mathrm{d}\mathbf{x}=[\mathbf{f}(\mathbf{x},t)-g^2(t)\nabla_\mathbf{x}\log p_t(\mathbf{x})]\mathrm{d}t+g(t)\mathrm{d}\bar \ {\mathbf{w}}(t)$$</p><p>ODE：SDE去掉维纳过程，变成一个常微分方程<br>$$\mathrm{d}\mathbf{x}_t=<br>\begin{bmatrix}<br>f(\mathbf{x}_t,t)-\frac{1}{2}g^2(t)\nabla\log p_t(\mathbf{x}_t)<br>\end{bmatrix}\mathrm{d}t$$</p><h2 id="如何用神经网络训练一致性模型">如何用神经网络训练一致性模型</h2><p>一致性函数<br>$$f(\mathbf{x}<em>t,t)=<br>\begin{cases}<br>\mathbf{x}</em>\varepsilon, &amp; t=\varepsilon \<br>f(\mathbf{x}_{t^{\prime}},t^{\prime}), &amp; t\in(\varepsilon,T],\forall t^{\prime}\in[\varepsilon,T] &amp;<br>\end{cases}$$</p><p>一致性模型：即用神经网络模拟一致性函数的特性<br>给定任意神经网络F,<br>$$f_\theta(\mathbf{x}<em>t,t)=C</em>{\mathrm{skip}}(t)\mathbf{x}<em>t+C</em>{\mathrm{out}}(t)F_\theta(\mathbf{x}_t,t)$$   随t变化时C的变化</p><p>EDM–$C_{in}$</p><p>损失函数——相邻两个时间输出值差距最小化$$\mathcal{L}^N(\theta)=\mathbb{E}[|f_\theta(\mathbf{x}<em>{t</em>{n+1}},t_{n+1})-f_\theta(\hat{\mathbf{x}}<em>{t_n},t_n)|<em>2^2]$$  再经过EMA,最终$$\mathcal{L}^N(\theta,\theta^-)=\mathbb{E}[|f</em>\theta(\mathbf{x}</em>{t_{n+1}},t_{n+1})-f_{\theta^-}(\hat{\mathbf{x}}_{t_n},t_n)|_2^2]$$</p><h3 id="一致性蒸馏（简称CD，Consistency-Distillation）——从已经学好的score-function蒸馏">一致性蒸馏（简称CD，Consistency Distillation）——从已经学好的score function蒸馏</h3><p><img src="image%5C1747148746366.png" alt=""></p><p>已经有了score function $\mathbf{s}_{\phi}(\mathbf{x}(t),t)$</p><h3 id="一致性训练-简称CT，Consistency-Training-——从数据中直接学">一致性训练(简称CT，Consistency Training)——从数据中直接学</h3><p><img src="image%5CSnipaste_2025-05-15_01-19-37.png" alt=""></p><p>用$\nabla\log p_t(\mathbf{x}_t)=-\mathbb{E}\left[\frac{\mathbf{x}_t-\mathbf{x}}{t^2}|\mathbf{x}_t\right]$来代替一致性蒸馏中的已有的sore fuction</p><h2 id="如何通过一致性模型采样获得图像">如何通过一致性模型采样获得图像</h2><h3 id="一步采样">一步采样</h3><p>给定一个$x_t$，带入一致性模型</p><h3 id="多步采样">多步采样</h3><p>可提升图像质量<br><img src="" alt=""></p><h1>SR3</h1><p>SR3 is an approach to image super resolution via iterative refinement<br>通过迭代优化实现生成图像超分辨率</p><h2 id="key-words">key words</h2><ol><li>iterative refinement</li><li>both faces and natural images</li><li>bicubic interpolation</li><li>flexibility inchoosing number of diffusion steps, and the noise schedule during inference</li><li>FID</li><li>rather than estimating the posterior mean, SR3 generates samples from the target posterior.</li><li>constant number of refinement steps (often no more than 100).</li><li>onot requireanyauxiliaryobjective function inorder toensureconsistencywith the low resolutioninputs</li><li>our diffusion models do not provide a knob to control sample quality vs. sample diversity（如何平衡样本质量与样本多样性吗？）, and finding ways to do so isinteresting<br>avenue for future research.</li></ol><h2 id="涉及知识点">涉及知识点</h2><ol><li>score matching</li><li>Langevin dynamics</li><li>PSNR and SSIM</li><li>residual blocks</li><li>级联结构</li><li>Normalizing flows</li><li>anti-aliasing</li><li>ImageNet</li><li>Dropout</li></ol><h2 id="总结">总结</h2><ol><li>将LR作为条件输入</li><li>不在取离散的t，而是将同样范围内连续t的采样值（即noise）输入<br>或许可以减小推理步数，加快速度？</li><li>级联 分阶段生成：<br>第一阶段：使用无条件生成模型（如DDPM）生成低分辨率图像（如64×64）。<br>第二阶段：将低分辨率图像输入第一个SR3模型，进行4倍上采样（64→256）。<br>第三阶段：将256×256图像输入第二个SR3模型，再次4倍上采样至1024×1024。</li></ol><h2 id="问题">问题</h2><ol><li>下采样操作，将 HR 图像的尺⼨减半，⽣成对应的 LR 图像<br>下采样方式如何选择（是否采用SR3论文中提到的双三次插值？），以及为什么规定LR为HR尺寸减半后的结果</li><li>SR3采用的是迭代优化实现图像超分辨率重建的方法，是否面临计算和时间成本高的问题，如何解决是否可以参考连续一致性模型的做法</li><li>连续一致性模型有单步采样和多部采样两种方式，多部采样可以理解为牺牲速度换取高质量？是否可以再次基础上实现超分辨率重建？</li><li>尝试<a href="https://github.com/openai/consistency_models">https://github.com/openai/consistency_models</a><br>和<a href="https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement">https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement</a> 时遇到困难</li><li>对数学公式的推导要掌握到什么程度？</li></ol>]]></content>
    
    
    <categories>
      
      <category>科研实习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
